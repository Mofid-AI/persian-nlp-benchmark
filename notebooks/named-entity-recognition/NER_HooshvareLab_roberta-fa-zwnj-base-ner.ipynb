{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NER/HooshvareLab/roberta-fa-zwnj-base-ner.ipynb","provenance":[],"collapsed_sections":["_jH-igoeBJwl"],"authorship_tag":"ABX9TyMVsTuAUWM7hnbchE86U6LD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"979875c66b474222a3a61cee5c34f9e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ece6501b09c146da9480cf5553a45aee","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7219fe0eb7ad42659ed98562edff32ff","IPY_MODEL_e6c1feb349e24e39b82805711d3ce379"]}},"ece6501b09c146da9480cf5553a45aee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7219fe0eb7ad42659ed98562edff32ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dac39fedeed949f88b74cbe5ddd9870e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1425,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1425,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_519fb7eb900540f6bdd69a4a1e91f727"}},"e6c1feb349e24e39b82805711d3ce379":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fd9163a94c1f4bc297ae06b292737eb4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.43k/1.43k [00:02&lt;00:00, 630B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b5f7143c626d4d7a9f2897359eb93161"}},"dac39fedeed949f88b74cbe5ddd9870e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"519fb7eb900540f6bdd69a4a1e91f727":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd9163a94c1f4bc297ae06b292737eb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b5f7143c626d4d7a9f2897359eb93161":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dcaa20a75c0f47358b54d4f2252d622b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1086aa053513477394137f1459620abd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7a1f16c965e6456ebadb5b46dbcbd30d","IPY_MODEL_dd04093e84384ef2b00f40f5cb6c0b45"]}},"1086aa053513477394137f1459620abd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7a1f16c965e6456ebadb5b46dbcbd30d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4e7aa42059dc45919a1fdecb22a89b90","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1159342,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1159342,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1900f3c1276e44bb8cd2ed3d656e36c6"}},"dd04093e84384ef2b00f40f5cb6c0b45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bc83e69b363c4fa1ac711c704de7059d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.16M/1.16M [00:58&lt;00:00, 19.7kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38b82e9190ef41bf9d84367e5db452dc"}},"4e7aa42059dc45919a1fdecb22a89b90":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1900f3c1276e44bb8cd2ed3d656e36c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bc83e69b363c4fa1ac711c704de7059d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"38b82e9190ef41bf9d84367e5db452dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"52fda4bd4ed3447d9bdfdf4b30853dd7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0e598f9aadaa4e0fa1fb842d82049adf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_142cbb7c68974044a415b868f253e53d","IPY_MODEL_0690845d415c48cd91451c725b76496b"]}},"0e598f9aadaa4e0fa1fb842d82049adf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"142cbb7c68974044a415b868f253e53d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_207c4e6afc2240fe977efb58f51552dd","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":875476,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":875476,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bc07fac861de4c3ab5bb386c4709c175"}},"0690845d415c48cd91451c725b76496b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b64bb9777cf4437d86a30b83ad9a00bc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 875k/875k [00:05&lt;00:00, 156kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fc4d48a4347e45709adcabc3fafe2b72"}},"207c4e6afc2240fe977efb58f51552dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bc07fac861de4c3ab5bb386c4709c175":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b64bb9777cf4437d86a30b83ad9a00bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fc4d48a4347e45709adcabc3fafe2b72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"33f982c6220349f1a6e585090f38c460":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fe2f8c573a4d42bd96317807f9f56abf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_74e9991fe0a142f8bd4c2abb20bbd21a","IPY_MODEL_126e1ea0d47249a082eebc083735fbd0"]}},"fe2f8c573a4d42bd96317807f9f56abf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74e9991fe0a142f8bd4c2abb20bbd21a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0efcf42a66294fdf92ec55c3b51dfae8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2749025,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2749025,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7b5d8899fc9d4860b10e87ce9369266e"}},"126e1ea0d47249a082eebc083735fbd0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dd1c813375de4785aadf1f0024dea497","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.75M/2.75M [00:03&lt;00:00, 764kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_37cd0f55575f43ea8b9a27e367a8ed71"}},"0efcf42a66294fdf92ec55c3b51dfae8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7b5d8899fc9d4860b10e87ce9369266e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dd1c813375de4785aadf1f0024dea497":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"37cd0f55575f43ea8b9a27e367a8ed71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4ab473eb7d1c4e679e31119f456cd6a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_266b69109448487e87f8b391563b2961","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_00132fc6692c43a587c7f37eb01196ab","IPY_MODEL_0d20dd6a878343db9912eb12ff48d0d6"]}},"266b69109448487e87f8b391563b2961":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"00132fc6692c43a587c7f37eb01196ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ecd99adad137492986597a9e7537050f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":315,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":315,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_13ee3f1b66ea454d931cedd926774a49"}},"0d20dd6a878343db9912eb12ff48d0d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b5cb20832e424224a4056debe150ba40","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 315/315 [00:50&lt;00:00, 6.21B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4b45c260ebaf413cbe1b5b8329e9dfbd"}},"ecd99adad137492986597a9e7537050f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"13ee3f1b66ea454d931cedd926774a49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5cb20832e424224a4056debe150ba40":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4b45c260ebaf413cbe1b5b8329e9dfbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b494bc39c1bb4165afdf168f8688cd54":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_da3007e101bf48d099aa59ec495c7861","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5b0d75d11b3f466aa2f99e9e64bd2747","IPY_MODEL_dc0c08ea432f449c95a7e8f6b2a6f208"]}},"da3007e101bf48d099aa59ec495c7861":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b0d75d11b3f466aa2f99e9e64bd2747":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b63cd3864f1242d4bfe465104acceb7b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":358,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":358,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cde58422089d4b798b4d07f870bb28bc"}},"dc0c08ea432f449c95a7e8f6b2a6f208":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b11c9af8dc0341ba84bd17aa0200aad8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 358/358 [00:03&lt;00:00, 117B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4cc0e5d92cb24026a031202682b28357"}},"b63cd3864f1242d4bfe465104acceb7b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cde58422089d4b798b4d07f870bb28bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b11c9af8dc0341ba84bd17aa0200aad8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4cc0e5d92cb24026a031202682b28357":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"382d2fa266514a47a96f332300ab107d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9a2fff6de10547dfa3f7c8cc777eab39","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7be85b9e40e545ea9a010403aa6049cd","IPY_MODEL_989cb4c98b8742118c644aaaccb17666"]}},"9a2fff6de10547dfa3f7c8cc777eab39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7be85b9e40e545ea9a010403aa6049cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a5313d9060dd4ac78a1f900f31c3d521","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":470984439,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":470984439,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_88d639fed76744788f8adec52257fd16"}},"989cb4c98b8742118c644aaaccb17666":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_099bd430d8674ab2ac6d4ebc0572ff34","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 471M/471M [00:46&lt;00:00, 10.2MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_08a4aff97a254babb1c8334506ec0d9e"}},"a5313d9060dd4ac78a1f900f31c3d521":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"88d639fed76744788f8adec52257fd16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"099bd430d8674ab2ac6d4ebc0572ff34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"08a4aff97a254babb1c8334506ec0d9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"609a50dd9c754b558af106f4723fcd90":{"model_module":"@jupyter-widgets/controls","model_name":"TextareaModel","state":{"_view_name":"TextareaView","style":"IPY_MODEL_100b281528234c93a7ed7bdfa2102e84","rows":5,"_dom_classes":[],"description":"","_model_name":"TextareaModel","placeholder":"Please enter you text ...","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"مدیرکل محیط زیست استان البرز با بیان اینکه با بیان اینکه موضوع شیرابه‌های زباله‌های انتقال یافته در منطقه حلقه دره خطری برای این استان است، گفت: در این مورد گزارشاتی در ۲۵ مرداد ۱۳۹۷ تقدیم مدیران استان شده است.","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","continuous_update":true,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_04d9a3be9df8498b931eada451ac92d0"}},"100b281528234c93a7ed7bdfa2102e84":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"04d9a3be9df8498b931eada451ac92d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"90%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a9c37d5cbc72421e80025fa94c7a3b4b":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","state":{"_view_name":"ButtonView","style":"IPY_MODEL_a8b8d1914d3c484495e906016479a54b","_dom_classes":[],"description":"Send","_model_name":"ButtonModel","button_style":"success","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","tooltip":"Submit","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","layout":"IPY_MODEL_633b90f3cb574ba7a8427d9de08177a4","_model_module":"@jupyter-widgets/controls","icon":""}},"a8b8d1914d3c484495e906016479a54b":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","state":{"_view_name":"StyleView","_model_name":"ButtonStyleModel","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"button_color":null,"font_weight":"","_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"633b90f3cb574ba7a8427d9de08177a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f5fc43ae93984a4a8646133a316d2701":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","state":{"_view_name":"OutputView","msg_id":"","_dom_classes":[],"_model_name":"OutputModel","outputs":[{"output_type":"display_data","metadata":{"tags":[]},"text/html":"<p class=\"ner-box\"><span class=\"token\"><s></span> <span class=\"token\">ĠÙħØ¯ÛĮØ±Ú©ÙĦ</span> <span class=\"token token-ner\">ĠÙħØŃÛĮØ·<span class=\"ner-label\">B-ORG</span></span> <span class=\"token token-ner\">ĠØ²ÛĮØ³Øª<span class=\"ner-label\">I-ORG</span></span> <span class=\"token token-ner\">ĠØ§Ø³ØªØ§ÙĨ<span class=\"ner-label\">I-ORG</span></span> <span class=\"token token-ner\">ĠØ§ÙĦØ¨Ø±Ø²<span class=\"ner-label\">I-ORG</span></span> <span class=\"token\">ĠØ¨Ø§</span> <span class=\"token\">ĠØ¨ÛĮØ§ÙĨ</span> <span class=\"token\">ĠØ§ÛĮÙĨÚ©Ùĩ</span> <span class=\"token\">ĠØ¨Ø§</span> <span class=\"token\">ĠØ¨ÛĮØ§ÙĨ</span> <span class=\"token\">ĠØ§ÛĮÙĨÚ©Ùĩ</span> <span class=\"token\">ĠÙħÙĪØ¶ÙĪØ¹</span> <span class=\"token\">ĠØ´ÛĮØ±</span> <span class=\"token\">Ø§Ø¨Ùĩ</span> <span class=\"token\">âĢĮ</span> <span class=\"token\">ÙĩØ§ÛĮ</span> <span class=\"token\">ĠØ²Ø¨Ø§ÙĦÙĩ</span> <span class=\"token\">âĢĮ</span> <span class=\"token\">ÙĩØ§ÛĮ</span> <span class=\"token\">ĠØ§ÙĨØªÙĤØ§ÙĦ</span> <span class=\"token\">ĠÛĮØ§ÙģØªÙĩ</span> <span class=\"token\">ĠØ¯Ø±</span> <span class=\"token token-ner\">ĠÙħÙĨØ·ÙĤÙĩ<span class=\"ner-label\">B-LOC</span></span> <span class=\"token token-ner\">ĠØŃÙĦÙĤÙĩ<span class=\"ner-label\">I-LOC</span></span> <span class=\"token token-ner\">ĠØ¯Ø±Ùĩ<span class=\"ner-label\">I-LOC</span></span> <span class=\"token\">ĠØ®Ø·Ø±ÛĮ</span> <span class=\"token\">ĠØ¨Ø±Ø§ÛĮ</span> <span class=\"token\">ĠØ§ÛĮÙĨ</span> <span class=\"token\">ĠØ§Ø³ØªØ§ÙĨ</span> <span class=\"token\">ĠØ§Ø³Øª</span> <span class=\"token\">ØĮ</span> <span class=\"token\">ĠÚ¯ÙģØª</span> <span class=\"token\">:</span> <span class=\"token\">ĠØ¯Ø±</span> <span class=\"token\">ĠØ§ÛĮÙĨ</span> <span class=\"token\">ĠÙħÙĪØ±Ø¯</span> <span class=\"token\">ĠÚ¯Ø²Ø§Ø±Ø´Ø§ØªÛĮ</span> <span class=\"token\">ĠØ¯Ø±</span> <span class=\"token token-ner\">ĠÛ²Ûµ<span class=\"ner-label\">B-DAT</span></span> <span class=\"token token-ner\">ĠÙħØ±Ø¯Ø§Ø¯<span class=\"ner-label\">I-DAT</span></span> <span class=\"token token-ner\">ĠÛ±Û³Û¹Û·<span class=\"ner-label\">I-DAT</span></span> <span class=\"token\">ĠØªÙĤØ¯ÛĮÙħ</span> <span class=\"token\">ĠÙħØ¯ÛĮØ±Ø§ÙĨ</span> <span class=\"token\">ĠØ§Ø³ØªØ§ÙĨ</span> <span class=\"token\">ĠØ´Ø¯Ùĩ</span> <span class=\"token\">ĠØ§Ø³Øª</span> <span class=\"token\">.</span> <span class=\"token\"></s></span></p>","text/plain":"<IPython.core.display.HTML object>"}],"_view_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_view_count":null,"_view_module_version":"1.0.0","layout":"IPY_MODEL_5d49c86a084d4c6cad5ed37a758e805e","_model_module":"@jupyter-widgets/output"}},"5d49c86a084d4c6cad5ed37a758e805e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hA3SNXdmANP2"},"source":["# RobertaNER\n","This model fine-tuned for the Named Entity Recognition (NER) task on a mixed NER dataset collected from ARMAN, PEYMA, and WikiANN that covered ten types of entities:\n","\n","* Date (DAT)\n","* Event (EVE)\n","* Facility (FAC)\n","* Location (LOC)\n","* Money (MON)\n","* Organization (ORG)\n","* Percent (PCT)\n","* Person (PER)\n","* Product (PRO)\n","* Time (TIM)"]},{"cell_type":"code","metadata":{"id":"avTogA1BZ66c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627132195237,"user_tz":-270,"elapsed":806,"user":{"displayName":"Zohreh Fallah","photoUrl":"","userId":"16168249174167062064"}},"outputId":"933651c6-b6dc-4e79-bef6-fea43196f743"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sat Jul 24 13:09:53 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   46C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               79\n","Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n","Stepping:            0\n","CPU MHz:             2199.998\n","BogoMIPS:            4399.99\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            256K\n","L3 cache:            56320K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FOt2Gor9fUW6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627132224146,"user_tz":-270,"elapsed":28913,"user":{"displayName":"Zohreh Fallah","photoUrl":"","userId":"16168249174167062064"}},"outputId":"923dd69d-fbf1-4337-b1fd-a2e98d4a5a1f"},"source":["!pip install hazm==0.7.0\n","!pip install seqeval==1.2.2\n","!pip install sentencepiece==0.1.96\n","!pip install transformers==4.7.0"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting hazm==0.7.0\n","  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 24.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 61 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 71 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 81 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 92 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 316 kB 5.4 MB/s \n","\u001b[?25hCollecting libwapiti>=0.2.1\n","  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n","\u001b[K     |████████████████████████████████| 233 kB 38.7 MB/s \n","\u001b[?25hCollecting nltk==3.3\n","  Downloading nltk-3.3.0.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 38.4 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm==0.7.0) (1.15.0)\n","Building wheels for collected packages: nltk, libwapiti\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394488 sha256=96d54b88a1c506d23cd076fc6f84ccdae8f90c11b3d6c897e45775ea45a3ddb3\n","  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n","  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154045 sha256=029639d202756e0758f9f06424a8467ca1ed7e9b0486e29b059dc3db56a9ca0a\n","  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n","Successfully built nltk libwapiti\n","Installing collected packages: nltk, libwapiti, hazm\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n","Collecting seqeval==1.2.2\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 936 kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2) (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.0.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=dca52b3b7cf361acd0c296af45ccc45d8188bccda0dabfc2c6e4ee865d9bb299\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Collecting sentencepiece==0.1.96\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 4.3 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting transformers==4.7.0\n","  Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (4.6.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (2.23.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (3.13)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 39.0 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 43.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (21.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (2019.12.20)\n","Collecting huggingface-hub==0.0.8\n","  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (1.19.5)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0) (3.5.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.7.0) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (2021.5.30)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (1.15.0)\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.7.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dwWkjJHQiwLL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627132258777,"user_tz":-270,"elapsed":34644,"user":{"displayName":"Zohreh Fallah","photoUrl":"","userId":"16168249174167062064"}},"outputId":"253b9b94-5a16-48df-df22-c23980c35b61"},"source":["!pip install PyDrive\n","import os\n","import IPython.display as ipd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: PyDrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (1.12.8)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.32.1)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.26.3)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n","Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.17.3)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2018.9)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (21.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.23.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (57.2.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.53.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (0.2.8)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.24.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UOODWzFYhEMM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627132276694,"user_tz":-270,"elapsed":8220,"user":{"displayName":"Zohreh Fallah","photoUrl":"","userId":"16168249174167062064"}},"outputId":"8da751b9-9d96-43f8-fb5e-adc799b9d077"},"source":["import os\n","import gc\n","import ast\n","import time\n","import hazm\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","import transformers\n","from transformers import AutoTokenizer, AutoConfig\n","from transformers import AutoModelForTokenClassification\n","\n","from IPython.display import display, HTML, clear_output\n","from ipywidgets import widgets, Layout\n","\n","from keras.preprocessing.sequence import pad_sequences\n","\n","from seqeval.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","\n","print()\n","print('numpy', np.__version__)\n","print('pandas', pd.__version__)\n","print('transformers', transformers.__version__)\n","print('torch', torch.__version__)\n","print()\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\n","numpy 1.19.5\n","pandas 1.1.5\n","transformers 4.7.0\n","torch 1.9.0+cu102\n","\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p5uKV9e-hERQ","executionInfo":{"status":"ok","timestamp":1627132286157,"user_tz":-270,"elapsed":1959,"user":{"displayName":"Zohreh Fallah","photoUrl":"","userId":"16168249174167062064"}}},"source":["class NER:\n","    def __init__(self, model_name):\n","        self.normalizer = hazm.Normalizer()\n","        self.model_name = model_name\n","        self.config = AutoConfig.from_pretrained(self.model_name)\n","        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n","        self.model = AutoModelForTokenClassification.from_pretrained(self.model_name)\n","        # self.labels = list(self.config.label2id.keys())\n","        self.id2label = self.config.id2label\n","\n","    @staticmethod\n","    def load_ner_data(file_path, word_index, tag_index, delimiter, join=False):\n","        dataset, labels = [], []\n","        with open(file_path, encoding=\"utf8\") as infile:\n","            sample_text, sample_label = [], []\n","            for line in infile:\n","                parts = line.strip().split(delimiter)\n","                if len(parts) > 1:\n","                    word, tag = parts[word_index], parts[tag_index]\n","                    if not word:\n","                        continue\n","                    sample_text.append(word)\n","                    sample_label.append(tag)\n","                else:\n","                    # end of sample\n","                    if sample_text and sample_label:\n","                        if join:\n","                            dataset.append(' '.join(sample_text))\n","                            labels.append(' '.join(sample_label))\n","                        else:\n","                            dataset.append(sample_text)\n","                            labels.append(sample_label)\n","                    sample_text, sample_label = [], []\n","        if sample_text and sample_label:\n","            if join:\n","                dataset.append(' '.join(sample_text))\n","                labels.append(' '.join(sample_label))\n","            else:\n","                dataset.append(sample_text)\n","                labels.append(sample_label)\n","        return dataset, labels\n","\n","    def load_test_datasets(self, dataset_name, dataset_dir, **kwargs):\n","        if dataset_name.lower() == \"peyma\":\n","            ner_file_path = dataset_dir + 'test.txt'\n","            if not os.path.exists(ner_file_path):\n","                print(ner_file_path)\n","                exit(1)\n","            return self.load_ner_data(ner_file_path, word_index=0, tag_index=1, delimiter='|',\n","                                      join=kwargs.get('join', False))\n","        elif dataset_name.lower() == \"arman\":\n","            dataset, labels = [], []\n","            for i in range(1, 4):\n","                ner_file_path = dataset_dir + f'test_fold{i}.txt'\n","                if not os.path.exists(ner_file_path):\n","                    print(ner_file_path)\n","                dataset_part, labels_part = self.load_ner_data(ner_file_path, word_index=0, tag_index=1, delimiter=' ',\n","                                                               join=kwargs.get('join', False))\n","                dataset += dataset_part\n","                labels += labels_part\n","            return dataset, labels\n","        elif dataset_name.lower() == \"hooshvare-peyman+arman+wikiann\":\n","            ner_file_path = dataset_dir + 'test.csv'\n","            if not os.path.exists(ner_file_path):\n","                print(ner_file_path)\n","                exit(1)\n","            data = pd.read_csv(ner_file_path, delimiter=\"\\t\")\n","            sentences, sentences_tags = data['tokens'].values.tolist(), data['ner_tags'].values.tolist()\n","            sentences = [ast.literal_eval(ss) for ss in sentences]\n","            sentences_tags = [ast.literal_eval(ss) for ss in sentences_tags]\n","            print(f'test part:\\n #sentences: {len(sentences)}, #sentences_tags: {len(sentences_tags)}')\n","            return sentences, sentences_tags\n","\n","    def load_datasets(self, dataset_name, dataset_dir, **kwargs):\n","        if dataset_name.lower() == \"farsiyar\":\n","            dataset, labels = [], []\n","            for i in range(1, 6):\n","                ner_file_path = dataset_dir + 'Persian-NER-part{i}.txt'\n","                if not os.path.exists(ner_file_path):\n","                    print(ner_file_path)\n","                dataset_part, labels_part = self.load_ner_data(ner_file_path, word_index=0, tag_index=1, delimiter='\\t',\n","                                                               join=kwargs.get('join', False))\n","                dataset += dataset_part\n","                labels += labels_part\n","            return dataset, labels\n","        elif dataset_name.lower() == \"wikiann\":\n","            ner_file_path = dataset_dir + 'wikiann-fa.bio'\n","            if not os.path.exists(ner_file_path):\n","                print(ner_file_path)\n","                exit(1)\n","            return self.load_ner_data(ner_file_path, word_index=0, tag_index=-1, delimiter=' ',\n","                                      join=kwargs.get('join', False))\n","\n","    def ner_inference(self, input_text, device, max_length):\n","        if not self.model or not self.tokenizer or not self.id2label:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        pt_batch = self.tokenizer(\n","            [self.normalizer.normalize(sequence) for sequence in input_text],\n","            padding=True,\n","            truncation=True,\n","            max_length=max_length,\n","            return_tensors=\"pt\"\n","        )\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","\n","        pt_batch = pt_batch.to(device)\n","        pt_outputs = self.model(**pt_batch)\n","        pt_predictions = torch.argmax(pt_outputs.logits, dim=-1)\n","        pt_predictions = pt_predictions.cpu().detach().numpy().tolist()\n","\n","        output_predictions = []\n","        for i, sequence in enumerate(input_text):\n","            tokens = self.tokenizer.tokenize(self.tokenizer.decode(self.tokenizer.encode(sequence)))\n","            predictions = [(token, self.id2label[prediction]) for token, prediction in\n","                           zip(tokens, pt_predictions[i])]\n","            output_predictions.append(predictions)\n","        return output_predictions\n","\n","    def ner_evaluation(self, input_text, input_labels, device, batch_size=4):\n","        if not self.model or not self.tokenizer or not self.id2label:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        max_len = 0\n","        tokenized_texts, new_labels = [], []\n","        for sentence, sentence_label in zip(input_text, input_labels):\n","            if type(sentence) == str:\n","                sentence = sentence.strip().split()\n","            if len(sentence) != len(sentence_label):\n","                print('Something wrong has been happened! Length of a sentence and its label is not equal!')\n","                return\n","            tokenized_sentence, new_sentence_label = [], []\n","            for word, label in zip(sentence, sentence_label):\n","                # Tokenize the word and count # of subwords the word is broken into\n","                tokenized_word = self.tokenizer.tokenize(word)\n","                n_subwords = len(tokenized_word)\n","\n","                # Add the tokenized word to the final tokenized word list\n","                tokenized_sentence.extend(tokenized_word)\n","                # Add the same label to the new list of labels `n_subwords` times\n","                new_sentence_label.extend([label] * n_subwords)\n","\n","            max_len = max(max_len, len(tokenized_sentence))\n","            tokenized_texts.append(tokenized_sentence)\n","            new_labels.append(new_sentence_label)\n","\n","        max_len = min(max_len, self.config.max_position_embeddings)\n","        print(\"max_len:\", max_len)\n","        input_ids = pad_sequences([self.tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n","                                  maxlen=max_len, dtype=\"long\", value=self.config.pad_token_id,\n","                                  truncating=\"post\", padding=\"post\")\n","        del tokenized_texts\n","        input_labels = pad_sequences([[self.config.label2id.get(l) for l in lab] for lab in new_labels],\n","                                     maxlen=max_len, value=self.config.label2id.get('O'), padding=\"post\",\n","                                     dtype=\"long\", truncating=\"post\")\n","        del new_labels\n","\n","        train_data = TensorDataset(torch.tensor(input_ids), torch.tensor(input_labels))\n","        data_loader = DataLoader(train_data, batch_size=batch_size)\n","        # data_loader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=batch_size)\n","        print(\"#samples:\", len(input_ids))\n","        print(\"#batch:\", len(data_loader))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","\n","        total_loss, total_time = 0, 0\n","        output_predictions = []\n","        print(\"Start to evaluate test data ...\")\n","        for step, batch in enumerate(data_loader):\n","            b_input_ids, b_labels = batch\n","\n","            # move tensors to GPU if CUDA is available\n","            b_input_ids = b_input_ids.to(device)\n","            b_labels = b_labels.to(device)\n","\n","            # This will return the loss (rather than the model output) because we have provided the `labels`.\n","            with torch.no_grad():\n","                start = time.monotonic()\n","                outputs = self.model(b_input_ids, labels=b_labels)\n","                end = time.monotonic()\n","                total_time += end - start\n","                print(f'inference time for step {step}: {end - start}')\n","            # get the loss\n","            total_loss += outputs.loss.item()\n","\n","            b_predictions = torch.argmax(outputs.logits, dim=2)\n","            b_predictions = b_predictions.cpu().detach().numpy().tolist()\n","            b_labels = b_labels.cpu().detach().numpy().tolist()\n","\n","            for i, sample in enumerate(b_input_ids):\n","                sample_input = list(sample)\n","                # remove pad tokens\n","                while sample_input[-1] == self.config.pad_token_id:\n","                    sample_input.pop()\n","                # tokens = self.tokenizer.tokenize(self.tokenizer.decode(sample_input))\n","                tokens = [self.tokenizer.decode([t]) for t in sample_input]\n","                sample_true_labels = [self.id2label[e] for e in b_labels[i][:len(sample_input)]]\n","                sample_predictions = [self.id2label[e] for e in b_predictions[i][:len(sample_input)]]\n","                output_predictions.append(\n","                    [(t, sample_true_labels[j], sample_predictions[j]) for j, t in enumerate(tokens)])\n","\n","        # Calculate the average loss over the training data.\n","        avg_train_loss = total_loss / len(data_loader)\n","        print(\"average loss:\", avg_train_loss)\n","        print(\"total inference time:\", total_time)\n","        print(\"total inference time / #samples:\", total_time / len(input_ids))\n","\n","        return output_predictions\n","\n","    def ner_evaluation_2(self, input_text, input_labels, device, batch_size=4):\n","        if not self.model or not self.tokenizer or not self.id2label:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        print(\"len(input_text):\", len(input_text))\n","        print(\"len(input_labels):\", len(input_labels))\n","        c = 0\n","        max_len = 0\n","        tokenized_texts, new_labels = [], []\n","        for sentence, sentence_label in zip(input_text, input_labels):\n","            if type(sentence) == str:\n","                sentence = sentence.strip().split()\n","            if len(sentence) != len(sentence_label):\n","                print('Something wrong has been happened! Length of a sentence and its label is not equal!')\n","                return\n","            tokenized_words = self.tokenizer(sentence, padding=False, add_special_tokens=False).input_ids\n","            tokenized_sentence_ids, new_sentence_label = [], []\n","            for i, tokenized_word in enumerate(tokenized_words):\n","                # Add the tokenized word to the final tokenized word list\n","                tokenized_sentence_ids += tokenized_word\n","                # Add the same label to the new list of labels `number of subwords` times\n","                new_sentence_label.extend([self.config.label2id.get(sentence_label[i])] * len(tokenized_word))\n","\n","            max_len = max(max_len, len(tokenized_sentence_ids))\n","            tokenized_texts.append(tokenized_sentence_ids)\n","            new_labels.append(new_sentence_label)\n","            c += 1\n","            if c % 10000 == 0:\n","                print(\"c:\", c)\n","        max_len = min(max_len, self.config.max_position_embeddings)\n","        print(\"max_len:\", max_len)\n","        input_ids = pad_sequences(tokenized_texts, maxlen=max_len, dtype=\"long\", value=self.config.pad_token_id,\n","                                  truncating=\"post\", padding=\"post\")\n","        del tokenized_texts\n","        input_labels = pad_sequences(new_labels, maxlen=max_len, value=self.config.label2id.get('O'), padding=\"post\",\n","                                     dtype=\"long\", truncating=\"post\")\n","        del new_labels\n","\n","        train_data = TensorDataset(torch.tensor(input_ids), torch.tensor(input_labels))\n","        data_loader = DataLoader(train_data, batch_size=batch_size)\n","        # data_loader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=batch_size)\n","        print(\"#samples:\", len(input_ids))\n","        print(\"#batch:\", len(data_loader))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","\n","        total_time = 0\n","        output_predictions = []\n","        print(\"Start to evaluate test data ...\")\n","        for step, batch in enumerate(data_loader):\n","            b_input_ids, b_labels = batch\n","\n","            # move tensors to GPU if CUDA is available\n","            b_input_ids = b_input_ids.to(device)\n","            b_labels = b_labels.to(device)\n","\n","            # This will return the loss (rather than the model output) because we have provided the `labels`.\n","            with torch.no_grad():\n","                start = time.monotonic()\n","                outputs = self.model(b_input_ids, labels=b_labels)\n","                end = time.monotonic()\n","                total_time += end - start\n","                print(f'inference time for step {step}: {end - start}')\n","\n","            b_predictions = torch.argmax(outputs.logits, dim=2)\n","            b_predictions = b_predictions.cpu().detach().numpy().tolist()\n","            b_labels = b_labels.cpu().detach().numpy().tolist()\n","\n","            for i, sample in enumerate(b_input_ids):\n","                sample_input = list(sample)\n","                # remove pad tokens\n","                while sample_input[-1] == self.config.pad_token_id:\n","                    sample_input.pop()\n","                # tokens = self.tokenizer.tokenize(self.tokenizer.decode(sample_input))\n","                tokens = [self.tokenizer.decode([t]) for t in sample_input]\n","                sample_true_labels = [self.id2label[e] for e in b_labels[i][:len(sample_input)]]\n","                sample_predictions = [self.id2label[e] for e in b_predictions[i][:len(sample_input)]]\n","                output_predictions.append(\n","                    [(t, sample_true_labels[j], sample_predictions[j]) for j, t in enumerate(tokens)])\n","\n","        print(\"total inference time:\", total_time)\n","        print(\"total inference time / #samples:\", total_time / len(input_ids))\n","\n","        return output_predictions\n","\n","    def check_input_label_consistency(self, labels):\n","        model_labels = self.config.label2id.keys()\n","        dataset_labels = set()\n","        for l in labels:\n","            dataset_labels.update(set(l))\n","        print(\"model labels:\", model_labels)\n","        print(\"dataset labels:\", dataset_labels)\n","        print(\"intersection:\", set(model_labels).intersection(dataset_labels))\n","        print(\"model_labels-dataset_labels:\", list(set(model_labels) - set(dataset_labels)))\n","        print(\"dataset_labels-model_labels:\", list(set(dataset_labels) - set(model_labels)))\n","        if list(set(dataset_labels) - set(model_labels)):\n","            return False\n","        return True\n","\n","    @staticmethod\n","    def resolve_input_label_consistency(labels, label_translation_map):\n","        for i, sentence_labels in enumerate(labels):\n","            for j, label in enumerate(sentence_labels):\n","                labels[i][j] = label_translation_map.get(label)\n","        return labels\n","\n","    @staticmethod\n","    def evaluate_prediction_results(labels, output_predictions):\n","        dataset_labels = set()\n","        for label in labels:\n","            dataset_labels.update(set(label))\n","\n","        true_labels, predictions = [], []\n","        for sample_output in output_predictions:\n","            sample_true_labels = []\n","            sample_predicted_labels = []\n","            for token, true_label, predicted_label in sample_output:\n","                sample_true_labels.append(true_label)\n","                if predicted_label in dataset_labels:\n","                    sample_predicted_labels.append(predicted_label)\n","                else:\n","                    sample_predicted_labels.append('O')\n","            true_labels.append(sample_true_labels)\n","            predictions.append(sample_predicted_labels)\n","\n","        print(\"Test Accuracy: {}\".format(accuracy_score(true_labels, predictions)))\n","        print(\"Test Precision: {}\".format(precision_score(true_labels, predictions)))\n","        print(\"Test Recall: {}\".format(recall_score(true_labels, predictions)))\n","        print(\"Test F1-Score: {}\".format(f1_score(true_labels, predictions)))\n","        print(\"Test classification Report:\\n{}\".format(classification_report(true_labels, predictions, digits=2)))\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"YW_jzz56hEUI","colab":{"base_uri":"https://localhost:8080/","height":358,"referenced_widgets":["979875c66b474222a3a61cee5c34f9e9","ece6501b09c146da9480cf5553a45aee","7219fe0eb7ad42659ed98562edff32ff","e6c1feb349e24e39b82805711d3ce379","dac39fedeed949f88b74cbe5ddd9870e","519fb7eb900540f6bdd69a4a1e91f727","fd9163a94c1f4bc297ae06b292737eb4","b5f7143c626d4d7a9f2897359eb93161","dcaa20a75c0f47358b54d4f2252d622b","1086aa053513477394137f1459620abd","7a1f16c965e6456ebadb5b46dbcbd30d","dd04093e84384ef2b00f40f5cb6c0b45","4e7aa42059dc45919a1fdecb22a89b90","1900f3c1276e44bb8cd2ed3d656e36c6","bc83e69b363c4fa1ac711c704de7059d","38b82e9190ef41bf9d84367e5db452dc","52fda4bd4ed3447d9bdfdf4b30853dd7","0e598f9aadaa4e0fa1fb842d82049adf","142cbb7c68974044a415b868f253e53d","0690845d415c48cd91451c725b76496b","207c4e6afc2240fe977efb58f51552dd","bc07fac861de4c3ab5bb386c4709c175","b64bb9777cf4437d86a30b83ad9a00bc","fc4d48a4347e45709adcabc3fafe2b72","33f982c6220349f1a6e585090f38c460","fe2f8c573a4d42bd96317807f9f56abf","74e9991fe0a142f8bd4c2abb20bbd21a","126e1ea0d47249a082eebc083735fbd0","0efcf42a66294fdf92ec55c3b51dfae8","7b5d8899fc9d4860b10e87ce9369266e","dd1c813375de4785aadf1f0024dea497","37cd0f55575f43ea8b9a27e367a8ed71","4ab473eb7d1c4e679e31119f456cd6a8","266b69109448487e87f8b391563b2961","00132fc6692c43a587c7f37eb01196ab","0d20dd6a878343db9912eb12ff48d0d6","ecd99adad137492986597a9e7537050f","13ee3f1b66ea454d931cedd926774a49","b5cb20832e424224a4056debe150ba40","4b45c260ebaf413cbe1b5b8329e9dfbd","b494bc39c1bb4165afdf168f8688cd54","da3007e101bf48d099aa59ec495c7861","5b0d75d11b3f466aa2f99e9e64bd2747","dc0c08ea432f449c95a7e8f6b2a6f208","b63cd3864f1242d4bfe465104acceb7b","cde58422089d4b798b4d07f870bb28bc","b11c9af8dc0341ba84bd17aa0200aad8","4cc0e5d92cb24026a031202682b28357","382d2fa266514a47a96f332300ab107d","9a2fff6de10547dfa3f7c8cc777eab39","7be85b9e40e545ea9a010403aa6049cd","989cb4c98b8742118c644aaaccb17666","a5313d9060dd4ac78a1f900f31c3d521","88d639fed76744788f8adec52257fd16","099bd430d8674ab2ac6d4ebc0572ff34","08a4aff97a254babb1c8334506ec0d9e"]},"executionInfo":{"status":"ok","timestamp":1627132348826,"user_tz":-270,"elapsed":62675,"user":{"displayName":"Zohreh Fallah","photoUrl":"","userId":"16168249174167062064"}},"outputId":"5eec44d1-6f4f-486f-c88a-176f2d826d13"},"source":["model_name='HooshvareLab/roberta-fa-zwnj-base-ner'\n","ner_model = NER(model_name)"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"979875c66b474222a3a61cee5c34f9e9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1425.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dcaa20a75c0f47358b54d4f2252d622b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1159342.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52fda4bd4ed3447d9bdfdf4b30853dd7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=875476.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33f982c6220349f1a6e585090f38c460","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2749025.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ab473eb7d1c4e679e31119f456cd6a8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=315.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b494bc39c1bb4165afdf168f8688cd54","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=358.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"382d2fa266514a47a96f332300ab107d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=470984439.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n9qODhaOhX3M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627132348826,"user_tz":-270,"elapsed":5,"user":{"displayName":"Zohreh Fallah","photoUrl":"","userId":"16168249174167062064"}},"outputId":"2cdbfd39-4082-4f33-9802-4a54feca4231"},"source":["print(ner_model.config)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForTokenClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": \"ner\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"O\",\n","    \"1\": \"B-DAT\",\n","    \"2\": \"B-EVE\",\n","    \"3\": \"B-FAC\",\n","    \"4\": \"B-LOC\",\n","    \"5\": \"B-MON\",\n","    \"6\": \"B-ORG\",\n","    \"7\": \"B-PCT\",\n","    \"8\": \"B-PER\",\n","    \"9\": \"B-PRO\",\n","    \"10\": \"B-TIM\",\n","    \"11\": \"I-DAT\",\n","    \"12\": \"I-EVE\",\n","    \"13\": \"I-FAC\",\n","    \"14\": \"I-LOC\",\n","    \"15\": \"I-MON\",\n","    \"16\": \"I-ORG\",\n","    \"17\": \"I-PCT\",\n","    \"18\": \"I-PER\",\n","    \"19\": \"I-PRO\",\n","    \"20\": \"I-TIM\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"B-DAT\": 1,\n","    \"B-EVE\": 2,\n","    \"B-FAC\": 3,\n","    \"B-LOC\": 4,\n","    \"B-MON\": 5,\n","    \"B-ORG\": 6,\n","    \"B-PCT\": 7,\n","    \"B-PER\": 8,\n","    \"B-PRO\": 9,\n","    \"B-TIM\": 10,\n","    \"I-DAT\": 11,\n","    \"I-EVE\": 12,\n","    \"I-FAC\": 13,\n","    \"I-LOC\": 14,\n","    \"I-MON\": 15,\n","    \"I-ORG\": 16,\n","    \"I-PCT\": 17,\n","    \"I-PER\": 18,\n","    \"I-PRO\": 19,\n","    \"I-TIM\": 20,\n","    \"O\": 0\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.7.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 42000\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_jH-igoeBJwl"},"source":["#### Run TensorFlow Benchmark:"]},{"cell_type":"code","metadata":{"id":"is4RXwP9-sNf"},"source":["from transformers import TensorFlowBenchmark, TensorFlowBenchmarkArguments\n","args = TensorFlowBenchmarkArguments(models=[model_name], batch_sizes=[1, 2, 4, 8, 16, 32, 64, 128], sequence_lengths=[8, 16, 32, 64, 128, 256, 512], multi_process=False)\n","benchmark = TensorFlowBenchmark(args)\n","results = benchmark.run()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v2OwxyjoT5Ca"},"source":["#### Sample Inference:"]},{"cell_type":"code","metadata":{"id":"ko6xK1pVhX6y","executionInfo":{"status":"ok","timestamp":1627132375714,"user_tz":-270,"elapsed":817,"user":{"displayName":"Zohreh Fallah","photoUrl":"","userId":"16168249174167062064"}}},"source":["texts = [\n","    \"مدیرکل محیط زیست استان البرز با بیان اینکه با بیان اینکه موضوع شیرابه‌های زباله‌های انتقال یافته در منطقه حلقه دره خطری برای این استان است، گفت: در این مورد گزارشاتی در ۲۵ مرداد ۱۳۹۷ تقدیم مدیران استان شده است.\",\n","    \"به گزارش خبرگزاری تسنیم از کرج، حسین محمدی در نشست خبری مشترک با معاون خدمات شهری شهرداری کرج که با حضور مدیرعامل سازمان‌های پسماند، پارک‌ها و فضای سبز و نماینده منابع طبیعی در سالن کنفرانس شهرداری کرج برگزار شد، اظهار داشت: ۸۰٪  جمعیت استان البرز در کلانشهر کرج زندگی می‌کنند.\",\n","    \"وی افزود: با همکاری‌های مشترک بین اداره کل محیط زیست و شهرداری کرج برنامه‌های مشترکی برای حفاظت از محیط زیست در شهر کرج در دستور کار قرار گرفته که این اقدامات آثار مثبتی داشته و تاکنون نزدیک به ۱۰۰ میلیارد هزینه جهت خریداری اکس-ریس صورت گرفته است.\",\n","]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"g3qS9vSHjgu5","executionInfo":{"status":"ok","timestamp":1627132390134,"user_tz":-270,"elapsed":9608,"user":{"displayName":"Zohreh Fallah","photoUrl":"","userId":"16168249174167062064"}}},"source":["inference_output = ner_model.ner_inference(texts, device, ner_model.config.max_position_embeddings)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_rIxhweIJqdC","executionInfo":{"status":"ok","timestamp":1627132441836,"user_tz":-270,"elapsed":770,"user":{"displayName":"Zohreh Fallah","photoUrl":"","userId":"16168249174167062064"}},"outputId":"462f0e7d-e881-419b-cca8-759ab97dcbe2"},"source":["print(inference_output)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[[('<s>', 'O'), ('ĠÙħØ¯ÛĮØ±Ú©ÙĦ', 'O'), ('ĠÙħØŃÛĮØ·', 'B-ORG'), ('ĠØ²ÛĮØ³Øª', 'I-ORG'), ('ĠØ§Ø³ØªØ§ÙĨ', 'I-ORG'), ('ĠØ§ÙĦØ¨Ø±Ø²', 'I-ORG'), ('ĠØ¨Ø§', 'O'), ('ĠØ¨ÛĮØ§ÙĨ', 'O'), ('ĠØ§ÛĮÙĨÚ©Ùĩ', 'O'), ('ĠØ¨Ø§', 'O'), ('ĠØ¨ÛĮØ§ÙĨ', 'O'), ('ĠØ§ÛĮÙĨÚ©Ùĩ', 'O'), ('ĠÙħÙĪØ¶ÙĪØ¹', 'O'), ('ĠØ´ÛĮØ±', 'O'), ('Ø§Ø¨Ùĩ', 'O'), ('âĢĮ', 'O'), ('ÙĩØ§ÛĮ', 'O'), ('ĠØ²Ø¨Ø§ÙĦÙĩ', 'O'), ('âĢĮ', 'O'), ('ÙĩØ§ÛĮ', 'O'), ('ĠØ§ÙĨØªÙĤØ§ÙĦ', 'O'), ('ĠÛĮØ§ÙģØªÙĩ', 'O'), ('ĠØ¯Ø±', 'O'), ('ĠÙħÙĨØ·ÙĤÙĩ', 'B-LOC'), ('ĠØŃÙĦÙĤÙĩ', 'I-LOC'), ('ĠØ¯Ø±Ùĩ', 'I-LOC'), ('ĠØ®Ø·Ø±ÛĮ', 'O'), ('ĠØ¨Ø±Ø§ÛĮ', 'O'), ('ĠØ§ÛĮÙĨ', 'O'), ('ĠØ§Ø³ØªØ§ÙĨ', 'O'), ('ĠØ§Ø³Øª', 'O'), ('ØĮ', 'O'), ('ĠÚ¯ÙģØª', 'O'), (':', 'O'), ('ĠØ¯Ø±', 'O'), ('ĠØ§ÛĮÙĨ', 'O'), ('ĠÙħÙĪØ±Ø¯', 'O'), ('ĠÚ¯Ø²Ø§Ø±Ø´Ø§ØªÛĮ', 'O'), ('ĠØ¯Ø±', 'O'), ('ĠÛ²Ûµ', 'B-DAT'), ('ĠÙħØ±Ø¯Ø§Ø¯', 'I-DAT'), ('ĠÛ±Û³Û¹Û·', 'I-DAT'), ('ĠØªÙĤØ¯ÛĮÙħ', 'O'), ('ĠÙħØ¯ÛĮØ±Ø§ÙĨ', 'O'), ('ĠØ§Ø³ØªØ§ÙĨ', 'O'), ('ĠØ´Ø¯Ùĩ', 'O'), ('ĠØ§Ø³Øª', 'O'), ('.', 'O'), ('</s>', 'O')], [('<s>', 'O'), ('ĠØ¨Ùĩ', 'O'), ('ĠÚ¯Ø²Ø§Ø±Ø´', 'O'), ('ĠØ®Ø¨Ø±Ú¯Ø²Ø§Ø±ÛĮ', 'B-ORG'), ('ĠØªØ³ÙĨÛĮÙħ', 'I-ORG'), ('ĠØ§Ø²', 'O'), ('ĠÚ©Ø±Ø¬', 'B-LOC'), ('ØĮ', 'O'), ('ĠØŃØ³ÛĮÙĨ', 'B-PER'), ('ĠÙħØŃÙħØ¯ÛĮ', 'I-PER'), ('ĠØ¯Ø±', 'O'), ('ĠÙĨØ´Ø³Øª', 'O'), ('ĠØ®Ø¨Ø±ÛĮ', 'O'), ('ĠÙħØ´ØªØ±Ú©', 'O'), ('ĠØ¨Ø§', 'O'), ('ĠÙħØ¹Ø§ÙĪÙĨ', 'O'), ('ĠØ®Ø¯ÙħØ§Øª', 'O'), ('ĠØ´ÙĩØ±ÛĮ', 'O'), ('ĠØ´ÙĩØ±Ø¯Ø§Ø±ÛĮ', 'B-ORG'), ('ĠÚ©Ø±Ø¬', 'I-ORG'), ('ĠÚ©Ùĩ', 'O'), ('ĠØ¨Ø§', 'O'), ('ĠØŃØ¶ÙĪØ±', 'O'), ('ĠÙħØ¯ÛĮØ±Ø¹Ø§ÙħÙĦ', 'O'), ('ĠØ³Ø§Ø²ÙħØ§ÙĨ', 'O'), ('âĢĮ', 'O'), ('ÙĩØ§ÛĮ', 'O'), ('ĠÙ¾Ø³ÙħØ§ÙĨØ¯', 'O'), ('ØĮ', 'O'), ('ĠÙ¾Ø§Ø±Ú©', 'O'), ('âĢĮ', 'O'), ('ÙĩØ§', 'O'), ('ĠÙĪ', 'O'), ('ĠÙģØ¶Ø§ÛĮ', 'O'), ('ĠØ³Ø¨Ø²', 'O'), ('ĠÙĪ', 'O'), ('ĠÙĨÙħØ§ÛĮÙĨØ¯Ùĩ', 'O'), ('ĠÙħÙĨØ§Ø¨Ø¹', 'O'), ('ĠØ·Ø¨ÛĮØ¹ÛĮ', 'O'), ('ĠØ¯Ø±', 'O'), ('ĠØ³Ø§ÙĦÙĨ', 'B-LOC'), ('ĠÚ©ÙĨÙģØ±Ø§ÙĨØ³', 'I-LOC'), ('ĠØ´ÙĩØ±Ø¯Ø§Ø±ÛĮ', 'I-LOC'), ('ĠÚ©Ø±Ø¬', 'I-LOC'), ('ĠØ¨Ø±Ú¯Ø²Ø§Ø±', 'O'), ('ĠØ´Ø¯', 'O'), ('ØĮ', 'O'), ('ĠØ§Ø¸ÙĩØ§Ø±', 'O'), ('ĠØ¯Ø§Ø´Øª', 'O'), (':', 'O'), ('ĠÛ¸Û°', 'B-PCT'), ('Ùª', 'O'), ('Ġ', 'O'), ('ĠØ¬ÙħØ¹ÛĮØª', 'B-LOC'), ('ĠØ§Ø³ØªØ§ÙĨ', 'I-LOC'), ('ĠØ§ÙĦØ¨Ø±Ø²', 'O'), ('ĠØ¯Ø±', 'B-LOC'), ('ĠÚ©ÙĦØ§ÙĨØ´ÙĩØ±', 'I-LOC'), ('ĠÚ©Ø±Ø¬', 'O'), ('ĠØ²ÙĨØ¯Ú¯ÛĮ', 'O'), ('ĠÙħÛĮ', 'O'), ('âĢĮ', 'O'), ('Ú©ÙĨÙĨØ¯', 'O'), ('.', 'O')], [('<s>', 'O'), ('ĠÙĪÛĮ', 'O'), ('ĠØ§ÙģØ²ÙĪØ¯', 'O'), (':', 'O'), ('ĠØ¨Ø§', 'O'), ('ĠÙĩÙħÚ©Ø§Ø±ÛĮ', 'O'), ('âĢĮ', 'O'), ('ÙĩØ§ÛĮ', 'O'), ('ĠÙħØ´ØªØ±Ú©', 'O'), ('ĠØ¨ÛĮÙĨ', 'O'), ('ĠØ§Ø¯Ø§Ø±Ùĩ', 'B-ORG'), ('ĠÚ©ÙĦ', 'I-ORG'), ('ĠÙħØŃÛĮØ·', 'I-ORG'), ('ĠØ²ÛĮØ³Øª', 'I-ORG'), ('ĠÙĪ', 'O'), ('ĠØ´ÙĩØ±Ø¯Ø§Ø±ÛĮ', 'B-ORG'), ('ĠÚ©Ø±Ø¬', 'I-ORG'), ('ĠØ¨Ø±ÙĨØ§ÙħÙĩ', 'O'), ('âĢĮ', 'O'), ('ÙĩØ§ÛĮ', 'O'), ('ĠÙħØ´ØªØ±Ú©ÛĮ', 'O'), ('ĠØ¨Ø±Ø§ÛĮ', 'O'), ('ĠØŃÙģØ§Ø¸Øª', 'O'), ('ĠØ§Ø²', 'O'), ('ĠÙħØŃÛĮØ·', 'O'), ('ĠØ²ÛĮØ³Øª', 'O'), ('ĠØ¯Ø±', 'O'), ('ĠØ´ÙĩØ±', 'B-LOC'), ('ĠÚ©Ø±Ø¬', 'I-LOC'), ('ĠØ¯Ø±', 'O'), ('ĠØ¯Ø³ØªÙĪØ±', 'O'), ('ĠÚ©Ø§Ø±', 'O'), ('ĠÙĤØ±Ø§Ø±', 'O'), ('ĠÚ¯Ø±ÙģØªÙĩ', 'O'), ('ĠÚ©Ùĩ', 'O'), ('ĠØ§ÛĮÙĨ', 'O'), ('ĠØ§ÙĤØ¯Ø§ÙħØ§Øª', 'O'), ('ĠØ¢Ø«Ø§Ø±', 'O'), ('ĠÙħØ«Ø¨ØªÛĮ', 'O'), ('ĠØ¯Ø§Ø´ØªÙĩ', 'O'), ('ĠÙĪ', 'O'), ('ĠØªØ§Ú©ÙĨÙĪÙĨ', 'O'), ('ĠÙĨØ²Ø¯ÛĮÚ©', 'O'), ('ĠØ¨Ùĩ', 'O'), ('ĠÛ±Û°Û°', 'O'), ('ĠÙħÛĮÙĦÛĮØ§Ø±Ø¯', 'O'), ('ĠÙĩØ²ÛĮÙĨÙĩ', 'O'), ('ĠØ¬ÙĩØª', 'O'), ('ĠØ®Ø±ÛĮØ¯Ø§Ø±ÛĮ', 'O'), ('ĠØ§Ú©Ø³', 'O'), ('-', 'O'), ('Ø±ÛĮØ³', 'O'), ('ĠØµÙĪØ±Øª', 'O'), ('ĠÚ¯Ø±ÙģØªÙĩ', 'O'), ('ĠØ§Ø³Øª', 'O'), ('.', 'O'), ('</s>', 'O')]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":582,"referenced_widgets":["609a50dd9c754b558af106f4723fcd90","100b281528234c93a7ed7bdfa2102e84","04d9a3be9df8498b931eada451ac92d0","a9c37d5cbc72421e80025fa94c7a3b4b","a8b8d1914d3c484495e906016479a54b","633b90f3cb574ba7a8427d9de08177a4","f5fc43ae93984a4a8646133a316d2701","5d49c86a084d4c6cad5ed37a758e805e"]},"id":"IPfFv0GJeWy8","executionInfo":{"status":"ok","timestamp":1627132449969,"user_tz":-270,"elapsed":1184,"user":{"displayName":"Zohreh Fallah","photoUrl":"","userId":"16168249174167062064"}},"outputId":"f1ba820c-25e8-489e-95e4-1f619f943dca"},"source":["#@title Live Playground { display-mode: \"form\" }\n","\n","css_is_load = False\n","css = \"\"\"<style>\n",".ner-box {\n","    direction: rtl;\n","    font-size: 18px !important;\n","    line-height: 20px !important;\n","    margin: 0 0 15px;\n","    padding: 10px;\n","    text-align: justify;\n","    color: #343434 !important;\n","}\n",".token, .token span {\n","    display: inline-block !important;\n","    padding: 2px;\n","    margin: 2px 0;\n","}\n",".token.token-ner {\n","    background-color: #f6cd61;\n","    font-weight: bold;\n","    color: #000;\n","}\n",".token.token-ner .ner-label {\n","    color: #9a1f40;\n","    margin: 0px 2px;\n","}\n","</style>\"\"\"\n","\n","if not css_is_load:\n","    display(HTML(css))\n","    css_is_load = True\n","\n","submit_wd = widgets.Button(description='Send', disabled=False, button_style='success', tooltip='Submit')\n","text_wd = widgets.Textarea(placeholder='Please enter you text ...', rows=5, layout=Layout(width='90%'))\n","output_wd = widgets.Output()\n","\n","display(HTML(\"\"\"\n","<h2>Test NER model</h2>\n","<p style=\"padding: 2px 20px; margin: 0 0 20px;\">\n","</p>\n","<br /><br />\n","\"\"\"))\n","\n","display(text_wd)\n","display(submit_wd)\n","display(output_wd)\n","\n","def submit_text(sender):\n","    with output_wd:\n","        clear_output(wait=True)\n","        text = text_wd.value\n","        _output = ner_model.ner_inference([text], device, ner_model.config.max_position_embeddings)\n","        # print(_output)\n","        pred_sequence = []\n","        for token, label in _output[0]:\n","            if token not in ['[CLS]', '[SEP]']:\n","                if label != 'O':\n","                    pred_sequence.append(\n","                        '<span class=\"token token-ner\">%s<span class=\"ner-label\">%s</span></span>' \n","                        % (token, label))\n","                else:\n","                    pred_sequence.append(\n","                        '<span class=\"token\">%s</span>' \n","                        % token)\n","            \n","        html = '<p class=\"ner-box\">%s</p>' % ' '.join(pred_sequence) \n","        display(HTML(html))\n","\n","submit_wd.on_click(submit_text)"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/html":["<style>\n",".ner-box {\n","    direction: rtl;\n","    font-size: 18px !important;\n","    line-height: 20px !important;\n","    margin: 0 0 15px;\n","    padding: 10px;\n","    text-align: justify;\n","    color: #343434 !important;\n","}\n",".token, .token span {\n","    display: inline-block !important;\n","    padding: 2px;\n","    margin: 2px 0;\n","}\n",".token.token-ner {\n","    background-color: #f6cd61;\n","    font-weight: bold;\n","    color: #000;\n","}\n",".token.token-ner .ner-label {\n","    color: #9a1f40;\n","    margin: 0px 2px;\n","}\n","</style>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","<h2>Test NER model</h2>\n","<p style=\"padding: 2px 20px; margin: 0 0 20px;\">\n","</p>\n","<br /><br />\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"609a50dd9c754b558af106f4723fcd90","version_minor":0,"version_major":2},"text/plain":["Textarea(value='', layout=Layout(width='90%'), placeholder='Please enter you text ...', rows=5)"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9c37d5cbc72421e80025fa94c7a3b4b","version_minor":0,"version_major":2},"text/plain":["Button(button_style='success', description='Send', style=ButtonStyle(), tooltip='Submit')"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f5fc43ae93984a4a8646133a316d2701","version_minor":0,"version_major":2},"text/plain":["Output()"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"zKu4SZobohCq"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHTWTvbwog-u"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4YaptthPog1h"},"source":[""],"execution_count":null,"outputs":[]}]}