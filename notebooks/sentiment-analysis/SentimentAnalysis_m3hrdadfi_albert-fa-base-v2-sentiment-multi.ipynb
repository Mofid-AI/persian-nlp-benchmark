{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SentimentAnalysis/m3hrdadfi/albert-fa-base-v2-sentiment-multi.ipynb","provenance":[{"file_id":"1obI0XMxzhnotCcL49GlOHQIpbtnvo2HC","timestamp":1624943610213}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8051f021b71043fab2196137dfe69cd2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fd3480108d5d46fe8a97e44ccaa76d6d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_41a4d8581f5f4236999a772f63518d5c","IPY_MODEL_73b8f1e087514cb0990cd0e8b26f72fe"]}},"fd3480108d5d46fe8a97e44ccaa76d6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"41a4d8581f5f4236999a772f63518d5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cbbf9c6b977e4005afd3b130fc88db0a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2eefb86d3e6546b5b307bffc28e4ec6c"}},"73b8f1e087514cb0990cd0e8b26f72fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_29f2ee6a19e24ba0ab730ba46e2139f0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 898/898 [00:00&lt;00:00, 17.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_60eba4e302d44283904310cb4dd53fee"}},"cbbf9c6b977e4005afd3b130fc88db0a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2eefb86d3e6546b5b307bffc28e4ec6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"29f2ee6a19e24ba0ab730ba46e2139f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"60eba4e302d44283904310cb4dd53fee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4fdaa5cf069a4fbeb561ca32fe854a58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d239f5fae46947cebbc426a70a406ed2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ffd2a4159fb74bdeaa19e181b90cc1df","IPY_MODEL_54605287e6674d26b1a54ee28a979166"]}},"d239f5fae46947cebbc426a70a406ed2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ffd2a4159fb74bdeaa19e181b90cc1df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_01427d5ff1da4ad8b01f05e561178f7e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1882978,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1882978,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_81355772cba348bc9072801e0e86a8c2"}},"54605287e6674d26b1a54ee28a979166":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5c13def4959f4c4eae75cd46f64ded3a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.88M/1.88M [00:02&lt;00:00, 880kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3f52c6d00e234191b2aba62359c53ecc"}},"01427d5ff1da4ad8b01f05e561178f7e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"81355772cba348bc9072801e0e86a8c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c13def4959f4c4eae75cd46f64ded3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3f52c6d00e234191b2aba62359c53ecc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a9882af8c69d484ea9e410f4dac155ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1537d7f01e8d405ea2ec7e1bed4a23a3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0a0a4346adf34c21918117ce1d0b1fd0","IPY_MODEL_aa5699a8ec764564ba606847effa3adb"]}},"1537d7f01e8d405ea2ec7e1bed4a23a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a0a4346adf34c21918117ce1d0b1fd0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2e9b1b7c6f0c4e8894829655cba4aed4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":156,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":156,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a56e5b0fddc14e279d90c7d1f95044da"}},"aa5699a8ec764564ba606847effa3adb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c84320b37e194501a1e4cacab86d5506","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 156/156 [00:00&lt;00:00, 214B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8bef9bc735234932931c0a33ddaa883b"}},"2e9b1b7c6f0c4e8894829655cba4aed4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a56e5b0fddc14e279d90c7d1f95044da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c84320b37e194501a1e4cacab86d5506":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8bef9bc735234932931c0a33ddaa883b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b74c51d44d12416eb1980b473b2ff6a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0a160d4ce8b643d1aea5c501e4464e39","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3d8c5f0d7e4f4927a48c60451bf0bc99","IPY_MODEL_f70da8ae86b546c8aa158fcf85ba29b1"]}},"0a160d4ce8b643d1aea5c501e4464e39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d8c5f0d7e4f4927a48c60451bf0bc99":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d64788268a40478384225e0971682370","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":62,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":62,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cb16389467864f1fa40bf4fdd8d3c5fe"}},"f70da8ae86b546c8aa158fcf85ba29b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8eb62c32c607458d91ba908e1c69d710","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 62.0/62.0 [00:00&lt;00:00, 303B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ad3757d8c71f40d89973e3789da563de"}},"d64788268a40478384225e0971682370":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cb16389467864f1fa40bf4fdd8d3c5fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8eb62c32c607458d91ba908e1c69d710":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ad3757d8c71f40d89973e3789da563de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a821d6170e94e718c475f2d1eb912cc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a66ee32a38014d318da18b538a26c7fb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d59c2c5127d448dcbf6b5fa6233b9ce2","IPY_MODEL_1f07d58452cd49e48bb7260d74e380a9"]}},"a66ee32a38014d318da18b538a26c7fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d59c2c5127d448dcbf6b5fa6233b9ce2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d89b9be8ae114573825800389f829d2a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":72349964,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":72349964,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_86d623d65fa84793912e49b6e99709a5"}},"1f07d58452cd49e48bb7260d74e380a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dadb2a1aa1e745a38b59a833e681b9a4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 72.3M/72.3M [00:01&lt;00:00, 46.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e0bd1ad0f195497c96064f6a9807fbad"}},"d89b9be8ae114573825800389f829d2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"86d623d65fa84793912e49b6e99709a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dadb2a1aa1e745a38b59a833e681b9a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e0bd1ad0f195497c96064f6a9807fbad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"EVTLnae70XUx"},"source":["# Persian Sentiment\n","It aims to classify text, such as comments, based on their emotional bias. We tested three well-known datasets for this task: **Digikala** user comments, **SnappFood** user comments, and **DeepSentiPers** in two binary-form and multi-form types.\n"]},{"cell_type":"code","metadata":{"id":"o_zHi1zlwyXb"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4knw0YgC0SfX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627904853823,"user_tz":-270,"elapsed":28433,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"c101bc31-4807-4fd5-fb79-38d5584d7a0b"},"source":["!pip install hazm==0.7.0\n","!pip install seqeval==1.2.2\n","!pip install sentencepiece==0.1.96\n","!pip install transformers==4.7.0\n","!pip install clean-text[gpl]==0.4.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting hazm==0.7.0\n","  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 23.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 51 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 61 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 71 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 81 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 92 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 102 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 112 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 122 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 133 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 143 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 153 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 163 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 174 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 184 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 194 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 204 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 215 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 225 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 235 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 245 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 256 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 266 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 276 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 286 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 296 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 307 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 316 kB 7.8 MB/s \n","\u001b[?25hCollecting libwapiti>=0.2.1\n","  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n","\u001b[K     |████████████████████████████████| 233 kB 13.5 MB/s \n","\u001b[?25hCollecting nltk==3.3\n","  Downloading nltk-3.3.0.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 16.5 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm==0.7.0) (1.15.0)\n","Building wheels for collected packages: nltk, libwapiti\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394487 sha256=30394f1b77752b96992b8d1a79a069292bc187c9a898813482a10d5e1321bc6e\n","  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n","  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154536 sha256=47f2a1db827a000196b48af5bc7ea304c11449e2c74b75f1b0fb272d52dfcb59\n","  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n","Successfully built nltk libwapiti\n","Installing collected packages: nltk, libwapiti, hazm\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n","Collecting seqeval==1.2.2\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.4.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=84f14da95b94538b5fcd7e8c39a671614cfdc28a95c1c63b4595a92ff064b525\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Collecting sentencepiece==0.1.96\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 7.6 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting transformers==4.7.0\n","  Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (21.0)\n","Collecting huggingface-hub==0.0.8\n","  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (2.23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 46.7 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (4.6.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (4.41.1)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 38.2 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (3.13)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0) (3.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.7.0) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (2021.5.30)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (1.15.0)\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.7.0\n","Collecting clean-text[gpl]==0.4.0\n","  Downloading clean_text-0.4.0-py3-none-any.whl (9.8 kB)\n","Collecting ftfy<7.0,>=6.0\n","  Downloading ftfy-6.0.3.tar.gz (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 2.6 MB/s \n","\u001b[?25hCollecting emoji\n","  Downloading emoji-1.4.2.tar.gz (184 kB)\n","\u001b[K     |████████████████████████████████| 184 kB 15.0 MB/s \n","\u001b[?25hCollecting unidecode<2.0.0,>=1.1.1\n","  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n","\u001b[K     |████████████████████████████████| 241 kB 57.1 MB/s \n","\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy<7.0,>=6.0->clean-text[gpl]==0.4.0) (0.2.5)\n","Building wheels for collected packages: ftfy, emoji\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41934 sha256=abe8000841cbd50025f2f36a71a1338c84f0d75cc922b7b33b9771f3ab601359\n","  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186469 sha256=08a5718cbc7e72ae9c983efd9ec21aba1f0ad67f7eaf8d36ba3069ad026d39e2\n","  Stored in directory: /root/.cache/pip/wheels/e4/61/e7/2fc1ac8f306848fc66c6c013ab511f0a39ef4b1825b11363b2\n","Successfully built ftfy emoji\n","Installing collected packages: ftfy, emoji, unidecode, clean-text\n","Successfully installed clean-text-0.4.0 emoji-1.4.2 ftfy-6.0.3 unidecode-1.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rS4Rw-0iYEtd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627904911856,"user_tz":-270,"elapsed":58039,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"c55741fd-4fa9-4843-d9dd-6ae3b4394372"},"source":["!pip install PyDrive\n","import os\n","import IPython.display as ipd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: PyDrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (1.12.8)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.32.1)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.26.3)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.53.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (57.2.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.23.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2018.9)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (21.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.17.3)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.7.2)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.24.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HjQo6WGZ2aK5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627904920233,"user_tz":-270,"elapsed":6124,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"7c18f9a3-05d2-4d01-9f3a-d954ad3b5f50"},"source":["# Import required packages\n","import os\n","import gc\n","import re\n","import hazm\n","import time\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","import transformers\n","from transformers import AutoConfig, AutoTokenizer\n","from transformers import AutoModelForSequenceClassification\n","\n","from cleantext import clean\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","\n","print()\n","print('numpy', np.__version__)\n","print('pandas', pd.__version__)\n","print('transformers', transformers.__version__)\n","print('torch', torch.__version__)\n","print()\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","numpy 1.19.5\n","pandas 1.1.5\n","transformers 4.7.0\n","torch 1.9.0+cu102\n","\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5vC31D-N0Shj"},"source":["class SentimentAnalysisDataset(torch.utils.data.Dataset):\n","    \"\"\" Create a PyTorch dataset for Sentiment Analysis. \"\"\"\n","\n","    def __init__(self, tokenizer, comments, targets, label_list=None, max_len=128):\n","        self.comments = comments\n","        self.targets = targets\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        self.label2index = {label: i for i, label in enumerate(label_list)} if isinstance(label_list, list) else {}\n","        self.index2label = {i: label for label, i in self.label2index.items()}\n","\n","    def __len__(self):\n","        return len(self.comments)\n","\n","    def __getitem__(self, item):\n","        comment = self.comments[item]\n","        target = self.label2index[self.targets[item]]\n","        encoding = self.tokenizer.encode_plus(\n","            comment,\n","            add_special_tokens=True,\n","            truncation=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_tensors='pt')\n","\n","        inputs = {\n","            'comment': comment,\n","            'targets': torch.tensor(target, dtype=torch.long),\n","            'original_targets': self.targets[item],\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'token_type_ids': encoding['token_type_ids'].flatten(),\n","        }\n","\n","        return inputs\n","\n","\n","class MT5SentimentAnalysisDataset(torch.utils.data.Dataset):\n","    \"\"\" Create a PyTorch dataset for Sentiment Analysis. \"\"\"\n","\n","    def __init__(self, reviews, aspects, labels, tokenizer, max_length=128):\n","        self.reviews = reviews\n","        self.aspects = aspects\n","        self.targets = labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.reviews)\n","\n","    def __getitem__(self, item):\n","        if self.aspects is not None:\n","            encoding = self.tokenizer(\n","                self.reviews[item] + \" <sep> \" + self.aspects[item],\n","                add_special_tokens=True,\n","                max_length=self.max_length,\n","                truncation=True,\n","                padding='max_length',\n","                return_tensors=\"pt\"\n","            )\n","            inputs = {\n","                'review': self.reviews[item],\n","                'aspects': self.aspects[item],\n","                'targets': self.targets[item],\n","                'input_ids': encoding['input_ids'].flatten(),\n","                'attention_mask': encoding['attention_mask'].flatten()\n","            }\n","        else:\n","            encoding = self.tokenizer(\n","                self.reviews[item],\n","                add_special_tokens=True,\n","                max_length=self.max_length,\n","                truncation=True,\n","                padding='max_length',\n","                return_tensors=\"pt\"\n","            )\n","            inputs = {\n","                'review': self.reviews[item],\n","                'targets': self.targets[item],\n","                'input_ids': encoding['input_ids'].flatten(),\n","                'attention_mask': encoding['attention_mask'].flatten()\n","            }\n","\n","        return inputs\n","\n","\n","class SentimentAnalysis:\n","    def __init__(self, model_name, model_type=None):\n","        self.normalizer = hazm.Normalizer()\n","        self.model_name = model_name\n","        if model_type == \"mt5\":\n","            self.tokenizer = MT5Tokenizer.from_pretrained(model_name)\n","            self.model = MT5ForConditionalGeneration.from_pretrained(model_name)\n","            self.config = MT5Config.from_pretrained(self.model_name)\n","        else:\n","            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n","            self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)\n","            self.config = AutoConfig.from_pretrained(self.model_name)\n","            self.id2label = self.config.id2label\n","            self.label2id = self.config.label2id\n","\n","    def cleaning(self, text):\n","        def cleanhtml(raw_html):\n","            clean_pattern = re.compile('<.*?>')\n","            clean_text = re.sub(clean_pattern, '', raw_html)\n","            return clean_text\n","\n","        if type(text) is not str:\n","            return None\n","\n","        text = text.strip()\n","\n","        # regular cleaning\n","        text = clean(\n","            text,\n","            fix_unicode=True,\n","            to_ascii=False,\n","            lower=True,\n","            no_line_breaks=True,\n","            no_urls=True,\n","            no_emails=True,\n","            no_phone_numbers=True,\n","            no_numbers=False,\n","            no_digits=False,\n","            no_currency_symbols=True,\n","            no_punct=False,\n","            replace_with_url=\"\",\n","            replace_with_email=\"\",\n","            replace_with_phone_number=\"\",\n","            replace_with_number=\"\",\n","            replace_with_digit=\"0\",\n","            replace_with_currency_symbol=\"\"\n","        )\n","\n","        # cleaning htmls\n","        text = cleanhtml(text)\n","\n","        # normalizing\n","        text = self.normalizer.normalize(text)\n","\n","        # removing wierd patterns\n","        wierd_pattern = re.compile(\"[\"\n","                                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","                                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","                                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","                                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                                   u\"\\U00002702-\\U000027B0\"\n","                                   u\"\\U000024C2-\\U0001F251\"\n","                                   u\"\\U0001f926-\\U0001f937\"\n","                                   u'\\U00010000-\\U0010ffff'\n","                                   u\"\\u200d\"\n","                                   u\"\\u2640-\\u2642\"\n","                                   u\"\\u2600-\\u2B55\"\n","                                   u\"\\u23cf\"\n","                                   u\"\\u23e9\"\n","                                   u\"\\u231a\"\n","                                   u\"\\u3030\"\n","                                   u\"\\ufe0f\"\n","                                   u\"\\u2069\"\n","                                   u\"\\u2066\"\n","                                   # u\"\\u200c\"\n","                                   u\"\\u2068\"\n","                                   u\"\\u2067\"\n","                                   \"]+\", flags=re.UNICODE)\n","\n","        text = wierd_pattern.sub(r'', text)\n","\n","        # removing extra spaces, hashtags\n","        text = re.sub(\"#\", \"\", text)\n","        text = re.sub(\"\\s+\", \" \", text)\n","        if text in ['', \" \"]:\n","            return None\n","        return text\n","\n","    def load_dataset_test_file(self, dataset_name, dataset_file, **kwargs):\n","        if dataset_name.lower() == \"snappfood\":\n","            if not os.path.exists(dataset_file):\n","                print(f'{dataset_file} not exists!')\n","                return\n","            data = pd.read_csv(dataset_file, delimiter=\"\\t\")\n","            # drop label_id because its not consistent with albert model labels!\n","            data = data[['comment', 'label']]\n","\n","            # cleaning comments\n","            data = data.dropna(subset=['comment'])\n","            data['comment'] = data['comment'].apply(self.cleaning)\n","            data = data.dropna(subset=['comment'])\n","\n","            if 'label_map' in kwargs:\n","                data['label'] = data['label'].apply(lambda l: kwargs['label_map'][l])\n","                data = data.dropna(subset=['label'])\n","                data = data.reset_index(drop=True)\n","\n","            data['label_id'] = data['label'].apply(lambda t: self.label2id[t])\n","            x_test, y_test = data['comment'].values.tolist(), data['label_id'].values.tolist()\n","            print(f'test part:\\n #comment: {len(x_test)}, #labels: {len(y_test)}')\n","            return x_test, y_test\n","        if dataset_name.lower() == \"deepsentipers\":\n","            if not os.path.exists(dataset_file):\n","                print(f'{dataset_file} not exists!')\n","                return\n","            if 'label_map' not in kwargs:\n","                print(\"label_map is missing!\")\n","                return\n","            data = pd.read_csv(dataset_file, delimiter=\",\", names=['comment', 'label'], header=None)\n","\n","            # cleaning comments\n","            data = data.dropna(subset=['comment'])\n","            data['comment'] = data['comment'].apply(self.cleaning)\n","            data = data.dropna(subset=['comment'])\n","\n","            # map labels\n","            label_map = kwargs['label_map']\n","            data['label'] = data['label'].apply(lambda l: label_map[l])\n","            data = data.dropna(subset=['label'])\n","            data = data.reset_index(drop=True)\n","\n","            data['label_id'] = data['label'].apply(lambda t: self.label2id[t])\n","            x_test, y_test = data['comment'].values.tolist(), data['label_id'].values.tolist()\n","            print(f'test part:\\n #comment: {len(x_test)}, #labels: {len(y_test)}')\n","            return x_test, y_test\n","        if dataset_name.lower() == \"pasinlu-aspect-sentiment\":\n","            if not os.path.exists(dataset_file):\n","                print(f'{dataset_file} not exists!')\n","                return\n","            if 'label_map' not in kwargs:\n","                print(\"label_map is missing!\")\n","                return\n","\n","            reviews, aspects, labels = [], [], []\n","            with open(dataset_file, encoding=\"utf8\") as infile:\n","                for line in infile:\n","                    json_line = json.loads(line.strip())\n","\n","                    review = json_line['review']\n","                    reviews.append(review)\n","\n","                    question = json_line['question']\n","                    aspects.append(question)\n","\n","                    label = kwargs['label_map'][json_line['label']]\n","                    labels.append(label)\n","\n","            return reviews, aspects, labels\n","\n","    def load_dataset_file(self, dataset_name, dataset_file, **kwargs):\n","        if dataset_name.lower() == \"digikala\":\n","            if not os.path.exists(dataset_file):\n","                print(f'{dataset_file} not exists!')\n","                return\n","            data = pd.read_excel(dataset_file)\n","            data = data[['comment', 'recommend']]\n","\n","            # cleaning comments\n","            data = data.dropna(subset=['comment'])\n","            data['comment'] = data['comment'].apply(self.cleaning)\n","            data = data.dropna(subset=['comment'])\n","\n","            # cleaning labels\n","            valid_labels = ['no_idea', 'not_recommended', 'recommended']\n","            data['recommend'] = data['recommend'].apply(lambda r: r if r in valid_labels else None)\n","            data = data.dropna(subset=['recommend'])\n","            if 'label_map' in kwargs:\n","                data['recommend'] = data['recommend'].apply(lambda l: kwargs['label_map'][l])\n","            data = data.dropna(subset=['recommend'])\n","            data = data.reset_index(drop=True)\n","\n","            data['label_id'] = data['recommend'].apply(lambda t: self.label2id[t])\n","\n","            x_all, y_all = data['comment'].values.tolist(), data['label_id'].values.tolist()\n","            print(f'all data: #comment: {len(x_all)}, #labels: {len(y_all)}')\n","\n","            _, test = train_test_split(data, test_size=0.1, random_state=1, stratify=data['recommend'])\n","            test = test.reset_index(drop=True)\n","            x_test, y_test = test['comment'].values.tolist(), test['label_id'].values.tolist()\n","            print(f'test part:\\n #comment: {len(x_test)}, #labels: {len(y_test)}')\n","            return x_all, y_all, x_test, y_test\n","        if dataset_name.lower() == \"pasinlu-review-sentiment\":\n","            if not os.path.exists(dataset_file):\n","                print(f'{dataset_file} not exists!')\n","                return\n","            if 'label_map' not in kwargs:\n","                print(\"label_map is missing!\")\n","                return\n","\n","            reviews, labels = [], []\n","            with open(dataset_file, encoding=\"utf8\") as infile:\n","                for line in infile:\n","                    json_line = json.loads(line.strip())\n","\n","                    review = json_line['review']\n","                    reviews.append(review)\n","\n","                    label = kwargs['label_map'][json_line['sentiment']]\n","                    labels.append(label)\n","            return reviews, labels\n","\n","    def load_dataset_composite_file(self, dataset_name, dataset_files, **kwargs):\n","        if dataset_name.lower() == \"digikala+snappfood+deepsentipers\":\n","            if sorted(list(dataset_files.keys())) != [\"deepsentipers\", \"digikala\", \"snappfood\"]:\n","                print(\"dataset_files must contains path of all three datasets\")\n","                return\n","            if 'label_map' not in kwargs:\n","                print(\"label_map is missing!\")\n","                return\n","            elif sorted(list(kwargs['label_map'].keys())) != [\"deepsentipers\", \"digikala\", \"snappfood\"]:\n","                print(\"label_map must contains label_map for all three datasets!\")\n","                return\n","            print(\"digikala dataset - we only use test set:\")\n","            _, _, x_test_digi, y_test_digi = self.load_dataset_file('digikala', dataset_files['digikala'],\n","                                                                    label_map=kwargs['label_map']['digikala'])\n","            print(\"snappfood dataset:\")\n","            x_test_snapp, y_test_snapp = self.load_dataset_test_file('snappfood', dataset_files['snappfood'],\n","                                                                     label_map=kwargs['label_map']['snappfood'])\n","            print(\"deepsentipers dataset:\")\n","            x_test_senti, y_test_senti = self.load_dataset_test_file('deepsentipers', dataset_files['deepsentipers'],\n","                                                                     label_map=kwargs['label_map']['deepsentipers'])\n","            return x_test_digi + x_test_snapp + x_test_senti, y_test_digi + y_test_snapp + y_test_senti\n","\n","    def sentiment_analysis_inference(self, input_text, device):\n","        if not self.model or not self.tokenizer or not self.id2label:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        pt_batch = self.tokenizer(\n","            input_text,\n","            padding=True,\n","            truncation=True,\n","            max_length=self.config.max_position_embeddings,\n","            return_tensors=\"pt\"\n","        )\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","        pt_batch = pt_batch.to(device)\n","\n","        pt_outputs = self.model(**pt_batch)\n","        pt_predictions = torch.argmax(F.softmax(pt_outputs.logits, dim=1), dim=1)\n","\n","        output_predictions = []\n","        for i, sentence in enumerate(input_text):\n","            output_predictions.append((sentence, self.id2label.get(pt_predictions[i].item())))\n","        return output_predictions\n","\n","    def mt5_sentiment_analysis_inference(self, reviews, device):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        tokenized_batch = self.tokenizer(\n","            reviews,\n","            padding=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        input_ids = tokenized_batch.input_ids.to(device)\n","        attention_mask = tokenized_batch.attention_mask.to(device)\n","        outputs = self.model.generate(input_ids=input_ids,\n","                                      attention_mask=attention_mask)\n","        predictions = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","        return predictions\n","\n","    def mt5_aspect_sentiment_analysis_inference(self, reviews, aspects, device):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        new_input = []\n","        for r, a in zip(reviews, aspects):\n","            new_input.append(r + \" <sep> \" + a)\n","\n","        tokenized_batch = self.tokenizer(\n","            new_input,\n","            padding=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        input_ids = tokenized_batch.input_ids.to(device)\n","        attention_mask = tokenized_batch.attention_mask.to(device)\n","        outputs = self.model.generate(input_ids=input_ids,\n","                                      attention_mask=attention_mask)\n","        predictions = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","        return predictions\n","\n","    def evaluation(self, input_text, input_labels, device, batch_size=4):\n","        if not self.model or not self.tokenizer or not self.id2label:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        max_len = self.config.max_position_embeddings\n","        label_list = list(set(input_labels))\n","        label_count = {self.id2label[label]: input_labels.count(label) for label in label_list}\n","        print(\"label_count:\", label_count)\n","        dataset = SentimentAnalysisDataset(comments=input_text, targets=input_labels, tokenizer=self.tokenizer,\n","                                           max_len=max_len, label_list=label_list)\n","        data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n","\n","        print(\"#samples:\", len(input_text))\n","        print(\"#batch:\", len(data_loader))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        total_loss, total_time = 0, 0\n","        output_predictions = []\n","        golden_labels, predicted_labels = [], []\n","        print(\"Start to evaluate test data ...\")\n","        for step, batch in enumerate(data_loader):\n","            b_comments = batch['comment']\n","            b_input_ids = batch['input_ids']\n","            b_attention_mask = batch['attention_mask']\n","            b_token_type_ids = batch['token_type_ids']\n","            b_targets = batch['targets']\n","\n","            # move tensors to GPU if CUDA is available\n","            b_input_ids = b_input_ids.to(device)\n","            b_attention_mask = b_attention_mask.to(device)\n","            b_token_type_ids = b_token_type_ids.to(device)\n","            b_targets = b_targets.to(device)\n","\n","            # This will return the loss (rather than the model output) because we have provided the `labels`.\n","            with torch.no_grad():\n","                start = time.monotonic()\n","                b_outputs = self.model(input_ids=b_input_ids, attention_mask=b_attention_mask,\n","                                       token_type_ids=b_token_type_ids, labels=b_targets)\n","                end = time.monotonic()\n","                total_time += end - start\n","                print(f'inference time for step {step}: {end - start}')\n","            # get the loss\n","            total_loss += b_outputs.loss.item()\n","\n","            b_original_targets = batch['original_targets']\n","            golden_labels.extend(b_original_targets.tolist())\n","\n","            b_predictions = torch.argmax(F.softmax(b_outputs.logits, dim=1), dim=1)\n","            b_predictions = b_predictions.cpu().detach().numpy().tolist()\n","            b_predictions = [dataset.index2label[label] for label in b_predictions]\n","            predicted_labels.extend(b_predictions)\n","\n","            for i, comment in enumerate(b_comments):\n","                output_predictions.append((\n","                    comment,\n","                    self.id2label[b_original_targets[i].item()],\n","                    self.id2label[b_predictions[i]]\n","                ))\n","                # print(f'output prediction: {i},{comment},{self.id2label[b_original_targets[i].item()]},'\n","                #       f'{self.id2label[b_predictions[i]]}')\n","\n","        # Calculate the average loss over the training data.\n","        avg_train_loss = total_loss / len(data_loader)\n","        print(\"average loss:\", avg_train_loss)\n","        print(\"total inference time:\", total_time)\n","        print(\"total inference time / #samples:\", total_time / len(input_text))\n","\n","        # evaluate\n","        print(\"Test Accuracy: {}\".format(accuracy_score(golden_labels, predicted_labels)))\n","        print(\"Test Precision: {}\".format(precision_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test Recall: {}\".format(recall_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test F1-Score(weighted average): {}\".format(\n","            f1_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test classification Report:\\n{}\".format(classification_report(\n","            golden_labels, predicted_labels, digits=10, target_names=[self.id2label[_] for _ in sorted(label_list)])))\n","        return output_predictions\n","\n","    def mt5_sentiment_analysis_evaluation(self, reviews, labels, device, max_length, batch_size=4):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","        if len(reviews) != len(labels):\n","            print('length of inputs and labels is not equal!!')\n","            return\n","\n","        dataset = MT5SentimentAnalysisDataset(reviews=reviews, aspects=None, labels=labels, tokenizer=self.tokenizer,\n","                                              max_length=max_length)\n","        data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n","        print(f'#reviews:{len(reviews)}, #labels:{len(labels)}')\n","        print(\"#batch:\", len(data_loader))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        total_time = 0\n","        output_predictions = []\n","        golden_labels, predicted_labels = [], []\n","        print(\"Start to evaluate test data ...\")\n","        for step, batch in enumerate(data_loader):\n","            # move tensors to GPU if CUDA is available\n","            b_input_ids = batch['input_ids'].to(device)\n","            b_attention_mask = batch['attention_mask'].to(device)\n","\n","            # This will return the loss (rather than the model output) because we have provided the `labels`.\n","            with torch.no_grad():\n","                start = time.monotonic()\n","                b_outputs = self.model.generate(input_ids=b_input_ids, attention_mask=b_attention_mask)\n","                end = time.monotonic()\n","                total_time += end - start\n","                print(f'inference time for step {step}: {end - start}')\n","\n","            b_targets = batch['targets']\n","            golden_labels.extend(b_targets)\n","\n","            b_predictions = self.tokenizer.batch_decode(b_outputs, skip_special_tokens=True)\n","            predicted_labels.extend(b_predictions)\n","\n","            for i, review in enumerate(batch['review']):\n","                output_predictions.append((\n","                    review,\n","                    b_targets[i],\n","                    b_predictions[i]\n","                ))\n","\n","        print(\"total inference time:\", total_time)\n","        print(\"total inference time / #samples:\", total_time / len(reviews))\n","\n","        # evaluate\n","        print(\"Test Accuracy: {}\".format(accuracy_score(golden_labels, predicted_labels)))\n","        print(\"Test Precision: {}\".format(precision_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test Recall: {}\".format(recall_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test F1-Score(weighted average): {}\".format(\n","            f1_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test classification Report:\\n{}\".format(\n","            classification_report(golden_labels, predicted_labels, digits=10)))\n","        return output_predictions\n","\n","    def mt5_aspect_sentiment_analysis_evaluation(self, reviews, aspects, labels, device, max_length, batch_size=4):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","        if len(reviews) != len(labels):\n","            print('length of inputs and labels is not equal!!')\n","            return\n","\n","        dataset = MT5SentimentAnalysisDataset(reviews=reviews, aspects=aspects, labels=labels, tokenizer=self.tokenizer,\n","                                              max_length=max_length)\n","        data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n","        print(f'#reviews:{len(reviews)}, #aspects:{len(aspects)}, #labels:{len(labels)}')\n","        print(\"#batch:\", len(data_loader))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        total_time = 0\n","        output_predictions = []\n","        golden_labels, predicted_labels = [], []\n","        print(\"Start to evaluate test data ...\")\n","        for step, batch in enumerate(data_loader):\n","            # move tensors to GPU if CUDA is available\n","            b_input_ids = batch['input_ids'].to(device)\n","            b_attention_mask = batch['attention_mask'].to(device)\n","\n","            # This will return the loss (rather than the model output) because we have provided the `labels`.\n","            with torch.no_grad():\n","                start = time.monotonic()\n","                b_outputs = self.model.generate(input_ids=b_input_ids, attention_mask=b_attention_mask)\n","                end = time.monotonic()\n","                total_time += end - start\n","                print(f'inference time for step {step}: {end - start}')\n","\n","            b_targets = batch['targets']\n","            golden_labels.extend(b_targets)\n","\n","            b_predictions = self.tokenizer.batch_decode(b_outputs, skip_special_tokens=True)\n","            predicted_labels.extend(b_predictions)\n","\n","            for i, review in enumerate(batch['review']):\n","                output_predictions.append((\n","                    review,\n","                    batch['aspects'][i],\n","                    b_targets[i],\n","                    b_predictions[i]\n","                ))\n","\n","        print(\"total inference time:\", total_time)\n","        print(\"total inference time / #samples:\", total_time / len(reviews))\n","\n","        # evaluate\n","        print(\"Test Accuracy: {}\".format(accuracy_score(golden_labels, predicted_labels)))\n","        print(\"Test Precision: {}\".format(precision_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test Recall: {}\".format(recall_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test F1-Score(weighted average): {}\".format(\n","            f1_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test classification Report:\\n{}\".format(\n","            classification_report(golden_labels, predicted_labels, digits=10)))\n","        return output_predictions\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VD0FH_FF2oTy","colab":{"base_uri":"https://localhost:8080/","height":983,"referenced_widgets":["8051f021b71043fab2196137dfe69cd2","fd3480108d5d46fe8a97e44ccaa76d6d","41a4d8581f5f4236999a772f63518d5c","73b8f1e087514cb0990cd0e8b26f72fe","cbbf9c6b977e4005afd3b130fc88db0a","2eefb86d3e6546b5b307bffc28e4ec6c","29f2ee6a19e24ba0ab730ba46e2139f0","60eba4e302d44283904310cb4dd53fee","4fdaa5cf069a4fbeb561ca32fe854a58","d239f5fae46947cebbc426a70a406ed2","ffd2a4159fb74bdeaa19e181b90cc1df","54605287e6674d26b1a54ee28a979166","01427d5ff1da4ad8b01f05e561178f7e","81355772cba348bc9072801e0e86a8c2","5c13def4959f4c4eae75cd46f64ded3a","3f52c6d00e234191b2aba62359c53ecc","a9882af8c69d484ea9e410f4dac155ae","1537d7f01e8d405ea2ec7e1bed4a23a3","0a0a4346adf34c21918117ce1d0b1fd0","aa5699a8ec764564ba606847effa3adb","2e9b1b7c6f0c4e8894829655cba4aed4","a56e5b0fddc14e279d90c7d1f95044da","c84320b37e194501a1e4cacab86d5506","8bef9bc735234932931c0a33ddaa883b","b74c51d44d12416eb1980b473b2ff6a4","0a160d4ce8b643d1aea5c501e4464e39","3d8c5f0d7e4f4927a48c60451bf0bc99","f70da8ae86b546c8aa158fcf85ba29b1","d64788268a40478384225e0971682370","cb16389467864f1fa40bf4fdd8d3c5fe","8eb62c32c607458d91ba908e1c69d710","ad3757d8c71f40d89973e3789da563de","0a821d6170e94e718c475f2d1eb912cc","a66ee32a38014d318da18b538a26c7fb","d59c2c5127d448dcbf6b5fa6233b9ce2","1f07d58452cd49e48bb7260d74e380a9","d89b9be8ae114573825800389f829d2a","86d623d65fa84793912e49b6e99709a5","dadb2a1aa1e745a38b59a833e681b9a4","e0bd1ad0f195497c96064f6a9807fbad"]},"executionInfo":{"status":"ok","timestamp":1627904929334,"user_tz":-270,"elapsed":5932,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"3a3f5dd5-565b-4666-c334-b79be1757637"},"source":["model_name='m3hrdadfi/albert-fa-base-v2-sentiment-multi'\n","sa_model = SentimentAnalysis(model_name)\n","print(sa_model.config)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8051f021b71043fab2196137dfe69cd2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4fdaa5cf069a4fbeb561ca32fe854a58","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1882978.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9882af8c69d484ea9e410f4dac155ae","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=156.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b74c51d44d12416eb1980b473b2ff6a4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=62.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a821d6170e94e718c475f2d1eb912cc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=72349964.0, style=ProgressStyle(descrip…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","AlbertConfig {\n","  \"architectures\": [\n","    \"AlbertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0,\n","  \"bos_token_id\": 2,\n","  \"classifier_dropout_prob\": 0.1,\n","  \"down_scale_factor\": 1,\n","  \"embedding_size\": 128,\n","  \"eos_token_id\": 3,\n","  \"finetuning_task\": \"alpbert-sentiment\",\n","  \"gap_size\": 0,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"Negative\",\n","    \"1\": \"Neutral\",\n","    \"2\": \"Positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"inner_group_num\": 1,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"Negative\": 0,\n","    \"Neutral\": 1,\n","    \"Positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"albert\",\n","  \"net_structure_type\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_groups\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_memory_blocks\": 0,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.7.0\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 80000\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Yv8v5YOv21Qe"},"source":["## Sample Inference:"]},{"cell_type":"code","metadata":{"id":"XrvVQdG_218P"},"source":["texts = [\n","    \"خوب نبود اصلا\",\n","    \"از رنگش خوشم نیومد\",\n","    \"کیفیتیش عالی بود\"\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZMeNJ2k23N2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627904942008,"user_tz":-270,"elapsed":12677,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"fa9b4d1a-5f4a-4ccd-b09f-57a75dcc8e06"},"source":["sa_model.sentiment_analysis_inference(texts, device)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('خوب نبود اصلا', 'Negative'),\n"," ('از رنگش خوشم نیومد', 'Neutral'),\n"," ('کیفیتیش عالی بود', 'Positive')]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"XEWiWbu621Tk"},"source":["## DeepSentiPers([paper](https://arxiv.org/pdf/2004.05328.pdf))\n","which is a balanced and augmented version of SentiPers, contains ?12,138 user opinions about digital products labeled with five different classes; two positives (i.e., happy and delighted), two negatives (i.e., furious and angry) and one neutral class. Therefore, this dataset can be utilized for both multi-class and binary classification. In the case of binary classification, the neutral class and its corresponding sentences are removed from the dataset.\n","\n","Binary:\n","1. Negative (Furious + Angry)\n","2. Positive (Happy + Delighted)\n","\n","Multi:\n","1. Furious(-2)\n","2. Angry(-1)\n","3. Neutral(0)\n","4. Happy(1)\n","5. Delighted(2)\n","\n","Test set statistics (binary version):\n","\n","|          Label         | # | \n","|:------------------------:|:-----------:|\n","|  Positive  |      915    |\n","|  Negative |      196      |\n","\n","\n","\n","\t\t\n","Download You can download the dataset from \n","* [SentiPers](https://github.com/phosseini/sentipers)\n","* [DeepSentiPers](https://github.com/JoyeBright/DeepSentiPers)"]},{"cell_type":"code","metadata":{"id":"P8YNpA6LE_6B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627904945201,"user_tz":-270,"elapsed":3199,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"3e949499-3fbe-4f67-ee96-bcdd20f25180"},"source":["!git clone https://github.com/JoyeBright/DeepSentiPers\n","!ls DeepSentiPers\n","!ls DeepSentiPers/Dataset"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'DeepSentiPers'...\n","remote: Enumerating objects: 2264, done.\u001b[K\n","remote: Counting objects: 100% (109/109), done.\u001b[K\n","remote: Compressing objects: 100% (109/109), done.\u001b[K\n","remote: Total 2264 (delta 70), reused 0 (delta 0), pack-reused 2155\u001b[K\n","Receiving objects: 100% (2264/2264), 22.02 MiB | 24.56 MiB/s, done.\n","Resolving deltas: 100% (1252/1252), done.\n"," Binary-Classification\t Dataset\t\t     README.md\n"," _config.yml\t\t Images\t\t\t     Results.xlsx\n","'Data Augmentation'\t Multiclass-Classification\n","balanced.csv  original.csv  test.csv  translation.csv\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Jxi_YYyua8ZS"},"source":["Run on `test` set:"]},{"cell_type":"code","metadata":{"id":"CJivebhsFK53","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627904945970,"user_tz":-270,"elapsed":774,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"f543b42e-2b98-498a-a434-383b92df1083"},"source":["test_comments, test_labels = sa_model.load_dataset_test_file(dataset_name=\"deepsentipers\", dataset_file=\"./DeepSentiPers/Dataset/test.csv\", label_map={-2: \"Negative\", -1: \"Negative\", 0: \"Neutral\", 1: \"Positive\", 2: \"Positive\"})\n","print(test_comments[:5])\n","print(test_labels[:5])\n","print(len(test_comments))\n","print(len(test_labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test part:\n"," #comment: 1854, #labels: 1854\n","['اندازه\\u200cی خوبی داره.', 'با این چیزا نمیتونه از galaxy s iii بهتر باشه', 'سرعت اجرا بسیار بالا است و مصرف باتری نیز مناسب است.', 'از حساسیت ۴۰۰ مقداری نویز در عکس\\u200cها مشاهده می\\u200cشود اما همچنان جزئیات عکس\\u200cها خیلی خوب پیدا هستند.', 'در کل، با اینکه عکاسی با تبلت را همواره جزو موارد غیر ضروری نامیده\\u200cایم، ولی در مورد این دستگاه برای کسانی که علاقه\\u200cمند به عکاسی نیز هستند، هواوی شرایطی را فراهم نموده است که کاملا آن\\u200cها را راضی خواهد نمود.']\n","[2, 0, 2, 2, 2]\n","1854\n","1854\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T0zWwKm6T9um","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627904946966,"user_tz":-270,"elapsed":1000,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"a8044b03-8afb-4dec-a796-b62d1acd0015"},"source":["sa_model.sentiment_analysis_inference(test_comments[:5], device)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('اندازه\\u200cی خوبی داره.', 'Neutral'),\n"," ('با این چیزا نمیتونه از galaxy s iii بهتر باشه', 'Neutral'),\n"," ('سرعت اجرا بسیار بالا است و مصرف باتری نیز مناسب است.', 'Positive'),\n"," ('از حساسیت ۴۰۰ مقداری نویز در عکس\\u200cها مشاهده می\\u200cشود اما همچنان جزئیات عکس\\u200cها خیلی خوب پیدا هستند.',\n","  'Positive'),\n"," ('در کل، با اینکه عکاسی با تبلت را همواره جزو موارد غیر ضروری نامیده\\u200cایم، ولی در مورد این دستگاه برای کسانی که علاقه\\u200cمند به عکاسی نیز هستند، هواوی شرایطی را فراهم نموده است که کاملا آن\\u200cها را راضی خواهد نمود.',\n","  'Positive')]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"SookPMv752pv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627904946966,"user_tz":-270,"elapsed":13,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"71048f5c-ab43-427e-b55b-ab1278c99bf4"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon Aug  2 11:49:06 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   57C    P0    48W /  70W |   1470MiB / 15109MiB |     17%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               79\n","Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n","Stepping:            0\n","CPU MHz:             2199.998\n","BogoMIPS:            4399.99\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            256K\n","L3 cache:            56320K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dF3g4Y0m6WTK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627905033893,"user_tz":-270,"elapsed":86931,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"267168fb-6a90-4ad7-902e-b1084cac9880"},"source":["evaluation_output = sa_model.evaluation(test_comments, test_labels, device, batch_size=128)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["label_count: {'Negative': 196, 'Neutral': 743, 'Positive': 915}\n","#samples: 1854\n","#batch: 15\n","Start to evaluate test data ...\n","inference time for step 0: 0.02272441700000627\n","inference time for step 1: 0.010685543000022335\n","inference time for step 2: 0.010327255000021296\n","inference time for step 3: 0.009933571999994228\n","inference time for step 4: 0.01110837199999537\n","inference time for step 5: 0.010860687999979746\n","inference time for step 6: 0.00962704700000927\n","inference time for step 7: 0.009863312999982554\n","inference time for step 8: 0.00974726900000178\n","inference time for step 9: 0.009487225000015087\n","inference time for step 10: 0.010244021999994857\n","inference time for step 11: 0.01054818500000465\n","inference time for step 12: 0.010153691999988723\n","inference time for step 13: 0.009866336000015963\n","inference time for step 14: 0.01124409999999898\n","average loss: 1.3437920014063518\n","total inference time: 0.1664210360000311\n","total inference time / #samples: 8.976323408847416e-05\n","Test Accuracy: 0.6779935275080906\n","Test Precision: 0.7325644826169483\n","Test Recall: 0.6779935275080906\n","Test F1-Score(weighted average): 0.6760233506873838\n","Test classification Report:\n","              precision    recall  f1-score   support\n","\n","    Negative  0.5155279503 0.4234693878 0.4649859944       196\n","     Neutral  0.5844625113 0.8707940781 0.6994594595       743\n","    Positive  0.8993174061 0.5759562842 0.7021985343       915\n","\n","    accuracy                      0.6779935275      1854\n","   macro avg  0.6664359559 0.6234065833 0.6222146627      1854\n","weighted avg  0.7325644826 0.6779935275 0.6760233507      1854\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q2WUkTiD6hBn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627905033894,"user_tz":-270,"elapsed":26,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"70c706ac-5842-4489-876c-82ce39665e72"},"source":["for comment, true_label, predicted_label in evaluation_output[:25]:\n","  print('{}\\t{}\\t{}'.format(comment, true_label, predicted_label))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["اندازه‌ی خوبی داره.\tPositive\tNeutral\n","با این چیزا نمیتونه از galaxy s iii بهتر باشه\tNegative\tNeutral\n","سرعت اجرا بسیار بالا است و مصرف باتری نیز مناسب است.\tPositive\tPositive\n","از حساسیت ۴۰۰ مقداری نویز در عکس‌ها مشاهده می‌شود اما همچنان جزئیات عکس‌ها خیلی خوب پیدا هستند.\tPositive\tPositive\n","در کل، با اینکه عکاسی با تبلت را همواره جزو موارد غیر ضروری نامیده‌ایم، ولی در مورد این دستگاه برای کسانی که علاقه‌مند به عکاسی نیز هستند، هواوی شرایطی را فراهم نموده است که کاملا آن‌ها را راضی خواهد نمود.\tPositive\tPositive\n","به هر صورت دیدن یک نمایشگری لمسی بر روی دوربینی در این رده‌ی قیمت بسیار عالیست.\tPositive\tNeutral\n","پهنای باند حافظه پهنای باندی که در حافظه‌ی موجود وجود دارد، حدود ۲۵۶ گیگابایت در ثانیه است که ارتباط سریع میان واحدها را با کمترین تاخیر مهیا می‌کند.\tPositive\tNeutral\n","سنسور با رزولوشن بالا، توانایی فیلم برداری ۷۲۰p hd و طراحی و ساخت زیبا و باریک نیز جزو ویژگی همه‌ی دوربین‌های سری a امسال محسوب می‌گردند.\tPositive\tPositive\n","همه میدانیم که این گوشی از سیستم عامل ios۶ پشتیبانی میکند سیستم عاملی که رییس شرکت سامسونگ در معرفی گلکسی نوت۲ دربارش میگوید: این سیستم عامل بی نظیر و دست نیافتنی است و من ارزو دارم روزی از این سیستم عامل بر روی گوشی‌های سامسونگ استفاده کنم.\tPositive\tPositive\n","در قسمت پشتی دوربین، نمایشگر ۳ اینچی قرار گرفته است که رزولوشن ۲۳۰۰۰۰ نقطه را ارائه می‌دهد.\tNeutral\tNeutral\n","همانند iphone ۵، بدنه ipod touch نسل پنجم نیز از آلومینیوم یکپارچه ساخته شده و تنها در قسمت جلویی دستگاه، یک لایه شیشه‌ای، برای محافظت از صفحه نمایش قرار داده شده است.\tNeutral\tNeutral\n","نباید توقع اجرای بازی رو با بالاترین گرافیک رو داشته باشیم.\tNeutral\tNegative\n","این دستگاه‌ها با گرد هم آوردن چند دستگاه به صورت یک جا، هم فضای کمتری می‌گیرد و هم هزینه کمتری به خریداران خود تحمیل می‌کند.\tPositive\tNegative\n","حساسیت لمسی خود نمایشگر هم کاملا عالیست.\tPositive\tPositive\n","تازه گارانتیشم که بخاطر ت ح ر ی م!\tNeutral\tNeutral\n","۵- ورژن جدیدتر نسخه بستنی نونی آندروید یعنی ۴٫۰.۴ (ورژن آندروید desire x ا: ice cream sandwich ۴٫۰.۰) ***برتری‌های desire x نسبت به desire sv: ***۱- داشتن تراکم پیکسلی بالاتر به علت کوچکتر بودن صفحه نمایش (با ۲۳۳ppi، در هر اینچ ۱۶ پیکسل بیشتر داره) ۲- سرعت بلوتوث بالاتر به علت بهره بردن از a۲dp.\tNeutral\tNeutral\n","منم چند روزی میشه که گرفتم.\tNeutral\tNeutral\n","بنابراین کاربران می‌توانند لذت عکاسی با کیفیت dslr را با امکاناتی مانند auto hdr تجربه کنند.\tPositive\tNeutral\n","عکس و موسیقی.\tNeutral\tNeutral\n","سیپیوشم اصلا کم نمیاره اونم با بازیهایی مثل modrn combat۴ و..\tPositive\tNegative\n","جالب است که one x با امتیاز کمتر از نصف آیفون۵ در رده چهارم و galaxy s iii در رده پنجم ایستاند.\tNeutral\tNeutral\n","شاید بشه گفت برای بازی مناسب نیست.\tNegative\tNeutral\n","این کانکتور کاملا دیجیتالی بوده و طوری طراحی گردیده که از هر دو طرف قابل اتصال است.\tNeutral\tNeutral\n","من این گوشی را از همین سایت خریدم (سایت مطمئن و خوبیه دیجی کالا) دوستم گالگسی مینی ۲ داره با یه نرم افزار اونا چک کردیم گوشی من تو همه زمینه‌ها به غیر از i/o از اون سرتر بود و جالبه بدونید قیمتش از اون کمتر بود هر گوشی برای کار خاصی طراحی شده بعضیا رو صوتی تصویری بیشتر کار کردن بعضیا هم رو نرم افزاری با توجه به مشخصاتش این گوشی مناسب کارای نرم افزاری است از مزایاش خیلی خوش فرم و رنگ سفیدش معرکه است برند خیلی معروف و خوبی داره (این گوشی جدید و لوازم جانبیش نیامده اما خیلی راحت از لوازم مینی ۲ و ایس براش خریدم که مزید برند معروف بودنه در ثانی خرابی سامسونگ از بقیه کمتره) سی پی یو و رم قوی +نسخه نهایی آندروید که هر نرم افزاری را راحت نصب میکنه ۲ سیم کارته بودنش صفحه بزرگش (۳٫۲۷) صفحه نمایشم به نظرم کیفیت خوبی داره از معایبش ۱- مصرف زیاد باطری نسبت به مینی ۲ ۲-بلندگوی گوشی صداش یکم بم نسبت به گوشی قبلیم (k۸۰۰) اما میکروفونش فوق العادس ۳-نداشتن فلش در کل با توجه به کارائی و قیمتش از ۱۰۰ نمره ۸۵ بهش میدم\tNeutral\tPositive\n","گارانتی هماهنگ عالیه\tPositive\tPositive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C14crydH6jB6"},"source":["output_file_name = \"sentiment_analysis_deepsentipers_multi_testset_{}_outputs.txt\".format(model_name.replace('/','-'))\n","with open(output_file_name, \"w\", encoding='utf8') as output_file:\n","  for comment, true_label, predicted_label in evaluation_output:\n","    output_file.write('{}\\t{}\\t{}\\n'.format(comment, true_label, predicted_label))\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","upload = drive.CreateFile({'title': output_file_name})\n","upload.SetContentFile(output_file_name)\n","upload.Upload()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZqzQwzsAfqDO"},"source":["## Digikala+SnappFood+DeepSentiPers"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hSYmd_okhCYW","executionInfo":{"status":"ok","timestamp":1627905037121,"user_tz":-270,"elapsed":2257,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"dc9f886a-6ba5-4e59-c355-d46e40e93442"},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","download = drive.CreateFile({'id': '1bUcDtQS3vXZpo_zq8RuJV2_WDK6JLXiO'})\n","download.GetContentFile('persian-digikala-reviwes.zip')\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["adc.json\n","DeepSentiPers\n","persian-digikala-reviwes.zip\n","sample_data\n","sentiment_analysis_deepsentipers_multi_testset_m3hrdadfi-albert-fa-base-v2-sentiment-multi_outputs.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8luiGnbfhEDT","executionInfo":{"status":"ok","timestamp":1627905037121,"user_tz":-270,"elapsed":7,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"5bff61c0-36e0-4d70-a803-7764c0e36dc8"},"source":["!unzip persian-digikala-reviwes.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  persian-digikala-reviwes.zip\n","   creating: persian-digikala-reviwes/\n","  inflating: persian-digikala-reviwes/2-p9vcb5bb.xlsx  \n","  inflating: persian-digikala-reviwes/link.txt  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Emop7TohHCw","executionInfo":{"status":"ok","timestamp":1627905039358,"user_tz":-270,"elapsed":2241,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"32797e51-5099-4ae2-8361-5cce703679b0"},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","download = drive.CreateFile({'id': '15J4zPN1BD7Q_ZIQ39VeFquwSoW8qTxgu'})\n","download.GetContentFile('snappfood.zip')\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["adc.json\n","DeepSentiPers\n","persian-digikala-reviwes\n","persian-digikala-reviwes.zip\n","sample_data\n","sentiment_analysis_deepsentipers_multi_testset_m3hrdadfi-albert-fa-base-v2-sentiment-multi_outputs.txt\n","snappfood.zip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IX-xIAdoheWJ","executionInfo":{"status":"ok","timestamp":1627905039921,"user_tz":-270,"elapsed":569,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"b2584d2c-dde8-48f6-8304-8bf3f600270a"},"source":["!unzip snappfood.zip\n","!ls\n","!ls snappfood"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  snappfood.zip\n","   creating: snappfood/\n","  inflating: snappfood/dev.csv       \n","  inflating: snappfood/train.csv     \n","  inflating: snappfood/test.csv      \n","adc.json\n","DeepSentiPers\n","persian-digikala-reviwes\n","persian-digikala-reviwes.zip\n","sample_data\n","sentiment_analysis_deepsentipers_multi_testset_m3hrdadfi-albert-fa-base-v2-sentiment-multi_outputs.txt\n","snappfood\n","snappfood.zip\n","dev.csv  test.csv  train.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NWRZkBqt6hEk"},"source":["!git clone https://github.com/JoyeBright/DeepSentiPers\n","!ls DeepSentiPers\n","!ls DeepSentiPers/Dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oxq-OEhLkUzC","executionInfo":{"status":"ok","timestamp":1627905099791,"user_tz":-270,"elapsed":59873,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"009a9a7e-a0de-4e67-c3aa-eba0ae6dfdc7"},"source":["test_comments, test_labels = sa_model.load_dataset_composite_file(\n","    dataset_name=\"digikala+snappfood+deepsentipers\",\n","    dataset_files={\"deepsentipers\": \"./DeepSentiPers/Dataset/test.csv\", \"digikala\": \"./persian-digikala-reviwes/2-p9vcb5bb.xlsx\", \"snappfood\":\"./snappfood/test.csv\"},\n","    label_map={\n","        \"deepsentipers\": {-2: \"Negative\", -1: \"Negative\", 0: \"Neutral\", 1: \"Positive\", 2: \"Positive\"},\n","        \"digikala\":{'no_idea': \"Neutral\", 'not_recommended': \"Negative\", 'recommended': \"Positive\"},\n","        \"snappfood\": {'HAPPY': \"Positive\",'SAD': \"Negative\"}\n","    }\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["digikala dataset - we only use test set:\n","all data: #comment: 63582, #labels: 63582\n","test part:\n"," #comment: 6359, #labels: 6359\n","snappfood dataset:\n","test part:\n"," #comment: 7000, #labels: 7000\n","deepsentipers dataset:\n","test part:\n"," #comment: 1854, #labels: 1854\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eFwPGVW0kVYO","executionInfo":{"status":"ok","timestamp":1627905100413,"user_tz":-270,"elapsed":629,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"2be205f4-ad1b-4baa-941e-59b25e8bc648"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon Aug  2 11:51:39 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   69C    P0    32W /  70W |   5896MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               79\n","Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n","Stepping:            0\n","CPU MHz:             2199.998\n","BogoMIPS:            4399.99\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            256K\n","L3 cache:            56320K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_q3DpFNkVa6","executionInfo":{"status":"ok","timestamp":1627905850781,"user_tz":-270,"elapsed":750381,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"53075190-2a9a-495d-bf93-a8fa0fc31b4f"},"source":["evaluation_output = sa_model.evaluation(test_comments, test_labels, device, batch_size=128)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["label_count: {'Negative': 5306, 'Neutral': 1796, 'Positive': 8111}\n","#samples: 15213\n","#batch: 119\n","Start to evaluate test data ...\n","inference time for step 0: 0.03237121699999079\n","inference time for step 1: 0.011312417999988611\n","inference time for step 2: 0.010391957000024377\n","inference time for step 3: 0.011102414999982102\n","inference time for step 4: 0.010739014999955998\n","inference time for step 5: 0.010280239999985952\n","inference time for step 6: 0.009691668000016307\n","inference time for step 7: 0.009876071000007869\n","inference time for step 8: 0.01033821200002194\n","inference time for step 9: 0.011807683000029101\n","inference time for step 10: 0.009747518999972726\n","inference time for step 11: 0.0101511660000142\n","inference time for step 12: 0.009701742000004288\n","inference time for step 13: 0.011134852999987288\n","inference time for step 14: 0.009923209000021416\n","inference time for step 15: 0.010457191000000421\n","inference time for step 16: 0.010775190999993356\n","inference time for step 17: 0.009818189999975857\n","inference time for step 18: 0.009990383000001657\n","inference time for step 19: 0.009617101999992883\n","inference time for step 20: 0.00977412299999969\n","inference time for step 21: 0.01052430900000445\n","inference time for step 22: 0.00955458099997486\n","inference time for step 23: 0.011208807999992132\n","inference time for step 24: 0.01144537999999784\n","inference time for step 25: 0.009753135000039492\n","inference time for step 26: 0.009888476000014634\n","inference time for step 27: 0.009985705000019607\n","inference time for step 28: 0.010032826999974986\n","inference time for step 29: 0.010677821999934167\n","inference time for step 30: 0.00964740899996741\n","inference time for step 31: 0.010147921999987375\n","inference time for step 32: 0.009583095000039066\n","inference time for step 33: 0.009684210000045823\n","inference time for step 34: 0.01097196500006703\n","inference time for step 35: 0.009538835000057588\n","inference time for step 36: 0.011175892999972348\n","inference time for step 37: 0.009909075999985362\n","inference time for step 38: 0.009955902000001515\n","inference time for step 39: 0.009988785000018652\n","inference time for step 40: 0.009791754999923796\n","inference time for step 41: 0.01416853099999571\n","inference time for step 42: 0.009827292000068155\n","inference time for step 43: 0.009834959000045274\n","inference time for step 44: 0.010151487000030102\n","inference time for step 45: 0.010640515999966738\n","inference time for step 46: 0.010723290999976598\n","inference time for step 47: 0.01052882499993757\n","inference time for step 48: 0.009822757000051752\n","inference time for step 49: 0.009892675999935818\n","inference time for step 50: 0.010780874000033691\n","inference time for step 51: 0.009957002999954057\n","inference time for step 52: 0.009732413000051565\n","inference time for step 53: 0.009645875999922282\n","inference time for step 54: 0.010219372999927145\n","inference time for step 55: 0.010046154000065144\n","inference time for step 56: 0.011760401000060483\n","inference time for step 57: 0.009965249999936532\n","inference time for step 58: 0.014191009000001031\n","inference time for step 59: 0.009815272000082587\n","inference time for step 60: 0.011232321999955275\n","inference time for step 61: 0.010731119999945804\n","inference time for step 62: 0.013389274000019213\n","inference time for step 63: 0.01914619199999379\n","inference time for step 64: 0.01005337200001577\n","inference time for step 65: 0.009919287000002441\n","inference time for step 66: 0.009903371999939736\n","inference time for step 67: 0.009796957999924416\n","inference time for step 68: 0.009866834000035851\n","inference time for step 69: 0.009887676999937867\n","inference time for step 70: 0.01038433000007899\n","inference time for step 71: 0.009999083999900904\n","inference time for step 72: 0.010226114000033704\n","inference time for step 73: 0.015489754999975958\n","inference time for step 74: 0.010799980999991021\n","inference time for step 75: 0.010573517000011634\n","inference time for step 76: 0.009980630000086421\n","inference time for step 77: 0.009747122999897329\n","inference time for step 78: 0.010271742000099948\n","inference time for step 79: 0.009955466000064916\n","inference time for step 80: 0.00972734300000866\n","inference time for step 81: 0.011128220000045985\n","inference time for step 82: 0.009610920000000078\n","inference time for step 83: 0.011317089000044689\n","inference time for step 84: 0.010504111000045668\n","inference time for step 85: 0.009733395999887762\n","inference time for step 86: 0.009637930999929267\n","inference time for step 87: 0.009960590999980923\n","inference time for step 88: 0.011022967000030803\n","inference time for step 89: 0.010057081000013568\n","inference time for step 90: 0.009901824000053239\n","inference time for step 91: 0.01024807100009184\n","inference time for step 92: 0.010074786999894059\n","inference time for step 93: 0.011042545999998765\n","inference time for step 94: 0.009808276999933696\n","inference time for step 95: 0.010796941999956289\n","inference time for step 96: 0.0108669789999567\n","inference time for step 97: 0.010162098000023434\n","inference time for step 98: 0.01092522999999801\n","inference time for step 99: 0.010101559000077032\n","inference time for step 100: 0.009777412999937951\n","inference time for step 101: 0.01195423599995138\n","inference time for step 102: 0.01122130599992488\n","inference time for step 103: 0.011181956000086757\n","inference time for step 104: 0.009992292999982055\n","inference time for step 105: 0.012970755999958783\n","inference time for step 106: 0.010220345999982783\n","inference time for step 107: 0.009502617000066493\n","inference time for step 108: 0.010739672999989125\n","inference time for step 109: 0.010324659999923824\n","inference time for step 110: 0.00983990999998241\n","inference time for step 111: 0.016517907999968884\n","inference time for step 112: 0.009701084999960585\n","inference time for step 113: 0.009975636999797644\n","inference time for step 114: 0.010393580000027214\n","inference time for step 115: 0.009829263000028732\n","inference time for step 116: 0.010076613999899564\n","inference time for step 117: 0.010438934999910998\n","inference time for step 118: 0.016281142000025284\n","average loss: 1.0165883821098745\n","total inference time: 1.283092855999314\n","total inference time / #samples: 8.434186919077854e-05\n","Test Accuracy: 0.7306908565043055\n","Test Precision: 0.8299635581729423\n","Test Recall: 0.7306908565043055\n","Test F1-Score(weighted average): 0.75596316743986\n","Test classification Report:\n","              precision    recall  f1-score   support\n","\n","    Negative  0.8623833757 0.7664907652 0.8116144482      5306\n","     Neutral  0.3505632869 0.8836302895 0.5019769097      1796\n","    Positive  0.9149078727 0.6734064850 0.7757971735      8111\n","\n","    accuracy                      0.7306908565     15213\n","   macro avg  0.7092848451 0.7745091799 0.6964628438     15213\n","weighted avg  0.8299635582 0.7306908565 0.7559631674     15213\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LJBzS7eFoRRN","executionInfo":{"status":"ok","timestamp":1627905850782,"user_tz":-270,"elapsed":8,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"42f6f900-4e84-4adf-f461-f1128384b4af"},"source":["for comment, true_label, predicted_label in evaluation_output[:25]:\n","  print('{}\\t{}\\t{}'.format(comment, true_label, predicted_label))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["خیلی خوبه من ازش خوشم اومدبه نظرم نسبت به صندلی‌های دیگه خیلی بهتره وجمع وجوره خریدش روبهتون پیشنهادمیکنم ولی برای افرادباوزن بالا مناسب نیست به نظرم تاهشتادکیلوروجواب میده\tPositive\tNeutral\n","فاجعست\tNegative\tNegative\n","محصول خوبیه در کل. ارزش خریدن داره.\tPositive\tNeutral\n","خیلی بد بود اصلا من انداختمش دور مایع داخلش خشک بود\tNegative\tNegative\n","جنسش خیلی خوب و مقاوم هست و کاملا از صفحه گوشی محافظت میکنه، فقط حتما باید توسط نصاب ماهر نصب بشه تا خوب بچسبه\tPositive\tPositive\n","بلآخره سونی دیگه جزو بهترین‌های بازار\tPositive\tPositive\n","من فروشنده هستم. به جرات میگم تنها فلشی ک به هیچ عنوان خرابی نداره ساندیسک هست. سرعتش هم خوب هست. قیمتش هم خیلی عالی. مطمن باشین تجربه ۶ ساله منه. بخرین اصلا پشیمونی نداره\tNeutral\tNeutral\n","من این روان نویس را برای گزینۀ شارژ مجددش خریداری کردم ولی وقتی بدستم رسید، متوجه شدم که نه تنها شارژی نیست، بلکه مغزی آن یک بار مصرف بوده و پس از اتمام باید دور انداخته شود و مغزی جدید را حالا از کجا باید تهیه کرد!!! خدا می‌داند. برای کسانی که یکبار مصرف کار می‌کنند، بد نیست ولی مطمئن باشید شارژ مجدد برای این روان نویس امکان ندارد و پشت جوهرش را با ژله‌ای تقریبا بی رنگ (مانند خیلی از روان نویس‌های زبرا) پر کرده‌اند که با فشار هوایی که از دریچه بالایی آن به ژله و به تبع با نوشتن و خالی شدن جوهر به جوهر می‌آید، جوهر را به جلو رانده و خلاصه وقتی که تمام شود آن ژله به انتهایی‌ترین نقطه هم نرسیده پخش می‌شود و کلا خراب کاری می‌شود، ولی تا حدود آخرین جوهر را (بجز اندکی) مصرف می‌کند.\tNeutral\tNeutral\n","من لنت کارخونه رو عوض کردم اینو انداختم ولی سوت میکشه.\tNegative\tNegative\n","بسیار عالی\tPositive\tPositive\n","من این محافظ صفحه رو خریداری کردم و راضی ام\tPositive\tNeutral\n","عالی خیلی خوبه\tPositive\tNeutral\n","جنس بدنه نسبتا نرمه ولی نه مثل گاردهای tpu دکمه‌های خاموش روشن و کم و زیاد کردن صدا توی عکس کامل مشخص نیست ولی بیرون زدگی زیادی داره و رنگ فلز مانندش همخوانی نداره با بدنه مهمترین مشکل ابن که پورت شارژر کامل سر جاش قرار نمیگیره و هر بار مجبوری قسمت پایین گارد ر در بیاری و همین جا زدن‌های مکرر گارد باعث میشه لبه‌های محافظ صفحه از ر صفحه بلند بشه که اصلا خوب نیست\tNegative\tNeutral\n","کیفیتش مناسبه و با لین قیمت واقعا ارزش هرید داره\tPositive\tPositive\n","اصلا اصلاح نمی‌کنه\tNegative\tNegative\n","گلدان کوچک و زیبا یی است من برای کادو دادن خریدم.\tPositive\tNeutral\n","سلام این دستگاه رو وقتی دیدم که توی دیجی کالا خیلی ازش تعریف کرده بودن منم راغب شدم همین گلوکومتر بگیرم. چند روز اول با توجه به اینکه خیلی سریع جواب میداد و نیاز به خون بسیار کمی داشت ازش راضی بودم، تا اینکه به نظرم رسید تستش کنم ببینم جواب آزمایش‌های متفاوت از یک نمونه یکسان هست یا نه، اما کاملا نامید شدم، جواب‌ها متفاوت با اختلاف زیاد بود. در روزهای بعد هم اینکارو کردم حتی شش بار پشت سر هم اینکارو انجام دادم و هر دفعه جواب متفاوت بود. دنبال مایع است دستگاه بودم که ببینم عیب از دستگاهه یا نوار‌های تست که موفق نشدم پیداش کنم. الان هم دیگه ازش تا امید شدم.\tNegative\tNegative\n","من قبلا از این برند شارژر مدل‌های دیگشو استفاده کردم ولی این مدلش رو که خریدم پشیمان شدم اولش خوب شارژ میکنه بعد چند دقیقه که کار کرد داغ میکنه دیگه خوب شارژ نمیکنه.\tNegative\tNeutral\n","حتملا پیشنها د میکنم خیلی خوبه چون من کمر درد داشتم هر وقت میزارم احساس میکنم درد کمرم کم میشه و شکمم عرق میکنه خیلی خوبه از دیجی ممنونم با این شکم بند لاغری که هزنیه زیادیم نداره\tPositive\tPositive\n","ماندگاری درحد چن دقیقه.\tNegative\tNeutral\n","۱-کیفیت ۲-بی صدا ۳-سبک بودن ۴-ساخت ژاپن ۵-بدون لرزش ۶-تنوع شانه\tPositive\tPositive\n","صدای ضعیفی دارد ارگونمی خیلی بدی دارد داخل گوش نمی‌ایستد در مقابل قیمتش اصلا نمیارزه\tNegative\tNeutral\n","من چون همزن برقی و خردکن داشتم، نیاز به یه گوشکوب برقی داشتم فقط. چون معمولا گوشکوب برقی‌ها سه چهار کاره هستند و امکانات دیگه‌ای هم دارن. برای کسی که همزن و خردکن و این چیزا رو نداشته باشه، خب قطعا بهتره بره یه چندکاره بگیره. ولی اگر کسی بخواد فقط کوشکوب برقی بگیره این یکی عالیه. هم قدرتش و هم کیفیت ساخت بدنه ش و هم امکاناتش با بوش برابری می‌کنه.\tPositive\tNeutral\n","در یک کلام عالی نسبت به قیمتش عالیه همه امکانات داره من خودم گوشی فروشی دارم تواین قیمت هیچ گوشی به اندازه این امکانات نداره باطریشم عالیه\tPositive\tPositive\n","طعمش چیزی که فکر میکردم نیست\tNeutral\tNeutral\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"thmplawwoRUe"},"source":["output_file_name = \"sentiment_analysis_digi-snapp-senti_multi_testset_{}_outputs.txt\".format(model_name.replace('/','-'))\n","with open(output_file_name, \"w\", encoding='utf8') as output_file:\n","  for comment, true_label, predicted_label in evaluation_output:\n","    output_file.write('{}\\t{}\\t{}\\n'.format(comment, true_label, predicted_label))\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","upload = drive.CreateFile({'title': output_file_name})\n","upload.SetContentFile(output_file_name)\n","upload.Upload()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QUq4teHIhoH0"},"source":[""],"execution_count":null,"outputs":[]}]}