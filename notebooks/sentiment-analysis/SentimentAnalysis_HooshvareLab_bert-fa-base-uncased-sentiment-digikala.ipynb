{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SentimentAnalysis/HooshvareLab/bert-fa-base-uncased-sentiment-digikala.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOknaOPn1S4RVlMRE7/BS6i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3b1d6bce35d04b6fbc8e9ee825558a54":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_684f3c140b014a88876ce6f2ebbeb6cc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4c048b3c991345779cb30b22949b68bb","IPY_MODEL_ab1916287ad4480b9282dd39bf154cbe"]}},"684f3c140b014a88876ce6f2ebbeb6cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4c048b3c991345779cb30b22949b68bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_798ec4fbe3c24bdd870d91df81c60c81","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":694,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":694,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38097bd71faf4540b638db392ac4bb05"}},"ab1916287ad4480b9282dd39bf154cbe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ad3a807aa70e41d7a00ebb1230e9fd32","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 694/694 [00:03&lt;00:00, 226B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_45d440f8d2a24a779c7aacc5229381c2"}},"798ec4fbe3c24bdd870d91df81c60c81":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"38097bd71faf4540b638db392ac4bb05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ad3a807aa70e41d7a00ebb1230e9fd32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"45d440f8d2a24a779c7aacc5229381c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd437bdd5f684a6e8860b3b8811c4122":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_49df9b5210e14fff9d4695ac5bea7c2c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9f3b4d5950a84a7faddfd6b5dc2d62de","IPY_MODEL_e8856cb79afd4686852ff3b82c09669c"]}},"49df9b5210e14fff9d4695ac5bea7c2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f3b4d5950a84a7faddfd6b5dc2d62de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_db144bcbeae0465c86aaeb00f457f863","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1198122,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1198122,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4fd4096ddbef4856a343c526305f52ef"}},"e8856cb79afd4686852ff3b82c09669c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7bad31d249f444b88a2ef34d7fb812f2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.20M/1.20M [00:01&lt;00:00, 763kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_94f8edf0b19b451b8f38833ac3ad7e82"}},"db144bcbeae0465c86aaeb00f457f863":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4fd4096ddbef4856a343c526305f52ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7bad31d249f444b88a2ef34d7fb812f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"94f8edf0b19b451b8f38833ac3ad7e82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"222d0e6fd9064b99a92dfa474408b758":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3ac7b4cf08654f85a9526a9db1a9e12e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9abed3a4e74e4da68c5d3a847b02b47b","IPY_MODEL_c92d22f17f234b2bac71cbd01c1f4b2a"]}},"3ac7b4cf08654f85a9526a9db1a9e12e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9abed3a4e74e4da68c5d3a847b02b47b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_188e26ab705646a3b82a32dcb477b77c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a9534424f6c548c091249feb1514e6c1"}},"c92d22f17f234b2bac71cbd01c1f4b2a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_57d289c9ad1c448f9e0b853a3219abc7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 138B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a14f6bf2785a448985044f44f2b4fe19"}},"188e26ab705646a3b82a32dcb477b77c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a9534424f6c548c091249feb1514e6c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57d289c9ad1c448f9e0b853a3219abc7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a14f6bf2785a448985044f44f2b4fe19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51cab54d00714931a90492e683fcd572":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e18992238ff84f17ab466937673cd82d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_60e0cb2a41b2480eb46b0477d4a1b165","IPY_MODEL_24052745762444a9a3023c755c62f60c"]}},"e18992238ff84f17ab466937673cd82d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"60e0cb2a41b2480eb46b0477d4a1b165":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f218aa8fbea143c7b4d9a4d9c55e7ec5","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":62,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":62,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b3a7ad7303d84caea0b5b73df8bdd135"}},"24052745762444a9a3023c755c62f60c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_478401d1e138421987323d9eab9fca62","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 62.0/62.0 [00:00&lt;00:00, 480B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_54ebd3cc27034b1e883473e0a20cf921"}},"f218aa8fbea143c7b4d9a4d9c55e7ec5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b3a7ad7303d84caea0b5b73df8bdd135":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"478401d1e138421987323d9eab9fca62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"54ebd3cc27034b1e883473e0a20cf921":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"53b2c82c8ec74f51acfcf1bfe306ba17":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e76ab77182854846a9ff9f03e72f724f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6431b2b0ed794928a3e122c57a6ea448","IPY_MODEL_3da4bd227944457c8bb60c418f037ea1"]}},"e76ab77182854846a9ff9f03e72f724f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6431b2b0ed794928a3e122c57a6ea448":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_06c4b5c313c9436fa3db37ad6bbb7708","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":651462369,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":651462369,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_de7831f0554a4d6992780b1ec5bdc9e2"}},"3da4bd227944457c8bb60c418f037ea1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3e45733cff1a4a1ba7f999ac14bed07d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 651M/651M [00:19&lt;00:00, 34.2MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_56f2addce35c49d9adb5ee26933cce3e"}},"06c4b5c313c9436fa3db37ad6bbb7708":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"de7831f0554a4d6992780b1ec5bdc9e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3e45733cff1a4a1ba7f999ac14bed07d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"56f2addce35c49d9adb5ee26933cce3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"OCaTlZA9OrP8"},"source":["# Persian Sentiment\n","It aims to classify text, such as comments, based on their emotional bias. We tested three well-known datasets for this task: **Digikala** user comments, **SnappFood** user comments, and **DeepSentiPers** in two binary-form and multi-form types.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rtExQfTFX62b","executionInfo":{"status":"ok","timestamp":1627907542306,"user_tz":-270,"elapsed":522,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"2f78d6e6-8c6a-4db5-d79a-8e0ecf309bcf"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon Aug  2 12:32:21 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   65C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               85\n","Model name:          Intel(R) Xeon(R) CPU @ 2.00GHz\n","Stepping:            3\n","CPU MHz:             2000.196\n","BogoMIPS:            4000.39\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            1024K\n","L3 cache:            39424K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LQarQ7jDUHzK","executionInfo":{"status":"ok","timestamp":1627907570096,"user_tz":-270,"elapsed":27794,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"3515773a-2cfe-41aa-f7c3-5b5cd92a753a"},"source":["!pip install hazm==0.7.0\n","!pip install seqeval==1.2.2\n","!pip install sentencepiece==0.1.96\n","!pip install transformers==4.7.0\n","!pip install clean-text[gpl]==0.4.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting hazm==0.7.0\n","  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 31.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40 kB 17.7 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 51 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 61 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 71 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 81 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 92 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 102 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 112 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 122 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 133 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 143 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 153 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 163 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 174 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 184 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 194 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 204 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 215 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 225 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 235 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 245 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 256 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 266 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 276 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 286 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 296 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 307 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 316 kB 8.5 MB/s \n","\u001b[?25hCollecting nltk==3.3\n","  Downloading nltk-3.3.0.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 41.9 MB/s \n","\u001b[?25hCollecting libwapiti>=0.2.1\n","  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n","\u001b[K     |████████████████████████████████| 233 kB 64.1 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm==0.7.0) (1.15.0)\n","Building wheels for collected packages: nltk, libwapiti\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394487 sha256=3b6ebf54d5e4afbbadea76d3cc43799324f25c82156f95963b9239c838768f25\n","  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n","  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154537 sha256=693faf5ee909737d3e01a09fcffb1d9ef1f0e0ad07c6135623c986317427c53e\n","  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n","Successfully built nltk libwapiti\n","Installing collected packages: nltk, libwapiti, hazm\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n","Collecting seqeval==1.2.2\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2) (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.0.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=fc2dcf30fc2165ea2bca50904abc189d93fbc8f13a93bd532d1138395f07ea4a\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Collecting sentencepiece==0.1.96\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 7.4 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting transformers==4.7.0\n","  Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 8.3 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 57.3 MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.8\n","  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (3.13)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 63.8 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (4.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (21.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (4.41.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0) (3.5.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.7.0) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (2021.5.30)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (7.1.2)\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.7.0\n","Collecting clean-text[gpl]==0.4.0\n","  Downloading clean_text-0.4.0-py3-none-any.whl (9.8 kB)\n","Collecting ftfy<7.0,>=6.0\n","  Downloading ftfy-6.0.3.tar.gz (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 2.8 MB/s \n","\u001b[?25hCollecting emoji\n","  Downloading emoji-1.4.2.tar.gz (184 kB)\n","\u001b[K     |████████████████████████████████| 184 kB 15.3 MB/s \n","\u001b[?25hCollecting unidecode<2.0.0,>=1.1.1\n","  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n","\u001b[K     |████████████████████████████████| 241 kB 59.6 MB/s \n","\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy<7.0,>=6.0->clean-text[gpl]==0.4.0) (0.2.5)\n","Building wheels for collected packages: ftfy, emoji\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41934 sha256=122cc1d42cd7b7aa793f233b7923737cc058f776cae94651ece13ab12c06a3ea\n","  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186469 sha256=6cb1676dea2ab258300abb9e804be6ea9cab1a67e71530a5fa46288f4373fa5c\n","  Stored in directory: /root/.cache/pip/wheels/e4/61/e7/2fc1ac8f306848fc66c6c013ab511f0a39ef4b1825b11363b2\n","Successfully built ftfy emoji\n","Installing collected packages: ftfy, emoji, unidecode, clean-text\n","Successfully installed clean-text-0.4.0 emoji-1.4.2 ftfy-6.0.3 unidecode-1.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HHgfio9mUILW","executionInfo":{"status":"ok","timestamp":1627907602567,"user_tz":-270,"elapsed":32493,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"e5c73a9d-5435-4c5c-9ac5-6159ba504915"},"source":["!pip install PyDrive\n","import os\n","import IPython.display as ipd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: PyDrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (1.12.8)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.32.1)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.26.3)\n","Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.23.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.53.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2018.9)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (57.2.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (21.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.17.3)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.2.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (0.2.8)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t0NQsg4fUMR7","executionInfo":{"status":"ok","timestamp":1627907611526,"user_tz":-270,"elapsed":6291,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"0e0f72ef-a9e3-4727-8d29-0c8db06b2f70"},"source":["# Import required packages\n","import os\n","import gc\n","import re\n","import hazm\n","import time\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","import transformers\n","from transformers import AutoConfig, AutoTokenizer\n","from transformers import AutoModelForSequenceClassification\n","\n","from cleantext import clean\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","\n","print()\n","print('numpy', np.__version__)\n","print('pandas', pd.__version__)\n","print('transformers', transformers.__version__)\n","print('torch', torch.__version__)\n","print()\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","numpy 1.19.5\n","pandas 1.1.5\n","transformers 4.7.0\n","torch 1.9.0+cu102\n","\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0l3uicV_XKeT"},"source":["class SentimentAnalysisDataset(torch.utils.data.Dataset):\n","    \"\"\" Create a PyTorch dataset for Sentiment Analysis. \"\"\"\n","\n","    def __init__(self, tokenizer, comments, targets, label_list=None, max_len=128):\n","        self.comments = comments\n","        self.targets = targets\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        self.label2index = {label: i for i, label in enumerate(label_list)} if isinstance(label_list, list) else {}\n","        self.index2label = {i: label for label, i in self.label2index.items()}\n","\n","    def __len__(self):\n","        return len(self.comments)\n","\n","    def __getitem__(self, item):\n","        comment = self.comments[item]\n","        target = self.label2index[self.targets[item]]\n","        encoding = self.tokenizer.encode_plus(\n","            comment,\n","            add_special_tokens=True,\n","            truncation=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_tensors='pt')\n","\n","        inputs = {\n","            'comment': comment,\n","            'targets': torch.tensor(target, dtype=torch.long),\n","            'original_targets': self.targets[item],\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'token_type_ids': encoding['token_type_ids'].flatten(),\n","        }\n","\n","        return inputs\n","\n","\n","class MT5SentimentAnalysisDataset(torch.utils.data.Dataset):\n","    \"\"\" Create a PyTorch dataset for Sentiment Analysis. \"\"\"\n","\n","    def __init__(self, reviews, aspects, labels, tokenizer, max_length=128):\n","        self.reviews = reviews\n","        self.aspects = aspects\n","        self.targets = labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.reviews)\n","\n","    def __getitem__(self, item):\n","        if self.aspects is not None:\n","            encoding = self.tokenizer(\n","                self.reviews[item] + \" <sep> \" + self.aspects[item],\n","                add_special_tokens=True,\n","                max_length=self.max_length,\n","                truncation=True,\n","                padding='max_length',\n","                return_tensors=\"pt\"\n","            )\n","            inputs = {\n","                'review': self.reviews[item],\n","                'aspects': self.aspects[item],\n","                'targets': self.targets[item],\n","                'input_ids': encoding['input_ids'].flatten(),\n","                'attention_mask': encoding['attention_mask'].flatten()\n","            }\n","        else:\n","            encoding = self.tokenizer(\n","                self.reviews[item],\n","                add_special_tokens=True,\n","                max_length=self.max_length,\n","                truncation=True,\n","                padding='max_length',\n","                return_tensors=\"pt\"\n","            )\n","            inputs = {\n","                'review': self.reviews[item],\n","                'targets': self.targets[item],\n","                'input_ids': encoding['input_ids'].flatten(),\n","                'attention_mask': encoding['attention_mask'].flatten()\n","            }\n","\n","        return inputs\n","\n","\n","class SentimentAnalysis:\n","    def __init__(self, model_name, model_type=None):\n","        self.normalizer = hazm.Normalizer()\n","        self.model_name = model_name\n","        if model_type == \"mt5\":\n","            self.tokenizer = MT5Tokenizer.from_pretrained(model_name)\n","            self.model = MT5ForConditionalGeneration.from_pretrained(model_name)\n","            self.config = MT5Config.from_pretrained(self.model_name)\n","        else:\n","            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n","            self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)\n","            self.config = AutoConfig.from_pretrained(self.model_name)\n","            self.id2label = self.config.id2label\n","            self.label2id = self.config.label2id\n","\n","    def cleaning(self, text):\n","        def cleanhtml(raw_html):\n","            clean_pattern = re.compile('<.*?>')\n","            clean_text = re.sub(clean_pattern, '', raw_html)\n","            return clean_text\n","\n","        if type(text) is not str:\n","            return None\n","\n","        text = text.strip()\n","\n","        # regular cleaning\n","        text = clean(\n","            text,\n","            fix_unicode=True,\n","            to_ascii=False,\n","            lower=True,\n","            no_line_breaks=True,\n","            no_urls=True,\n","            no_emails=True,\n","            no_phone_numbers=True,\n","            no_numbers=False,\n","            no_digits=False,\n","            no_currency_symbols=True,\n","            no_punct=False,\n","            replace_with_url=\"\",\n","            replace_with_email=\"\",\n","            replace_with_phone_number=\"\",\n","            replace_with_number=\"\",\n","            replace_with_digit=\"0\",\n","            replace_with_currency_symbol=\"\"\n","        )\n","\n","        # cleaning htmls\n","        text = cleanhtml(text)\n","\n","        # normalizing\n","        text = self.normalizer.normalize(text)\n","\n","        # removing wierd patterns\n","        wierd_pattern = re.compile(\"[\"\n","                                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","                                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","                                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","                                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                                   u\"\\U00002702-\\U000027B0\"\n","                                   u\"\\U000024C2-\\U0001F251\"\n","                                   u\"\\U0001f926-\\U0001f937\"\n","                                   u'\\U00010000-\\U0010ffff'\n","                                   u\"\\u200d\"\n","                                   u\"\\u2640-\\u2642\"\n","                                   u\"\\u2600-\\u2B55\"\n","                                   u\"\\u23cf\"\n","                                   u\"\\u23e9\"\n","                                   u\"\\u231a\"\n","                                   u\"\\u3030\"\n","                                   u\"\\ufe0f\"\n","                                   u\"\\u2069\"\n","                                   u\"\\u2066\"\n","                                   # u\"\\u200c\"\n","                                   u\"\\u2068\"\n","                                   u\"\\u2067\"\n","                                   \"]+\", flags=re.UNICODE)\n","\n","        text = wierd_pattern.sub(r'', text)\n","\n","        # removing extra spaces, hashtags\n","        text = re.sub(\"#\", \"\", text)\n","        text = re.sub(\"\\s+\", \" \", text)\n","        if text in ['', \" \"]:\n","            return None\n","        return text\n","\n","    def load_dataset_test_file(self, dataset_name, dataset_file, **kwargs):\n","        if dataset_name.lower() == \"snappfood\":\n","            if not os.path.exists(dataset_file):\n","                print(f'{dataset_file} not exists!')\n","                return\n","            data = pd.read_csv(dataset_file, delimiter=\"\\t\")\n","            # drop label_id because its not consistent with albert model labels!\n","            data = data[['comment', 'label']]\n","\n","            # cleaning comments\n","            data = data.dropna(subset=['comment'])\n","            data['comment'] = data['comment'].apply(self.cleaning)\n","            data = data.dropna(subset=['comment'])\n","\n","            if 'label_map' in kwargs:\n","                data['label'] = data['label'].apply(lambda l: kwargs['label_map'][l])\n","                data = data.dropna(subset=['label'])\n","                data = data.reset_index(drop=True)\n","\n","            data['label_id'] = data['label'].apply(lambda t: self.label2id[t])\n","            x_test, y_test = data['comment'].values.tolist(), data['label_id'].values.tolist()\n","            print(f'test part:\\n #comment: {len(x_test)}, #labels: {len(y_test)}')\n","            return x_test, y_test\n","        if dataset_name.lower() == \"deepsentipers\":\n","            if not os.path.exists(dataset_file):\n","                print(f'{dataset_file} not exists!')\n","                return\n","            if 'label_map' not in kwargs:\n","                print(\"label_map is missing!\")\n","                return\n","            data = pd.read_csv(dataset_file, delimiter=\",\", names=['comment', 'label'], header=None)\n","\n","            # cleaning comments\n","            data = data.dropna(subset=['comment'])\n","            data['comment'] = data['comment'].apply(self.cleaning)\n","            data = data.dropna(subset=['comment'])\n","\n","            # map labels\n","            label_map = kwargs['label_map']\n","            data['label'] = data['label'].apply(lambda l: label_map[l])\n","            data = data.dropna(subset=['label'])\n","            data = data.reset_index(drop=True)\n","\n","            data['label_id'] = data['label'].apply(lambda t: self.label2id[t])\n","            x_test, y_test = data['comment'].values.tolist(), data['label_id'].values.tolist()\n","            print(f'test part:\\n #comment: {len(x_test)}, #labels: {len(y_test)}')\n","            return x_test, y_test\n","        if dataset_name.lower() == \"pasinlu-aspect-sentiment\":\n","            if not os.path.exists(dataset_file):\n","                print(f'{dataset_file} not exists!')\n","                return\n","            if 'label_map' not in kwargs:\n","                print(\"label_map is missing!\")\n","                return\n","\n","            reviews, aspects, labels = [], [], []\n","            with open(dataset_file, encoding=\"utf8\") as infile:\n","                for line in infile:\n","                    json_line = json.loads(line.strip())\n","\n","                    review = json_line['review']\n","                    reviews.append(review)\n","\n","                    question = json_line['question']\n","                    aspects.append(question)\n","\n","                    label = kwargs['label_map'][json_line['label']]\n","                    labels.append(label)\n","\n","            return reviews, aspects, labels\n","\n","    def load_dataset_file(self, dataset_name, dataset_file, **kwargs):\n","        if dataset_name.lower() == \"digikala\":\n","            if not os.path.exists(dataset_file):\n","                print(f'{dataset_file} not exists!')\n","                return\n","            data = pd.read_excel(dataset_file)\n","            data = data[['comment', 'recommend']]\n","\n","            # cleaning comments\n","            data = data.dropna(subset=['comment'])\n","            data['comment'] = data['comment'].apply(self.cleaning)\n","            data = data.dropna(subset=['comment'])\n","\n","            # cleaning labels\n","            valid_labels = ['no_idea', 'not_recommended', 'recommended']\n","            data['recommend'] = data['recommend'].apply(lambda r: r if r in valid_labels else None)\n","            data = data.dropna(subset=['recommend'])\n","            if 'label_map' in kwargs:\n","                data['recommend'] = data['recommend'].apply(lambda l: kwargs['label_map'][l])\n","            data = data.dropna(subset=['recommend'])\n","            data = data.reset_index(drop=True)\n","\n","            data['label_id'] = data['recommend'].apply(lambda t: self.label2id[t])\n","\n","            x_all, y_all = data['comment'].values.tolist(), data['label_id'].values.tolist()\n","            print(f'all data: #comment: {len(x_all)}, #labels: {len(y_all)}')\n","\n","            _, test = train_test_split(data, test_size=0.1, random_state=1, stratify=data['recommend'])\n","            test = test.reset_index(drop=True)\n","            x_test, y_test = test['comment'].values.tolist(), test['label_id'].values.tolist()\n","            print(f'test part:\\n #comment: {len(x_test)}, #labels: {len(y_test)}')\n","            return x_all, y_all, x_test, y_test\n","        if dataset_name.lower() == \"pasinlu-review-sentiment\":\n","            if not os.path.exists(dataset_file):\n","                print(f'{dataset_file} not exists!')\n","                return\n","            if 'label_map' not in kwargs:\n","                print(\"label_map is missing!\")\n","                return\n","\n","            reviews, labels = [], []\n","            with open(dataset_file, encoding=\"utf8\") as infile:\n","                for line in infile:\n","                    json_line = json.loads(line.strip())\n","\n","                    review = json_line['review']\n","                    reviews.append(review)\n","\n","                    label = kwargs['label_map'][json_line['sentiment']]\n","                    labels.append(label)\n","            return reviews, labels\n","\n","    def load_dataset_composite_file(self, dataset_name, dataset_files, **kwargs):\n","        if dataset_name.lower() == \"digikala+snappfood+deepsentipers\":\n","            if sorted(list(dataset_files.keys())) != [\"deepsentipers\", \"digikala\", \"snappfood\"]:\n","                print(\"dataset_files must contains path of all three datasets\")\n","                return\n","            if 'label_map' not in kwargs:\n","                print(\"label_map is missing!\")\n","                return\n","            elif sorted(list(kwargs['label_map'].keys())) != [\"deepsentipers\", \"digikala\", \"snappfood\"]:\n","                print(\"label_map must contains label_map for all three datasets!\")\n","                return\n","            print(\"digikala dataset - we only use test set:\")\n","            _, _, x_test_digi, y_test_digi = self.load_dataset_file('digikala', dataset_files['digikala'],\n","                                                                    label_map=kwargs['label_map']['digikala'])\n","            print(\"snappfood dataset:\")\n","            x_test_snapp, y_test_snapp = self.load_dataset_test_file('snappfood', dataset_files['snappfood'],\n","                                                                     label_map=kwargs['label_map']['snappfood'])\n","            print(\"deepsentipers dataset:\")\n","            x_test_senti, y_test_senti = self.load_dataset_test_file('deepsentipers', dataset_files['deepsentipers'],\n","                                                                     label_map=kwargs['label_map']['deepsentipers'])\n","            return x_test_digi + x_test_snapp + x_test_senti, y_test_digi + y_test_snapp + y_test_senti\n","\n","    def sentiment_analysis_inference(self, input_text, device):\n","        if not self.model or not self.tokenizer or not self.id2label:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        pt_batch = self.tokenizer(\n","            input_text,\n","            padding=True,\n","            truncation=True,\n","            max_length=self.config.max_position_embeddings,\n","            return_tensors=\"pt\"\n","        )\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","        pt_batch = pt_batch.to(device)\n","\n","        pt_outputs = self.model(**pt_batch)\n","        pt_predictions = torch.argmax(F.softmax(pt_outputs.logits, dim=1), dim=1)\n","\n","        output_predictions = []\n","        for i, sentence in enumerate(input_text):\n","            output_predictions.append((sentence, self.id2label.get(pt_predictions[i].item())))\n","        return output_predictions\n","\n","    def mt5_sentiment_analysis_inference(self, reviews, device):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        tokenized_batch = self.tokenizer(\n","            reviews,\n","            padding=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        input_ids = tokenized_batch.input_ids.to(device)\n","        attention_mask = tokenized_batch.attention_mask.to(device)\n","        outputs = self.model.generate(input_ids=input_ids,\n","                                      attention_mask=attention_mask)\n","        predictions = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","        return predictions\n","\n","    def mt5_aspect_sentiment_analysis_inference(self, reviews, aspects, device):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        new_input = []\n","        for r, a in zip(reviews, aspects):\n","            new_input.append(r + \" <sep> \" + a)\n","\n","        tokenized_batch = self.tokenizer(\n","            new_input,\n","            padding=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        input_ids = tokenized_batch.input_ids.to(device)\n","        attention_mask = tokenized_batch.attention_mask.to(device)\n","        outputs = self.model.generate(input_ids=input_ids,\n","                                      attention_mask=attention_mask)\n","        predictions = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","        return predictions\n","\n","    def evaluation(self, input_text, input_labels, device, batch_size=4):\n","        if not self.model or not self.tokenizer or not self.id2label:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        max_len = self.config.max_position_embeddings\n","        label_list = list(set(input_labels))\n","        label_count = {self.id2label[label]: input_labels.count(label) for label in label_list}\n","        print(\"label_count:\", label_count)\n","        dataset = SentimentAnalysisDataset(comments=input_text, targets=input_labels, tokenizer=self.tokenizer,\n","                                           max_len=max_len, label_list=label_list)\n","        data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n","\n","        print(\"#samples:\", len(input_text))\n","        print(\"#batch:\", len(data_loader))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        total_loss, total_time = 0, 0\n","        output_predictions = []\n","        golden_labels, predicted_labels = [], []\n","        print(\"Start to evaluate test data ...\")\n","        for step, batch in enumerate(data_loader):\n","            b_comments = batch['comment']\n","            b_input_ids = batch['input_ids']\n","            b_attention_mask = batch['attention_mask']\n","            b_token_type_ids = batch['token_type_ids']\n","            b_targets = batch['targets']\n","\n","            # move tensors to GPU if CUDA is available\n","            b_input_ids = b_input_ids.to(device)\n","            b_attention_mask = b_attention_mask.to(device)\n","            b_token_type_ids = b_token_type_ids.to(device)\n","            b_targets = b_targets.to(device)\n","\n","            # This will return the loss (rather than the model output) because we have provided the `labels`.\n","            with torch.no_grad():\n","                start = time.monotonic()\n","                b_outputs = self.model(input_ids=b_input_ids, attention_mask=b_attention_mask,\n","                                       token_type_ids=b_token_type_ids, labels=b_targets)\n","                end = time.monotonic()\n","                total_time += end - start\n","                print(f'inference time for step {step}: {end - start}')\n","            # get the loss\n","            total_loss += b_outputs.loss.item()\n","\n","            b_original_targets = batch['original_targets']\n","            golden_labels.extend(b_original_targets.tolist())\n","\n","            b_predictions = torch.argmax(F.softmax(b_outputs.logits, dim=1), dim=1)\n","            b_predictions = b_predictions.cpu().detach().numpy().tolist()\n","            b_predictions = [dataset.index2label[label] for label in b_predictions]\n","            predicted_labels.extend(b_predictions)\n","\n","            for i, comment in enumerate(b_comments):\n","                output_predictions.append((\n","                    comment,\n","                    self.id2label[b_original_targets[i].item()],\n","                    self.id2label[b_predictions[i]]\n","                ))\n","                # print(f'output prediction: {i},{comment},{self.id2label[b_original_targets[i].item()]},'\n","                #       f'{self.id2label[b_predictions[i]]}')\n","\n","        # Calculate the average loss over the training data.\n","        avg_train_loss = total_loss / len(data_loader)\n","        print(\"average loss:\", avg_train_loss)\n","        print(\"total inference time:\", total_time)\n","        print(\"total inference time / #samples:\", total_time / len(input_text))\n","\n","        # evaluate\n","        print(\"Test Accuracy: {}\".format(accuracy_score(golden_labels, predicted_labels)))\n","        print(\"Test Precision: {}\".format(precision_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test Recall: {}\".format(recall_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test F1-Score(weighted average): {}\".format(\n","            f1_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test classification Report:\\n{}\".format(classification_report(\n","            golden_labels, predicted_labels, digits=10, target_names=[self.id2label[_] for _ in sorted(label_list)])))\n","        return output_predictions\n","\n","    def mt5_sentiment_analysis_evaluation(self, reviews, labels, device, max_length, batch_size=4):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","        if len(reviews) != len(labels):\n","            print('length of inputs and labels is not equal!!')\n","            return\n","\n","        dataset = MT5SentimentAnalysisDataset(reviews=reviews, aspects=None, labels=labels, tokenizer=self.tokenizer,\n","                                              max_length=max_length)\n","        data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n","        print(f'#reviews:{len(reviews)}, #labels:{len(labels)}')\n","        print(\"#batch:\", len(data_loader))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        total_time = 0\n","        output_predictions = []\n","        golden_labels, predicted_labels = [], []\n","        print(\"Start to evaluate test data ...\")\n","        for step, batch in enumerate(data_loader):\n","            # move tensors to GPU if CUDA is available\n","            b_input_ids = batch['input_ids'].to(device)\n","            b_attention_mask = batch['attention_mask'].to(device)\n","\n","            # This will return the loss (rather than the model output) because we have provided the `labels`.\n","            with torch.no_grad():\n","                start = time.monotonic()\n","                b_outputs = self.model.generate(input_ids=b_input_ids, attention_mask=b_attention_mask)\n","                end = time.monotonic()\n","                total_time += end - start\n","                print(f'inference time for step {step}: {end - start}')\n","\n","            b_targets = batch['targets']\n","            golden_labels.extend(b_targets)\n","\n","            b_predictions = self.tokenizer.batch_decode(b_outputs, skip_special_tokens=True)\n","            predicted_labels.extend(b_predictions)\n","\n","            for i, review in enumerate(batch['review']):\n","                output_predictions.append((\n","                    review,\n","                    b_targets[i],\n","                    b_predictions[i]\n","                ))\n","\n","        print(\"total inference time:\", total_time)\n","        print(\"total inference time / #samples:\", total_time / len(reviews))\n","\n","        # evaluate\n","        print(\"Test Accuracy: {}\".format(accuracy_score(golden_labels, predicted_labels)))\n","        print(\"Test Precision: {}\".format(precision_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test Recall: {}\".format(recall_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test F1-Score(weighted average): {}\".format(\n","            f1_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test classification Report:\\n{}\".format(\n","            classification_report(golden_labels, predicted_labels, digits=10)))\n","        return output_predictions\n","\n","    def mt5_aspect_sentiment_analysis_evaluation(self, reviews, aspects, labels, device, max_length, batch_size=4):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","        if len(reviews) != len(labels):\n","            print('length of inputs and labels is not equal!!')\n","            return\n","\n","        dataset = MT5SentimentAnalysisDataset(reviews=reviews, aspects=aspects, labels=labels, tokenizer=self.tokenizer,\n","                                              max_length=max_length)\n","        data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n","        print(f'#reviews:{len(reviews)}, #aspects:{len(aspects)}, #labels:{len(labels)}')\n","        print(\"#batch:\", len(data_loader))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        total_time = 0\n","        output_predictions = []\n","        golden_labels, predicted_labels = [], []\n","        print(\"Start to evaluate test data ...\")\n","        for step, batch in enumerate(data_loader):\n","            # move tensors to GPU if CUDA is available\n","            b_input_ids = batch['input_ids'].to(device)\n","            b_attention_mask = batch['attention_mask'].to(device)\n","\n","            # This will return the loss (rather than the model output) because we have provided the `labels`.\n","            with torch.no_grad():\n","                start = time.monotonic()\n","                b_outputs = self.model.generate(input_ids=b_input_ids, attention_mask=b_attention_mask)\n","                end = time.monotonic()\n","                total_time += end - start\n","                print(f'inference time for step {step}: {end - start}')\n","\n","            b_targets = batch['targets']\n","            golden_labels.extend(b_targets)\n","\n","            b_predictions = self.tokenizer.batch_decode(b_outputs, skip_special_tokens=True)\n","            predicted_labels.extend(b_predictions)\n","\n","            for i, review in enumerate(batch['review']):\n","                output_predictions.append((\n","                    review,\n","                    batch['aspects'][i],\n","                    b_targets[i],\n","                    b_predictions[i]\n","                ))\n","\n","        print(\"total inference time:\", total_time)\n","        print(\"total inference time / #samples:\", total_time / len(reviews))\n","\n","        # evaluate\n","        print(\"Test Accuracy: {}\".format(accuracy_score(golden_labels, predicted_labels)))\n","        print(\"Test Precision: {}\".format(precision_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test Recall: {}\".format(recall_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test F1-Score(weighted average): {}\".format(\n","            f1_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test classification Report:\\n{}\".format(\n","            classification_report(golden_labels, predicted_labels, digits=10)))\n","        return output_predictions\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":849,"referenced_widgets":["3b1d6bce35d04b6fbc8e9ee825558a54","684f3c140b014a88876ce6f2ebbeb6cc","4c048b3c991345779cb30b22949b68bb","ab1916287ad4480b9282dd39bf154cbe","798ec4fbe3c24bdd870d91df81c60c81","38097bd71faf4540b638db392ac4bb05","ad3a807aa70e41d7a00ebb1230e9fd32","45d440f8d2a24a779c7aacc5229381c2","cd437bdd5f684a6e8860b3b8811c4122","49df9b5210e14fff9d4695ac5bea7c2c","9f3b4d5950a84a7faddfd6b5dc2d62de","e8856cb79afd4686852ff3b82c09669c","db144bcbeae0465c86aaeb00f457f863","4fd4096ddbef4856a343c526305f52ef","7bad31d249f444b88a2ef34d7fb812f2","94f8edf0b19b451b8f38833ac3ad7e82","222d0e6fd9064b99a92dfa474408b758","3ac7b4cf08654f85a9526a9db1a9e12e","9abed3a4e74e4da68c5d3a847b02b47b","c92d22f17f234b2bac71cbd01c1f4b2a","188e26ab705646a3b82a32dcb477b77c","a9534424f6c548c091249feb1514e6c1","57d289c9ad1c448f9e0b853a3219abc7","a14f6bf2785a448985044f44f2b4fe19","51cab54d00714931a90492e683fcd572","e18992238ff84f17ab466937673cd82d","60e0cb2a41b2480eb46b0477d4a1b165","24052745762444a9a3023c755c62f60c","f218aa8fbea143c7b4d9a4d9c55e7ec5","b3a7ad7303d84caea0b5b73df8bdd135","478401d1e138421987323d9eab9fca62","54ebd3cc27034b1e883473e0a20cf921","53b2c82c8ec74f51acfcf1bfe306ba17","e76ab77182854846a9ff9f03e72f724f","6431b2b0ed794928a3e122c57a6ea448","3da4bd227944457c8bb60c418f037ea1","06c4b5c313c9436fa3db37ad6bbb7708","de7831f0554a4d6992780b1ec5bdc9e2","3e45733cff1a4a1ba7f999ac14bed07d","56f2addce35c49d9adb5ee26933cce3e"]},"id":"hED3hCa7XQhf","executionInfo":{"status":"ok","timestamp":1627907640034,"user_tz":-270,"elapsed":25684,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"0c3203d6-c631-4548-88c4-dcad02c87992"},"source":["model_name='HooshvareLab/bert-fa-base-uncased-sentiment-digikala'\n","sa_model = SentimentAnalysis(model_name)\n","print(sa_model.config)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b1d6bce35d04b6fbc8e9ee825558a54","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=694.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd437bdd5f684a6e8860b3b8811c4122","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1198122.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"222d0e6fd9064b99a92dfa474408b758","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51cab54d00714931a90492e683fcd572","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=62.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53b2c82c8ec74f51acfcf1bfe306ba17","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=651462369.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","BertConfig {\n","  \"architectures\": [\n","    \"BertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"digikala\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"no_idea\",\n","    \"1\": \"not_recommended\",\n","    \"2\": \"recommended\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"no_idea\": 0,\n","    \"not_recommended\": 1,\n","    \"recommended\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.7.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 100000\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1VeS75HYYr1X"},"source":["## Sample Inference:"]},{"cell_type":"code","metadata":{"id":"euU3l2oaYtzC"},"source":["texts = [\n","    \"خوب نبود اصلا\",\n","    \"از رنگش خوشم نیومد\",\n","    \"کیفیتیش عالی بود\"\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QR96rhFyW6Z6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627907659114,"user_tz":-270,"elapsed":12418,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"c48b4386-fcd6-444e-b3d2-6ad9fe369566"},"source":["sa_model.sentiment_analysis_inference(texts, device)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('خوب نبود اصلا', 'not_recommended'),\n"," ('از رنگش خوشم نیومد', 'not_recommended'),\n"," ('کیفیتیش عالی بود', 'recommended')]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"ijbyr1e2T3pd"},"source":["## Digikala (from kaggle)\n","\n","Digikala user comments provided by Open Data Mining Program (ODMP). This dataset contains 63582 user comments with three labels:\n","\n","|          Label         | # | \n","|:------------------------:|:-----------:|\n","|  no_idea  |      10528    |\n","|  not_recommended |      16096      |\n","|  recommended |      36958      |\n","\n","Download You can download the dataset from [here](https://www.kaggle.com/saeedtqp/persian-digikala-reviwes?select=2-p9vcb5bb.xlsx)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E3mTv1mABUya","executionInfo":{"status":"ok","timestamp":1627907662635,"user_tz":-270,"elapsed":3524,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"3a9ba4f2-3107-4dd7-85ca-eee5f931fb0b"},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","download = drive.CreateFile({'id': '1bUcDtQS3vXZpo_zq8RuJV2_WDK6JLXiO'})\n","download.GetContentFile('persian-digikala-reviwes.zip')\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["adc.json  persian-digikala-reviwes.zip\tsample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zPzaL6BX67lS","executionInfo":{"status":"ok","timestamp":1627907662636,"user_tz":-270,"elapsed":9,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"f3f8af91-ee94-4faf-e8f5-e92b378ebb68"},"source":["!unzip persian-digikala-reviwes.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  persian-digikala-reviwes.zip\n","   creating: persian-digikala-reviwes/\n","  inflating: persian-digikala-reviwes/2-p9vcb5bb.xlsx  \n","  inflating: persian-digikala-reviwes/link.txt  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"62FJ_H1nQtmn","executionInfo":{"status":"ok","timestamp":1627907720329,"user_tz":-270,"elapsed":57697,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"e04b0e0c-9c61-4025-ee4b-60ff310625af"},"source":["all_comments, all_labels, test_comments, test_labels = sa_model.load_dataset_file(dataset_name=\"digikala\", dataset_file=\"./persian-digikala-reviwes/2-p9vcb5bb.xlsx\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["all data: #comment: 63582, #labels: 63582\n","test part:\n"," #comment: 6359, #labels: 6359\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V6pbl_PRB2EY","executionInfo":{"status":"ok","timestamp":1627907720330,"user_tz":-270,"elapsed":12,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"82d7b8de-996e-43c4-e9a3-e3791e52c366"},"source":["print(all_comments[:5])\n","print(all_labels[:5])\n","print(len(all_comments))\n","print(len(all_labels))\n","print(len(test_comments))\n","print(len(test_labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['سلام، قبل اینکه نظرم رو بگم میخواستم به یک موضوع مهم اشاره کنم که نظراتی که ما برای کالاها ثبت میکنیم خیلی مهم هستن، چون بسیاری از مردم عزیز با استناد به این نظرات یک کالا رو خریداری میکنن. پس بهتره ک نظر غیر کارشناسی و الکی ندیم. من ۲سال این پاور بانک رو دارم، برای ۲نفر اشنا هم خریدم، پیشنهاد ویژه بود خریدم، واقعا از هر نظر عالیه، بعد گذشت ۲سال هنوزم ۵بار ایفون se رو شارژ میکنه، در خصوص زمان شارژ گفته بودن دوستان، اگر با کابل خود پاور شارژ کنید حدود ۶ساعت فول میشه، اما اگر هر کابل دیگه\\u200cای وصل کنید ۱۲تا۱۸ ساعت طول میکشه. همزمان با این پاور یک adata ۱۰۰۰۰ هم برای همسرم خریدم، اونم خوب درومد ولی حدود ۳۰\\u200e٪ افت داشته و کمتر بازدهی شارژ داره. طبق تجربه من و اطرافیانم ک شیائومی داشتن، اگر کالایی ک میخرید اصل باشه (فیک زیاد داره) واقعا شیائومی حرف اول و میزنه، anker هم برند خیلی خوب ولی گرونه، هفته پیش از دیجی خریدم a۱۲۱۴ اونم واقعا سبک و عالیه و بازدهی بالایی داره. (۲خروجی هوشمند داره، مجموع ۳امپر میده، حداکثر یک خروجی ۲٫۴ میده) ببخشید طولانی شد.', 'گیره\\u200cهای فلزی خیلی سخت تا میشوند و لذا حوله را خیلی سخت می\\u200cتوان در آورد مهسان یه مدل دیگه داره که پلاستیکی هست و خیلی ساده و راحت خم می\\u200cشود به نظرم تولید این طرح را باید متوقف کنن چون گیره\\u200cهای آهنی خیلی سفت هستن و وقتی می\\u200cخواستم خمشون کنم پایه پلاستیکیش شکست و بلا استفاده شد', 'همه چیز در رابطه با ظاهر این گوشی بسیار خوب است. بدنه یکپارچه فلزی-پلاستیکی و صفحه نمایش با کیفیت حسی ارزنده را منتقل میکند. در مقایسه با قیمت از بسیاری از گوشی\\u200cهای همرده پرتوان\\u200cتر است و امکانات زیادی را در اختیار کاربر میگذارد. تنها مورد قدرت پردازنده گرافیکی و cpu گوشی است که با توجه به رزولوشن بالای صفحه نمایش مقداری در اجرای بازی\\u200cهای سنگین کم می\\u200cآورد. همچنین حجم زیادی از رم محدود ۲ گیگی این گوشی توسط سیستم اشغال میشود و در بهترین مواقع تنها نیمی از آن قابل اسفاده برنامه\\u200cهای دیگر است. مورد دیگر کیفیت پایین دوربین و کیفیت پایینتر اسپیکر است. تصاویر هر دو دوربین بسیار پر نویز و تار هستند. تنها با استفاده از فلش و یا در نور روز تصاویر بهتری میتوان ثبت کرد. صدایی که از اسپیکر خارج میشود خیلی بیکیفیت و دارای اکو و نویز بالاست. اما کیفیت صدای خروجی هدفون بسیار خوب است. باتری در کارهای متداول سبک تا معمولی کارایی خوبی دارد، اما هنگام اجرای برنامه\\u200cهای سنگین خیلی زود خالی میشود. زمان شارژ شدن باتری نیز نسبتا طولانی است. (حدود ۳ ساعت) در کل این گوشی را به کسانی که استفاده سنگین مولتی تسکینگ و گیم دارند پیشنهاد نمیکنم. اما اگر کسی هستید که وبگردی، تماشای ویدئو و استفاده از برنامه\\u200cهای سبک بخش اعظم استفاده شما از گوشی موبایل هستند، دوربین و اسپیکر برایتان از نان شب واجب\\u200cتر نیست و به ظاهری زیبا و بدنه با کیفیت اهمیت میدهید در خرید آن شک نکنید.', 'اگر ظرفیتش براتون کافیه حتما بخرید. یه شارژر ۵ ولت ۲ آمپر براش تهیه کنید تا سریعتر شارژ شه. خود برند شیائومی شارژر\\u200cهای خوبی داره. ظرافتش خوبه و وزن و ضخامت کمی داره و مثل یه موبایل راحت حمل میشه. البته پیشنهاد من ظرفیت\\u200cهای بالاتر هست. چون این مدل بسته به ظرفیت باتری گوشیتون صرفا به اندازه یک الی ۲ بار شارژ کردن، انرژی ذخیره میکنه.', 'سلام دوستان،، منم مثه بعضی از دوستان قبل از خرید کلی تحقیق در مورد این لپ تاپ عالی انجام دادم و به این نتیجه رسیدم که از مدل\\u200cهای مشابه همین شرکت و شرکت\\u200cهای دیگه واقعا بهتره،، در طول تحقیق هم به اون ویدیو هایی که بعضی دوستامون اشاره کردن هم برخوردم که از براق بودن صفحه نمایش و لق بودن لولاهای لپ تاپ موقع استفاده از تاچ اسکرین ایراد گرفته بودن، منم خیلی ترسیدم از این بابت ولی وقتی که تصمیم گرفتم که انتخابم رو نهایی کنم و بدستم رسید لپ تاپ دیدم واقعا تمام اون گفته\\u200cها اقراری بیش نبوده و اصلا خبری از لق زدن صفحه نیست موقع تاچ مگر اینکه بخوای محکم بکوبی انگشتتو که اونوقت تو هر لپ تاپی مسئله لق زدن هست، ولی از این بابت هیچ مشکلی نیست و کاملا محکمه. در مورد بازتاب بیش از حد صفحه نمایش هم همینطور فقط اقرار شده، اگر بخوای تو محیط بسته قرار داشته باشی با یه پروژکتور رو بروی صفحه بازهم این مسئله واسه همه لپ تاپ\\u200cها هست، و اینکه اگه حتی با یه لپ تاپی که صفحه مات داشته باشه بخوای تو فضای آزاد زیر نور شدید خورشید کار کنی محتوای صفحه\\u200cی اون رو هم نمیبینی (گفتم اینارو چون لپ تاپ قبلیم صفحش مات بوده و تجربه کردم) ولی تو شرایط عادی و استفاده روزمره به مشکلی باهاش برنمیخوری. امیدوارم تونسته باشم تو رفع بعضی شبهه\\u200cها واسه بعضی از دوستامون کمک کرده باشم.']\n","[2, 1, 0, 0, 2]\n","63582\n","63582\n","6359\n","6359\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pjM-NaEa1wHj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627907732789,"user_tz":-270,"elapsed":1158,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"42abf39b-b3e3-4c75-d8de-8303a595d8d4"},"source":["sa_model.sentiment_analysis_inference(all_comments[:5], device)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('سلام، قبل اینکه نظرم رو بگم میخواستم به یک موضوع مهم اشاره کنم که نظراتی که ما برای کالاها ثبت میکنیم خیلی مهم هستن، چون بسیاری از مردم عزیز با استناد به این نظرات یک کالا رو خریداری میکنن. پس بهتره ک نظر غیر کارشناسی و الکی ندیم. من ۲سال این پاور بانک رو دارم، برای ۲نفر اشنا هم خریدم، پیشنهاد ویژه بود خریدم، واقعا از هر نظر عالیه، بعد گذشت ۲سال هنوزم ۵بار ایفون se رو شارژ میکنه، در خصوص زمان شارژ گفته بودن دوستان، اگر با کابل خود پاور شارژ کنید حدود ۶ساعت فول میشه، اما اگر هر کابل دیگه\\u200cای وصل کنید ۱۲تا۱۸ ساعت طول میکشه. همزمان با این پاور یک adata ۱۰۰۰۰ هم برای همسرم خریدم، اونم خوب درومد ولی حدود ۳۰\\u200e٪ افت داشته و کمتر بازدهی شارژ داره. طبق تجربه من و اطرافیانم ک شیائومی داشتن، اگر کالایی ک میخرید اصل باشه (فیک زیاد داره) واقعا شیائومی حرف اول و میزنه، anker هم برند خیلی خوب ولی گرونه، هفته پیش از دیجی خریدم a۱۲۱۴ اونم واقعا سبک و عالیه و بازدهی بالایی داره. (۲خروجی هوشمند داره، مجموع ۳امپر میده، حداکثر یک خروجی ۲٫۴ میده) ببخشید طولانی شد.',\n","  'recommended'),\n"," ('گیره\\u200cهای فلزی خیلی سخت تا میشوند و لذا حوله را خیلی سخت می\\u200cتوان در آورد مهسان یه مدل دیگه داره که پلاستیکی هست و خیلی ساده و راحت خم می\\u200cشود به نظرم تولید این طرح را باید متوقف کنن چون گیره\\u200cهای آهنی خیلی سفت هستن و وقتی می\\u200cخواستم خمشون کنم پایه پلاستیکیش شکست و بلا استفاده شد',\n","  'not_recommended'),\n"," ('همه چیز در رابطه با ظاهر این گوشی بسیار خوب است. بدنه یکپارچه فلزی-پلاستیکی و صفحه نمایش با کیفیت حسی ارزنده را منتقل میکند. در مقایسه با قیمت از بسیاری از گوشی\\u200cهای همرده پرتوان\\u200cتر است و امکانات زیادی را در اختیار کاربر میگذارد. تنها مورد قدرت پردازنده گرافیکی و cpu گوشی است که با توجه به رزولوشن بالای صفحه نمایش مقداری در اجرای بازی\\u200cهای سنگین کم می\\u200cآورد. همچنین حجم زیادی از رم محدود ۲ گیگی این گوشی توسط سیستم اشغال میشود و در بهترین مواقع تنها نیمی از آن قابل اسفاده برنامه\\u200cهای دیگر است. مورد دیگر کیفیت پایین دوربین و کیفیت پایینتر اسپیکر است. تصاویر هر دو دوربین بسیار پر نویز و تار هستند. تنها با استفاده از فلش و یا در نور روز تصاویر بهتری میتوان ثبت کرد. صدایی که از اسپیکر خارج میشود خیلی بیکیفیت و دارای اکو و نویز بالاست. اما کیفیت صدای خروجی هدفون بسیار خوب است. باتری در کارهای متداول سبک تا معمولی کارایی خوبی دارد، اما هنگام اجرای برنامه\\u200cهای سنگین خیلی زود خالی میشود. زمان شارژ شدن باتری نیز نسبتا طولانی است. (حدود ۳ ساعت) در کل این گوشی را به کسانی که استفاده سنگین مولتی تسکینگ و گیم دارند پیشنهاد نمیکنم. اما اگر کسی هستید که وبگردی، تماشای ویدئو و استفاده از برنامه\\u200cهای سبک بخش اعظم استفاده شما از گوشی موبایل هستند، دوربین و اسپیکر برایتان از نان شب واجب\\u200cتر نیست و به ظاهری زیبا و بدنه با کیفیت اهمیت میدهید در خرید آن شک نکنید.',\n","  'no_idea'),\n"," ('اگر ظرفیتش براتون کافیه حتما بخرید. یه شارژر ۵ ولت ۲ آمپر براش تهیه کنید تا سریعتر شارژ شه. خود برند شیائومی شارژر\\u200cهای خوبی داره. ظرافتش خوبه و وزن و ضخامت کمی داره و مثل یه موبایل راحت حمل میشه. البته پیشنهاد من ظرفیت\\u200cهای بالاتر هست. چون این مدل بسته به ظرفیت باتری گوشیتون صرفا به اندازه یک الی ۲ بار شارژ کردن، انرژی ذخیره میکنه.',\n","  'recommended'),\n"," ('سلام دوستان،، منم مثه بعضی از دوستان قبل از خرید کلی تحقیق در مورد این لپ تاپ عالی انجام دادم و به این نتیجه رسیدم که از مدل\\u200cهای مشابه همین شرکت و شرکت\\u200cهای دیگه واقعا بهتره،، در طول تحقیق هم به اون ویدیو هایی که بعضی دوستامون اشاره کردن هم برخوردم که از براق بودن صفحه نمایش و لق بودن لولاهای لپ تاپ موقع استفاده از تاچ اسکرین ایراد گرفته بودن، منم خیلی ترسیدم از این بابت ولی وقتی که تصمیم گرفتم که انتخابم رو نهایی کنم و بدستم رسید لپ تاپ دیدم واقعا تمام اون گفته\\u200cها اقراری بیش نبوده و اصلا خبری از لق زدن صفحه نیست موقع تاچ مگر اینکه بخوای محکم بکوبی انگشتتو که اونوقت تو هر لپ تاپی مسئله لق زدن هست، ولی از این بابت هیچ مشکلی نیست و کاملا محکمه. در مورد بازتاب بیش از حد صفحه نمایش هم همینطور فقط اقرار شده، اگر بخوای تو محیط بسته قرار داشته باشی با یه پروژکتور رو بروی صفحه بازهم این مسئله واسه همه لپ تاپ\\u200cها هست، و اینکه اگه حتی با یه لپ تاپی که صفحه مات داشته باشه بخوای تو فضای آزاد زیر نور شدید خورشید کار کنی محتوای صفحه\\u200cی اون رو هم نمیبینی (گفتم اینارو چون لپ تاپ قبلیم صفحش مات بوده و تجربه کردم) ولی تو شرایط عادی و استفاده روزمره به مشکلی باهاش برنمیخوری. امیدوارم تونسته باشم تو رفع بعضی شبهه\\u200cها واسه بعضی از دوستامون کمک کرده باشم.',\n","  'recommended')]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"tMwZ5KGrM-Hu"},"source":["Run on test set:"]},{"cell_type":"code","metadata":{"id":"n5H5nKjlUETq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627907741317,"user_tz":-270,"elapsed":371,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"c95919b0-987c-4fdb-a660-de7e4d9c5100"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon Aug  2 12:35:41 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   59C    P0    29W /  70W |   2952MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               85\n","Model name:          Intel(R) Xeon(R) CPU @ 2.00GHz\n","Stepping:            3\n","CPU MHz:             2000.196\n","BogoMIPS:            4000.39\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            1024K\n","L3 cache:            39424K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5TQbq9CaUEWR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627908012210,"user_tz":-270,"elapsed":264445,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"62d0d505-f17d-4df5-8e0c-6e81f3c706b3"},"source":["evaluation_output = sa_model.evaluation(test_comments, test_labels, device, batch_size=128)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["label_count: {'no_idea': 1053, 'not_recommended': 1610, 'recommended': 3696}\n","#samples: 6359\n","#batch: 50\n","Start to evaluate test data ...\n","inference time for step 0: 0.021711107999976775\n","inference time for step 1: 0.009519300000022213\n","inference time for step 2: 0.008498548999966715\n","inference time for step 3: 0.00833324199999197\n","inference time for step 4: 0.008346644999960517\n","inference time for step 5: 0.008350570999994034\n","inference time for step 6: 0.008309418000010282\n","inference time for step 7: 0.012603866000006292\n","inference time for step 8: 0.00870346200002814\n","inference time for step 9: 0.011439441999982591\n","inference time for step 10: 0.008671667000044181\n","inference time for step 11: 0.008683751999967626\n","inference time for step 12: 0.009544485999981589\n","inference time for step 13: 0.008480619000010847\n","inference time for step 14: 0.008510546000024988\n","inference time for step 15: 0.008697723000011592\n","inference time for step 16: 0.00917661500000122\n","inference time for step 17: 0.008664121999970575\n","inference time for step 18: 0.009380899000007048\n","inference time for step 19: 0.009830562999979975\n","inference time for step 20: 0.0086042149999912\n","inference time for step 21: 0.008988425000040934\n","inference time for step 22: 0.00829536899999539\n","inference time for step 23: 0.009071645999995326\n","inference time for step 24: 0.008265741000002436\n","inference time for step 25: 0.00807402599997431\n","inference time for step 26: 0.008011524999972153\n","inference time for step 27: 0.008791234999989683\n","inference time for step 28: 0.008986766000020907\n","inference time for step 29: 0.008147253000004184\n","inference time for step 30: 0.009128238000016609\n","inference time for step 31: 0.008726386000034836\n","inference time for step 32: 0.009710781000023871\n","inference time for step 33: 0.00963416000001871\n","inference time for step 34: 0.008228513999995357\n","inference time for step 35: 0.008928317000027164\n","inference time for step 36: 0.00844501599999603\n","inference time for step 37: 0.009187461999999869\n","inference time for step 38: 0.008626230999993822\n","inference time for step 39: 0.008658179000008204\n","inference time for step 40: 0.0080504000000019\n","inference time for step 41: 0.008793800999967516\n","inference time for step 42: 0.0086439519999999\n","inference time for step 43: 0.010268178999979227\n","inference time for step 44: 0.009247213999969972\n","inference time for step 45: 0.008027629000025627\n","inference time for step 46: 0.00830755900000213\n","inference time for step 47: 0.008905838000032418\n","inference time for step 48: 0.010414984000021832\n","inference time for step 49: 0.008663466000029985\n","average loss: 0.41636367082595827\n","total inference time: 0.45928910200007067\n","total inference time / #samples: 7.2226623997495e-05\n","Test Accuracy: 0.8471457776379934\n","Test Precision: 0.8362277804193979\n","Test Recall: 0.8471457776379934\n","Test F1-Score(weighted average): 0.8396886458175311\n","Test classification Report:\n","                 precision    recall  f1-score   support\n","\n","        no_idea  0.6039850560 0.4605887939 0.5226293103      1053\n","not_recommended  0.8478389580 0.8894409938 0.8681418612      1610\n","    recommended  0.8973364365 0.9388528139 0.9176252810      3696\n","\n","       accuracy                      0.8471457776      6359\n","      macro avg  0.7830534835 0.7629608672 0.7694654842      6359\n","   weighted avg  0.8362277804 0.8471457776 0.8396886458      6359\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"udST_qWCQ9hh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627908012211,"user_tz":-270,"elapsed":33,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"88919e69-2adf-4b41-ed85-699caf77a70d"},"source":["for comment, true_label, predicted_label in evaluation_output[:25]:\n","  print('{}\\t{}\\t{}'.format(comment, true_label, predicted_label))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["من اولین بار اینو از یه آرایشی بهداشتی خریدم که کلی شیفته ش شدم اما این بار از دیجی کالا خرید کردم و امروز به دستم رسید فوق العاده موها رو آبرسانی میکنه و نرم و صاف میکنه، ممنون دیجی\trecommended\trecommended\n","اصلا بدرد نمیخوره\tnot_recommended\tnot_recommended\n","یک ماه هست دارم هم باکیفیته هم کاربردی\tno_idea\trecommended\n","خیلی خوب نسبت به قیمت کیفیت خوب\trecommended\trecommended\n","شما نیاز به خرید هارد sata و ترجیحا آداپتور برای دوربین دارید. نصب آن آسان است و اگر از آداپتور مشترک استفاده می‌کنید مطمئن باشید سیم را درست نسب کنید. فقط یک سیم دارد و شاید آداپتور را باید ببرید و یا آداپتور دیگری بخرید. کیفیت دوربین خوب و نصب آن ساده است.\trecommended\trecommended\n","کیفیت ساختش نسبت به بقیه همرده‌ای خودش ظریف‌تر است که هم می‌تونه نقطه قوت هم ضعف باشه برای یک قطعه خودرو طول عمر خیلی مهمتر از ظرافت هست.\trecommended\tno_idea\n","سلام تراز ندارد وپایه‌های میخی آن پلاستیک است به عکس توجه نکنید\tnot_recommended\tnot_recommended\n","اصلا خوب نیست وهیچ عطری هم ندارد\tnot_recommended\tnot_recommended\n","در هنگام خواب مدم و دیگر وسایل که لازم ندارید را خاموش می‌کند.\trecommended\trecommended\n","من برای فیلم دیدن از فلش مموری استفاده میکنم و فیلم‌ها را از روی لپ تاپ میریزم روی فلش و فلشو میزنم به تلویزیون و تا مدت‌ها از فلش usb۲ استفاده میکردم و یه تایم طولانی باید صبر میکردم تا فیلم ریخته بشه روی فلش. ولی این فلش usb۳ میانگین سرعتش ۱۶تا۱۸ مگابایت بر ثانیه هستش یعنی ۲/۵ تا ۳ برابر فلش usb۲ خودم و راضیم ازش.\trecommended\trecommended\n","این محصول اشکال در نصب دارد در هنگام کپی کردن فایل‌های نصب توسط شرکت سازنده فایل‌ها و محتویات نصب رو بد کپی کرده هنگامی که به ۱ درصد نصب میرسی پیام میده یکی از فایلها مشکل کپی داره و دوباره تلاش کنید\tnot_recommended\tnot_recommended\n","این غذا ترکیبات خوبی داره اما فوق العاده آب آکواریوم رو کثیف میکنه. ضمن اینکه هیچ تاریخ انقضا یا تولیدی روی بسته بندی نیست که بتونید بفهمید غذا سالمه یا فاسد. در نتیجه با جون ماهی باید ریسک کرد!!\tno_idea\tnot_recommended\n","خیلی زیبا و شیک طراحی شده و با توجه به قیمتش کیفیتشم خوبه.. من در مجموع راضیم.. با تشکر از دی جی کالا\trecommended\trecommended\n","کاش به نظرات بیشتر دقت میکردم، فکر نکنم حتی یک ماه کار کنه\tnot_recommended\tno_idea\n","باطریش خوبه ۲روز شارژ نگه میداره سیم کارت میخوره مموری میخوره عکسبرداری داره ولی فیلم نمیگیره اتصال با بلوتوث صداش یکم ضعیفه در کل نسبت به قیمتش ساعت خوبیه (تاکید میکنم نسبت به قیمتش)\tno_idea\trecommended\n","از نظر قیمتش بهش می‌ارزه\trecommended\trecommended\n","سلام دوستان کار من تعمیرات کولر هستش خرداد ماه از دیجی خریدم تا الان دارم هر روز باهاش کار میکنم تا الان اخ نگفته کلی ضربه خورده و خیلی ازش کار میکشم نمیدونم بقیه چرا اینقد وسایل این سایتو زیر سوال میبرن من تا الان حدود ده وسیله برقی و غیره گرفتم کیفیتشون عالی بوده از تمامشونم راضیم هرکی باهاش مشکل داره مرجوع کنه تا هفت روز خیلی راحت مرجوعیو قبول میکنه بخرید با خیال راحت یا علی\trecommended\trecommended\n","کفش بدی نیست. طراحی و کیفیت مناسبی داره. من برای پیاده روی و ورزش مثل والیبال و فوتسال گرفتم. پا داخلش راحته و به نظرم دوام دوام خوبی داشته باشه. سایزش هم درسته و لازم نیست کوچکتر و ‌ بزرگتر سفارش بدید\tno_idea\trecommended\n","کاملا گیاهیه و مسواک زدن باهاش حس خوبی داره من که مشتری همیشگیشم\trecommended\trecommended\n","من تو نقدش تو سایت رومیزی و آموزش بازی تو آپارات دیدم اسطورلاب فلزیه ولی وقتی خریدم مقوایی بود که خورد تو ذوقم چرا باید تو تبلیغ ایونجوری باشه ولی موقع فروش این کیفیت، حس خویب نداره.\tno_idea\tno_idea\n","من راضیم. همه چیش خوبه\trecommended\trecommended\n","قدرت بادش حتی از یه سشوار ۸۰۰ واتی هم کمتره\tnot_recommended\tnot_recommended\n","من خودم لووا و مندل دارم ولی با این افزایش قیمتا اینو گرفتم دم دستی بپوشم اونا سالم بمونن. اگه کفش خوب پوشیده باشی این کفش دلتو نمیبره ولی اگه اولین کفش تقریبا حرفه ایت باشه کلی ذوق می‌کنی بپوشی! تو توضیحات نوشته ضد آب ولی ضد آب نیست بعد از تقریبا یک ساعت توی آب گذاشتن کفش یه مقدار کوچیکی نم احساس میشه رویه‌ی چرم مصنوعی (جیر) که داره کاملا آبو جذب می‌کنه عین حوله! یعنی تو برف و یخ، شل آب یا حتی بارون باعث میشه پاها سرد بشن. زیره‌اش ویبرامه ولی با ویبرام اسکارپای ۳ میلیونی زمین تا آسمون فرق داره آنچنان تهویه‌ای نداره ولی احساس سونا بخارم توش نخواهید داشت! با همه‌ی این اوصاف پا توش راحته برای ترکینگای سبک ۴ فصل مثل دربند و درکه و شاید حتی قله‌ی توچال تو هوای مناسب قابل استفاده است. اگه بودجتون همینقدره شک نکنید بخرید، با ۲۰۰ تومن بیشتر میتونید ترکینگ ۳ فصل کریمور بگیرید که دیجیکالا داره ولی ساقش کوتاست پیشنهاد نمیدم.\tno_idea\trecommended\n","اصلا خوب نیست من خریدم. بعد از چند روز عوضش کردم رفتم گلس خریدم مقاومتش خوب نبود وبا گارد چسبندگی طرافش در میومد.\tnot_recommended\tnot_recommended\n","اصلا به درد نمیخوره و به قیمتش نمیارزه. حتی امتحانش هم نکنید\tnot_recommended\tnot_recommended\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LhogPF04CKuX"},"source":["output_file_name = \"sentiment_analysis_digikala_testset_{}_outputs.txt\".format(model_name.replace('/','-'))\n","with open(output_file_name, \"w\", encoding='utf8') as output_file:\n","  for comment, true_label, predicted_label in evaluation_output:\n","    output_file.write('{}\\t{}\\t{}\\n'.format(comment, true_label, predicted_label))\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","upload = drive.CreateFile({'title': output_file_name})\n","upload.SetContentFile(output_file_name)\n","upload.Upload()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iZP0OBvjNoz4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"blsMX3n_15Gr"},"source":[""],"execution_count":null,"outputs":[]}]}