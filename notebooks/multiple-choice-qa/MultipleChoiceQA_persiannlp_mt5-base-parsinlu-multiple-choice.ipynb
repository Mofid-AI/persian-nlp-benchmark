{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MultipleChoiceQA/persiannlp/mt5-base-parsinlu-multiple-choice.ipynb","provenance":[{"file_id":"1c5WvqQKKZnab7GsUVa6fi1Q8vYwvlLTc","timestamp":1624943579756}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1ce98b79d7674ddf8e9fad6757934530":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4b3b7bf2ad94419a972e70b178f5a759","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_11bddf8fa04c4df9bdeae940dafee334","IPY_MODEL_2d37b21611b44a77aeb8211080e4c3c5","IPY_MODEL_f43fb59fe5fb41dcb0e9ace8fe6186aa"]}},"4b3b7bf2ad94419a972e70b178f5a759":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"11bddf8fa04c4df9bdeae940dafee334":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_29bf1fb0e2cd4858bef557b5704f5333","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1c829ca4db99435699a7ce7c90a3eba2"}},"2d37b21611b44a77aeb8211080e4c3c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a1de1fe31ebf427d913eb8c9a2129409","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4309802,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4309802,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_385832a5f5be4c9887a05d8030fb647b"}},"f43fb59fe5fb41dcb0e9ace8fe6186aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_217cee59b7c94b11910197922bf64b77","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4.31M/4.31M [00:00&lt;00:00, 7.15MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ff89ca42239149d3908367067f577297"}},"29bf1fb0e2cd4858bef557b5704f5333":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1c829ca4db99435699a7ce7c90a3eba2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a1de1fe31ebf427d913eb8c9a2129409":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"385832a5f5be4c9887a05d8030fb647b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"217cee59b7c94b11910197922bf64b77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ff89ca42239149d3908367067f577297":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bade3bd4961e49b08eb6996ba48a18f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ec8a644424864ea18e9d6550fe8ae98d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b979b0821c6842618dccea02ba98f8f4","IPY_MODEL_d9f763e2fa824761bf0341bc6061e0f2","IPY_MODEL_c45515697f644daf81c2f435a6a5058b"]}},"ec8a644424864ea18e9d6550fe8ae98d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b979b0821c6842618dccea02ba98f8f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1e9f15a054424f3c8cae77756230785f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a60a48632f13446da4416ca6a6947dee"}},"d9f763e2fa824761bf0341bc6061e0f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0c4b4eb7b49647549764f66add0a255a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":65,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":65,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_550108be22c64caca9f3be2b994d4ea5"}},"c45515697f644daf81c2f435a6a5058b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f7a9fbf2337b47ef800ce31d1a0bf773","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 65.0/65.0 [00:00&lt;00:00, 1.74kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_08e72a96c7da4064957311adefc2444b"}},"1e9f15a054424f3c8cae77756230785f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a60a48632f13446da4416ca6a6947dee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0c4b4eb7b49647549764f66add0a255a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"550108be22c64caca9f3be2b994d4ea5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f7a9fbf2337b47ef800ce31d1a0bf773":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"08e72a96c7da4064957311adefc2444b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cfb9e5b295d44ac6aaa9e2e9bc0be7cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5aa0b9fe53354d8194c1b21d5d09ba2e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8dd290b4fd464267a80e39a77c53f100","IPY_MODEL_ffb233c988304d88a704343ba34e05d4","IPY_MODEL_9d884a50d6934486a0c894acdf57b39e"]}},"5aa0b9fe53354d8194c1b21d5d09ba2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8dd290b4fd464267a80e39a77c53f100":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9176a67697dd4437bb3a1e3b4620efa0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_620bfe399bb644c5895b577b2a7f9748"}},"ffb233c988304d88a704343ba34e05d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f2828d678e7243fbb757925593f99862","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":375,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":375,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3b4e32037a3f4609afa215a52789b5a4"}},"9d884a50d6934486a0c894acdf57b39e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_be8cd6096ef7472eaac56583bd4d0480","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 375/375 [00:00&lt;00:00, 10.0kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_63754f701cd5472d8772233fe99d1ac1"}},"9176a67697dd4437bb3a1e3b4620efa0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"620bfe399bb644c5895b577b2a7f9748":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2828d678e7243fbb757925593f99862":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3b4e32037a3f4609afa215a52789b5a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"be8cd6096ef7472eaac56583bd4d0480":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"63754f701cd5472d8772233fe99d1ac1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c2815ec6fce745c6afc8430441cc7f0e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d10ec507125d4874a5c1e9f6c880038c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fbaa6a89a7a94effb6e3714707f30a77","IPY_MODEL_23d1a590deac4b69b48a640a9ce95208","IPY_MODEL_4af4910f76754df2b615d93e3ee4dfc8"]}},"d10ec507125d4874a5c1e9f6c880038c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fbaa6a89a7a94effb6e3714707f30a77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a99233ed74df4d34b18a0919ffbbe96f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_07bfdf09452e411d84c2d546eaa71de3"}},"23d1a590deac4b69b48a640a9ce95208":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e32509ed55fa42ecb55d7908c83e7b01","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":694,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":694,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_73446817d9134d31b3f44422d020001d"}},"4af4910f76754df2b615d93e3ee4dfc8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_62ce8e30a24e4c4db685e8b2cd3e00e8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 694/694 [00:00&lt;00:00, 16.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a6562154d56a48f59d641fb4faac501d"}},"a99233ed74df4d34b18a0919ffbbe96f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"07bfdf09452e411d84c2d546eaa71de3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e32509ed55fa42ecb55d7908c83e7b01":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"73446817d9134d31b3f44422d020001d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"62ce8e30a24e4c4db685e8b2cd3e00e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a6562154d56a48f59d641fb4faac501d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6f5cce0c8bbc4f0fb9b9a7bc5aa4c699":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_30114ce50ed843479b154e7200fe963b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7fbda1a8524b4ba397f0ea919fbd8f2e","IPY_MODEL_30242a96007b4525a1249383ec4fdd1c","IPY_MODEL_54e7e465af034e0ebffa30901cf5228f"]}},"30114ce50ed843479b154e7200fe963b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7fbda1a8524b4ba397f0ea919fbd8f2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ef0f5eccd6b64739b45bbf845acfe7d7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c2d395848c814298803df338a7b0ace7"}},"30242a96007b4525a1249383ec4fdd1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fe5758a884144f5980b621ba80326b72","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2329735667,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2329735667,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_30cb3de19c134dd79feb86e5c7b84915"}},"54e7e465af034e0ebffa30901cf5228f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_60f6024adda7475097bd00903027c147","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.33G/2.33G [01:36&lt;00:00, 30.2MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5551239fe3bf48c58573f186f491f74d"}},"ef0f5eccd6b64739b45bbf845acfe7d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c2d395848c814298803df338a7b0ace7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe5758a884144f5980b621ba80326b72":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"30cb3de19c134dd79feb86e5c7b84915":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"60f6024adda7475097bd00903027c147":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5551239fe3bf48c58573f186f491f74d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"EVTLnae70XUx"},"source":["# Multiple-Choice Question Answering"]},{"cell_type":"code","metadata":{"id":"o_zHi1zlwyXb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950450288,"user_tz":-270,"elapsed":650,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"748ef3d0-b586-4701-b28c-b0dc10b969a7"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sat Aug 14 14:14:09 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   69C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               63\n","Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n","Stepping:            0\n","CPU MHz:             2299.998\n","BogoMIPS:            4599.99\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            256K\n","L3 cache:            46080K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4knw0YgC0SfX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950489109,"user_tz":-270,"elapsed":38826,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"95b5bdf8-c080-4d5f-990d-6f9c75185ce4"},"source":["!pip install hazm==0.7.0\n","!pip install seqeval==1.2.2\n","!pip install sentencepiece==0.1.96\n","!pip install transformers==4.7.0\n","!pip install clean-text[gpl]==0.4.0\n","!pip install editdistance==0.5.3"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting hazm==0.7.0\n","  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 51 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 61 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 71 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 81 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 92 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 102 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 112 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 122 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 133 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 143 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 153 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 163 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 174 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 184 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 194 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 204 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 215 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 225 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 235 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 245 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 256 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 266 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 276 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 286 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 296 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 307 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 316 kB 13.9 MB/s \n","\u001b[?25hCollecting nltk==3.3\n","  Downloading nltk-3.3.0.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 30.1 MB/s \n","\u001b[?25hCollecting libwapiti>=0.2.1\n","  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n","\u001b[K     |████████████████████████████████| 233 kB 45.5 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm==0.7.0) (1.15.0)\n","Building wheels for collected packages: nltk, libwapiti\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394485 sha256=46bec6812e2ee6e93e5c4b235eb9c308e3c3a19b13cbad9ceb8033c588c2ec3d\n","  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n","  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154588 sha256=1318309ae287bb8ff28cdcbd02a2ef2609b4d59cca25ecec7410113036dd6896\n","  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n","Successfully built nltk libwapiti\n","Installing collected packages: nltk, libwapiti, hazm\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n","Collecting seqeval==1.2.2\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.4.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=470e078d84744178f54ab48ee493f86ff15db96ebe799e8483edd0ef53b5e1ef\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Collecting sentencepiece==0.1.96\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 12.9 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting transformers==4.7.0\n","  Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 12.0 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 41.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (2.23.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (3.13)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (2019.12.20)\n","Collecting huggingface-hub==0.0.8\n","  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (21.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 41.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (4.6.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (4.62.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0) (3.5.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.7.0) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (2021.5.30)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (7.1.2)\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.7.0\n","Collecting clean-text[gpl]==0.4.0\n","  Downloading clean_text-0.4.0-py3-none-any.whl (9.8 kB)\n","Collecting emoji\n","  Downloading emoji-1.4.2.tar.gz (184 kB)\n","\u001b[K     |████████████████████████████████| 184 kB 12.7 MB/s \n","\u001b[?25hCollecting ftfy<7.0,>=6.0\n","  Downloading ftfy-6.0.3.tar.gz (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 2.7 MB/s \n","\u001b[?25hCollecting unidecode<2.0.0,>=1.1.1\n","  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n","\u001b[K     |████████████████████████████████| 241 kB 50.0 MB/s \n","\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy<7.0,>=6.0->clean-text[gpl]==0.4.0) (0.2.5)\n","Building wheels for collected packages: ftfy, emoji\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=ab9a69889c0df4e99cadf5b1699693fcc36a18904a2d9eae54216fa21f63e6dc\n","  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186469 sha256=baa465ec9d4ab9a20ec55f75117a83fd47e4653c80aba006a2479fb6f32333e5\n","  Stored in directory: /root/.cache/pip/wheels/e4/61/e7/2fc1ac8f306848fc66c6c013ab511f0a39ef4b1825b11363b2\n","Successfully built ftfy emoji\n","Installing collected packages: ftfy, emoji, unidecode, clean-text\n","Successfully installed clean-text-0.4.0 emoji-1.4.2 ftfy-6.0.3 unidecode-1.2.0\n","Requirement already satisfied: editdistance==0.5.3 in /usr/local/lib/python3.7/dist-packages (0.5.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rS4Rw-0iYEtd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950517392,"user_tz":-270,"elapsed":28308,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"c5bba4bc-7d29-4ed0-d7bb-487c3f979bc7"},"source":["!pip install PyDrive\n","import os\n","import IPython.display as ipd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: PyDrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (1.12.8)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.34.0)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n","Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.26.3)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.17.3)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2018.9)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (57.2.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (21.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.23.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.53.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (0.2.8)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2021.5.30)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HjQo6WGZ2aK5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950531525,"user_tz":-270,"elapsed":8548,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"f86bf736-6181-4b30-de2b-4a539adfc28e"},"source":["# Import required packages\n","import os\n","import gc\n","import re\n","import hazm\n","import time\n","import json\n","import collections\n","import numpy as np\n","import pandas as pd\n","import editdistance\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","import transformers\n","from transformers import AutoConfig, AutoTokenizer\n","from transformers import AutoModelForMultipleChoice\n","from transformers import MT5Config, MT5ForConditionalGeneration, MT5Tokenizer\n","from transformers.data.metrics.squad_metrics import compute_exact, compute_f1\n","\n","from cleantext import clean\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","\n","print()\n","print('numpy', np.__version__)\n","print('pandas', pd.__version__)\n","print('transformers', transformers.__version__)\n","print('torch', torch.__version__)\n","print()\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\n","numpy 1.19.5\n","pandas 1.1.5\n","transformers 4.7.0\n","torch 1.9.0+cu102\n","\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5vC31D-N0Shj","executionInfo":{"status":"ok","timestamp":1628950532183,"user_tz":-270,"elapsed":661,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}}},"source":["class MultipleChoiceQADataset(torch.utils.data.Dataset):\n","    \"\"\" Create a PyTorch dataset for Multiple Choice Question Answering. \"\"\"\n","\n","    def __init__(self, questions, candidates, choices, answers, tokenizer, max_length, model_type):\n","        self.questions = questions\n","        self.candidates = candidates\n","        self.choices = choices\n","        self.answers = answers\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.model_type = model_type\n","\n","    def __len__(self):\n","        return len(self.questions)\n","\n","    def __getitem__(self, item):\n","        if self.model_type == \"mt5\":\n","            input_text = self.questions[item] + ' <sep> ' + ' <sep> '.join(self.candidates[item])\n","            encoding = self.tokenizer(\n","                input_text,\n","                add_special_tokens=True,\n","                max_length=self.max_length,\n","                truncation=True,\n","                padding='max_length',\n","                return_tensors=\"pt\"\n","            )\n","            inputs = {\n","                'item': str(item),\n","                'question': self.questions[item],\n","                'candidates': ' <sep> '.join(self.candidates[item]),\n","                'input_text': input_text,\n","                'choice': self.choices[item],\n","                'answer': self.answers[item],\n","                'input_ids': encoding.input_ids.flatten(),\n","                'attention_mask': encoding.attention_mask.flatten()\n","            }\n","            return inputs\n","        else:\n","            choices_input_ids, choices_attention_masks, choices_token_type_ids = [], [], []\n","            for c in self.candidates[item]:\n","                text_a = \"\"  # empty context\n","                text_b = self.questions[item] + \" \" + c\n","                inputs = self.tokenizer(\n","                    text_a,\n","                    text_b,\n","                    add_special_tokens=True,\n","                    max_length=self.max_length,\n","                    padding=\"max_length\",\n","                    truncation=True,\n","                    return_overflowing_tokens=True\n","                )\n","                choices_input_ids.append(inputs.input_ids[0])\n","                choices_attention_masks.append(inputs.attention_mask[0])\n","                choices_token_type_ids.append(inputs.token_type_ids[0])\n","\n","            inputs = {\n","                'item': str(item),\n","                'question': self.questions[item],\n","                'candidates': ' <sep> '.join(self.candidates[item]),\n","                'choice': int(self.choices[item]) - 1,\n","                'answer': self.answers[item],\n","                'input_ids': torch.LongTensor(choices_input_ids),\n","                'attention_mask': torch.LongTensor(choices_attention_masks),\n","                'token_type_ids': torch.LongTensor(choices_token_type_ids)\n","            }\n","            return inputs\n","\n","\n","class MultipleChoiceQA:\n","    def __init__(self, model_name, model_type):\n","        self.normalizer = hazm.Normalizer()\n","        self.model_name = model_name\n","        if model_type.lower() == \"mt5\":\n","            self.tokenizer = MT5Tokenizer.from_pretrained(model_name)\n","            self.model = MT5ForConditionalGeneration.from_pretrained(model_name)\n","            self.config = MT5Config.from_pretrained(self.model_name)\n","        elif model_type.lower() in [\"mbert\", \"parsbert\", \"wikibert\"]:\n","            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n","            self.config = AutoConfig.from_pretrained(self.model_name)\n","            self.model = AutoModelForMultipleChoice.from_pretrained(self.model_name, config=self.config)\n","            self.model_type = model_type.lower()\n","        else:\n","            print(f'model_type not supported!')\n","            return\n","\n","    def load_dataset_test_file(self, dataset_name, dataset_file, **kwargs):\n","        if dataset_name.lower() in [\"parsinlu\", \"parsinlu-literature\", \"parsinlu-math_and_logic\",\n","                                    \"parsinlu-common_knowledge\"]:\n","            if not os.path.exists(dataset_file):\n","                print(f'{dataset_file} not exists!')\n","                return\n","            questions, candidates, choices, answers = [], [], [], []\n","            with open(dataset_file, encoding=\"utf8\") as infile:\n","                for line in infile:\n","                    json_line = json.loads(line.strip())\n","                    question = json_line['question']\n","                    candidate_answers = json_line['candidates']\n","                    choice = json_line['answer']\n","                    answer = candidate_answers[int(json_line['answer']) - 1]\n","\n","                    questions.append(question)\n","                    candidates.append(candidate_answers)\n","                    choices.append(choice)\n","                    answers.append(answer)\n","            return questions, candidates, choices, answers\n","\n","    def multiple_choice_qa_inference(self, questions, candidates, device, max_length=512):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        input_ids, attention_masks, token_type_ids = [], [], []\n","        for q, cs in zip(questions, candidates):\n","            choices_input_ids, choices_attention_masks, choices_token_type_ids = [], [], []\n","            for c in cs:\n","                text_a = \"\"  # empty context\n","                text_b = q + \" \" + c\n","                inputs = self.tokenizer(\n","                    text_a,\n","                    text_b,\n","                    add_special_tokens=True,\n","                    max_length=max_length,\n","                    padding=\"max_length\",\n","                    truncation=True,\n","                    return_overflowing_tokens=True,\n","                )\n","                choices_input_ids.append(inputs.input_ids[0])\n","                choices_attention_masks.append(inputs.attention_mask[0])\n","                choices_token_type_ids.append(inputs.token_type_ids[0])\n","            input_ids.append(choices_input_ids)\n","            attention_masks.append(choices_attention_masks)\n","            token_type_ids.append(choices_token_type_ids)\n","\n","        input_ids = torch.LongTensor(input_ids).to(device)\n","        attention_masks = torch.LongTensor(attention_masks).to(device)\n","        token_type_ids = torch.LongTensor(token_type_ids).to(device)\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        outputs = self.model(input_ids=input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids)\n","        predictions = torch.argmax(outputs.logits, dim=1)\n","        return [(questions[i], candidates[i], candidates[i][p.item()]) for i, p in enumerate(predictions)]\n","\n","    def mt5_multiple_choice_qa_inference(self, questions, candidates, device):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        new_input = []\n","        for q, cs in zip(questions, candidates):\n","            new_input.append(q + ' <sep> ' + ' <sep> '.join(cs))\n","\n","        tokenized_batch = self.tokenizer(\n","            new_input,\n","            padding=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        input_ids = tokenized_batch.input_ids.to(device)\n","        attention_mask = tokenized_batch.attention_mask.to(device)\n","\n","        outputs = self.model.generate(input_ids=input_ids, attention_mask=attention_mask)\n","        predictions = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","        return [(questions[i], candidates[i], p) for i, p in enumerate(predictions)]\n","\n","    def evaluation(self, questions, candidates, choices, answers, device, max_length, batch_size=4):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","        if len(questions) != len(candidates):\n","            print('length of two inputs is not equal!!')\n","            return\n","        if len(choices) != len(answers):\n","            print('length of choices and answers is not equal!!')\n","            return\n","        if len(questions) != len(answers):\n","            print('length of inputs and answers is not equal!!')\n","            return\n","\n","        dataset = MultipleChoiceQADataset(questions=questions, candidates=candidates, choices=choices, answers=answers,\n","                                          tokenizer=self.tokenizer, max_length=max_length, model_type=self.model_type)\n","        data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n","        print(f'#question:{len(questions)}, #candidates:{len(candidates)}, #answer:{len(answers)}')\n","        print(\"#batch:\", len(data_loader))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        total_loss, total_time = 0, 0\n","        output_predictions = []\n","        golden_choices, predicted_choices = [], []\n","        print(\"Start to evaluate test data ...\")\n","        for step, batch in enumerate(data_loader):\n","            b_input_ids = batch['input_ids']\n","            b_attention_mask = batch['attention_mask']\n","            b_token_type_ids = batch['token_type_ids']\n","            b_choices = batch['choice']\n","\n","            # move tensors to GPU if CUDA is available\n","            b_input_ids = b_input_ids.to(device)\n","            b_attention_mask = b_attention_mask.to(device)\n","            b_token_type_ids = b_token_type_ids.to(device)\n","            b_choices = b_choices.to(device)\n","\n","            # This will return the loss (rather than the model output) because we have provided the `labels`.\n","            with torch.no_grad():\n","                start = time.monotonic()\n","                b_outputs = self.model(input_ids=b_input_ids, attention_mask=b_attention_mask,\n","                                       token_type_ids=b_token_type_ids, labels=b_choices)\n","                end = time.monotonic()\n","                total_time += end - start\n","                print(f'inference time for step {step}: {end - start}')\n","            # get the loss\n","            total_loss += b_outputs.loss.item()\n","\n","            golden_choices.extend(b_choices.cpu().detach().numpy().tolist())\n","            b_predictions = torch.argmax(b_outputs.logits, dim=1)\n","            b_predictions = b_predictions.cpu().detach().numpy().tolist()\n","            predicted_choices.extend(b_predictions)\n","\n","            for i in range(len(b_input_ids)):\n","                output_predictions.append((\n","                    batch['question'][i],\n","                    batch['candidates'][i].split(' <sep> '),\n","                    batch['choice'][i].item(),\n","                    batch['answer'][i],\n","                    b_predictions[i],\n","                    batch['candidates'][i].split(' <sep> ')[b_predictions[i]]\n","                ))\n","\n","        # Calculate the average loss over the training data.\n","        avg_train_loss = total_loss / len(data_loader)\n","        print(\"average loss:\", avg_train_loss)\n","\n","        print(\"total inference time:\", total_time)\n","        print(\"total inference time / #samples:\", total_time / len(questions))\n","\n","        # evaluate\n","        print(\"Test Accuracy: {}\".format(accuracy_score(golden_choices, predicted_choices)))\n","        print(\"Test Precision: {}\".format(precision_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test Recall: {}\".format(recall_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test F1-Score(weighted average): {}\".format(\n","            f1_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test classification Report:\\n{}\".format(\n","            classification_report(golden_choices, predicted_choices, digits=10)))\n","        return output_predictions\n","\n","    def mt5_evaluation(self, questions, candidates, choices, answers, device, max_length, batch_size=4):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","        if len(questions) != len(candidates):\n","            print('length of two inputs is not equal!!')\n","            return\n","        if len(choices) != len(answers):\n","            print('length of choices and answers is not equal!!')\n","            return\n","        if len(questions) != len(answers):\n","            print('length of inputs and answers is not equal!!')\n","            return\n","\n","        dataset = MultipleChoiceQADataset(questions=questions, candidates=candidates, choices=choices, answers=answers,\n","                                          tokenizer=self.tokenizer, max_length=max_length, model_type=\"mt5\")\n","        data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n","        print(f'#question:{len(questions)}, #candidates:{len(candidates)}, #answer:{len(answers)}')\n","        print(\"#batch:\", len(data_loader))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        total_time = 0\n","        output_predictions = []\n","        golden_choices, predicted_choices, exact_score_list, f1_score_list = [], [], [], []\n","        print(\"Start to evaluate test data ...\")\n","        for step, batch in enumerate(data_loader):\n","            b_input_ids = batch['input_ids']\n","            b_attention_mask = batch['attention_mask']\n","\n","            # move tensors to GPU if CUDA is available\n","            b_input_ids = b_input_ids.to(device)\n","            b_attention_mask = b_attention_mask.to(device)\n","\n","            # This will return the loss (rather than the model output) because we have provided the `labels`.\n","            with torch.no_grad():\n","                start = time.monotonic()\n","                b_outputs = self.model.generate(input_ids=b_input_ids, attention_mask=b_attention_mask)\n","                end = time.monotonic()\n","                total_time += end - start\n","                print(f'inference time for step {step}: {end - start}')\n","\n","            b_predictions = self.tokenizer.batch_decode(b_outputs, skip_special_tokens=True)\n","\n","            for i in range(len(b_input_ids)):\n","                if b_predictions[i] in batch['candidates'][i].split(' <sep> '):\n","                    predicted_choice = str(batch['candidates'][i].split(' <sep> ').index(b_predictions[i]) + 1)\n","                else:\n","                    normalized_edit_distance_list = [\n","                        editdistance.distance(ca, b_predictions[i]) / max(len(ca), len(b_predictions[i])) for ca in\n","                        batch['candidates'][i].split(' <sep> ')\n","                    ]\n","                    predicted_choice = str(normalized_edit_distance_list.index(min(normalized_edit_distance_list)) + 1)\n","\n","                golden_choices.append(batch['choice'][i])\n","                predicted_choices.append(predicted_choice)\n","\n","                exact_score_list.append(compute_exact(batch['answer'][i], b_predictions[i]))\n","                f1_score_list.append(compute_f1(batch['answer'][i], b_predictions[i]))\n","\n","                output_predictions.append((\n","                    batch['question'][i],\n","                    batch['candidates'][i].split(' <sep> '),\n","                    batch['choice'][i],\n","                    batch['answer'][i],\n","                    predicted_choice,\n","                    b_predictions[i],\n","                    exact_score_list[-1],\n","                    f1_score_list[-1]\n","                ))\n","\n","        print(\"total inference time:\", total_time)\n","        print(\"total inference time / #samples:\", total_time / len(questions))\n","\n","        # evaluate\n","        print(\"Test Accuracy: {}\".format(accuracy_score(golden_choices, predicted_choices)))\n","        print(\"Test Precision: {}\".format(precision_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test Recall: {}\".format(recall_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test F1-Score(weighted average): {}\".format(\n","            f1_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test classification Report:\\n{}\".format(\n","            classification_report(golden_choices, predicted_choices, digits=10)))\n","\n","        total = len(exact_score_list)\n","        evaluation_results = collections.OrderedDict(\n","            [\n","                (\"exact\", 100.0 * sum(exact_score_list) / total),\n","                (\"f1\", 100.0 * sum(f1_score_list) / total),\n","                (\"total\", total),\n","            ]\n","        )\n","        print(\"evaluation results:\\n\", evaluation_results)\n","\n","        return output_predictions\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"VD0FH_FF2oTy","colab":{"base_uri":"https://localhost:8080/","height":698,"referenced_widgets":["1ce98b79d7674ddf8e9fad6757934530","4b3b7bf2ad94419a972e70b178f5a759","11bddf8fa04c4df9bdeae940dafee334","2d37b21611b44a77aeb8211080e4c3c5","f43fb59fe5fb41dcb0e9ace8fe6186aa","29bf1fb0e2cd4858bef557b5704f5333","1c829ca4db99435699a7ce7c90a3eba2","a1de1fe31ebf427d913eb8c9a2129409","385832a5f5be4c9887a05d8030fb647b","217cee59b7c94b11910197922bf64b77","ff89ca42239149d3908367067f577297","bade3bd4961e49b08eb6996ba48a18f7","ec8a644424864ea18e9d6550fe8ae98d","b979b0821c6842618dccea02ba98f8f4","d9f763e2fa824761bf0341bc6061e0f2","c45515697f644daf81c2f435a6a5058b","1e9f15a054424f3c8cae77756230785f","a60a48632f13446da4416ca6a6947dee","0c4b4eb7b49647549764f66add0a255a","550108be22c64caca9f3be2b994d4ea5","f7a9fbf2337b47ef800ce31d1a0bf773","08e72a96c7da4064957311adefc2444b","cfb9e5b295d44ac6aaa9e2e9bc0be7cd","5aa0b9fe53354d8194c1b21d5d09ba2e","8dd290b4fd464267a80e39a77c53f100","ffb233c988304d88a704343ba34e05d4","9d884a50d6934486a0c894acdf57b39e","9176a67697dd4437bb3a1e3b4620efa0","620bfe399bb644c5895b577b2a7f9748","f2828d678e7243fbb757925593f99862","3b4e32037a3f4609afa215a52789b5a4","be8cd6096ef7472eaac56583bd4d0480","63754f701cd5472d8772233fe99d1ac1","c2815ec6fce745c6afc8430441cc7f0e","d10ec507125d4874a5c1e9f6c880038c","fbaa6a89a7a94effb6e3714707f30a77","23d1a590deac4b69b48a640a9ce95208","4af4910f76754df2b615d93e3ee4dfc8","a99233ed74df4d34b18a0919ffbbe96f","07bfdf09452e411d84c2d546eaa71de3","e32509ed55fa42ecb55d7908c83e7b01","73446817d9134d31b3f44422d020001d","62ce8e30a24e4c4db685e8b2cd3e00e8","a6562154d56a48f59d641fb4faac501d","6f5cce0c8bbc4f0fb9b9a7bc5aa4c699","30114ce50ed843479b154e7200fe963b","7fbda1a8524b4ba397f0ea919fbd8f2e","30242a96007b4525a1249383ec4fdd1c","54e7e465af034e0ebffa30901cf5228f","ef0f5eccd6b64739b45bbf845acfe7d7","c2d395848c814298803df338a7b0ace7","fe5758a884144f5980b621ba80326b72","30cb3de19c134dd79feb86e5c7b84915","60f6024adda7475097bd00903027c147","5551239fe3bf48c58573f186f491f74d"]},"executionInfo":{"status":"ok","timestamp":1628950644419,"user_tz":-270,"elapsed":112240,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"c1e02f6c-ab36-42e3-a0c5-0dda9692e540"},"source":["model_name='persiannlp/mt5-base-parsinlu-multiple-choice'\n","mcqa_model = MultipleChoiceQA(model_name=model_name, model_type=\"mt5\")\n","print(mcqa_model.config)"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ce98b79d7674ddf8e9fad6757934530","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bade3bd4961e49b08eb6996ba48a18f7","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cfb9e5b295d44ac6aaa9e2e9bc0be7cd","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/375 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2815ec6fce745c6afc8430441cc7f0e","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/694 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["You are using a model of type t5 to instantiate a model of type mt5. This is not supported for all configurations of models and can yield errors.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f5cce0c8bbc4f0fb9b9a7bc5aa4c699","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["You are using a model of type t5 to instantiate a model of type mt5. This is not supported for all configurations of models and can yield errors.\n"],"name":"stderr"},{"output_type":"stream","text":["MT5Config {\n","  \"_name_or_path\": \"/home/patrick/hugging_face/t5/mt5-base\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 2048,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"gated-gelu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"mt5\",\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"T5Tokenizer\",\n","  \"transformers_version\": \"4.7.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 250112\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_evY3NSRHQFu"},"source":["## Sample Inference"]},{"cell_type":"code","metadata":{"id":"LPd1N8CMQ07t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950656063,"user_tz":-270,"elapsed":11669,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"10e187e6-54a9-42cb-e87c-e85c6d192bf1"},"source":["question_list = [\n","    \"وسیع ترین کشور جهان کدام است؟\",\n","    \"طامع یعنی ؟\",\n","    \"زمینی به ۳۱ قطعه متساوی مفروض شده است و هر روز مساحت آماده شده برای احداث، دو برابر مساحت روز قبل است.اگر پس از (۵ روز) تمام زمین آماده شده باشد، در چه روزی یک قطعه زمین آماده شده\"\n","]\n","candidate_list=[\n","    [\"آمریکا\", \"کانادا\", \"روسیه\", \"چین\"],\n","    [\"آزمند\", \"خوش شانس\", \"محتاج\", \"مطمئن\"],\n","    [\"روز اول\", \"روز دوم\", \"روز سوم\", \"هیچکدام\"]\n","]\n","mcqa_model.mt5_multiple_choice_qa_inference(question_list, candidate_list, device)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('وسیع ترین کشور جهان کدام است؟',\n","  ['آمریکا', 'کانادا', 'روسیه', 'چین'],\n","  'چین'),\n"," ('طامع یعنی ؟', ['آزمند', 'خوش شانس', 'محتاج', 'مطمئن'], 'محتاج'),\n"," ('زمینی به ۳۱ قطعه متساوی مفروض شده است و هر روز مساحت آماده شده برای احداث، دو برابر مساحت روز قبل است.اگر پس از (۵ روز) تمام زمین آماده شده باشد، در چه روزی یک قطعه زمین آماده شده',\n","  ['روز اول', 'روز دوم', 'روز سوم', 'هیچکدام'],\n","  'روز اول')]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"XEWiWbu621Tk"},"source":["## Multiple-Choice Dataset\n"]},{"cell_type":"code","metadata":{"id":"pC7QvccoSgPY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950662348,"user_tz":-270,"elapsed":6289,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"b524eb9e-fc68-482a-b2f7-7adcaea42c2d"},"source":["!git clone https://github.com/persiannlp/parsinlu\n","!ls parsinlu\n","!ls parsinlu/data/multiple-choice/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Cloning into 'parsinlu'...\n","remote: Enumerating objects: 1434, done.\u001b[K\n","remote: Counting objects: 100% (182/182), done.\u001b[K\n","remote: Compressing objects: 100% (98/98), done.\u001b[K\n","remote: Total 1434 (delta 110), reused 139 (delta 82), pack-reused 1252\u001b[K\n","Receiving objects: 100% (1434/1434), 27.81 MiB | 16.91 MiB/s, done.\n","Resolving deltas: 100% (913/913), done.\n","data  LICENSE  README.md  requirements.txt  scripts  src\n","test_ck.jsonl  test_lit.jsonl  train.jsonl\n","test.jsonl     test_ml.jsonl   valid.jsonl\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ilPBM7goGNYW"},"source":["### Samples with literature as their category"]},{"cell_type":"code","metadata":{"id":"Ieg7Y37QSgSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950662349,"user_tz":-270,"elapsed":15,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"5b4d1b43-f9ce-4462-9662-9cbe63830e42"},"source":["test_questions_lit, test_candidates_lit, test_choices_lit, test_answers_lit = mcqa_model.load_dataset_test_file(\n","    dataset_name=\"parsinlu-literature\", dataset_file=\"./parsinlu/data/multiple-choice/test_lit.jsonl\")\n","print(test_questions_lit[0])\n","print(test_candidates_lit[0])\n","print(test_choices_lit[0])\n","print(test_answers_lit[0])\n","print(len(test_questions_lit))\n","print(len(test_candidates_lit))\n","print(len(test_choices_lit))\n","print(len(test_answers_lit))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["رابطه‌ی شیر با جنگل مثل رابطه‌ی\n","['سرباز است با پادگان', 'اتوبوس است با ایستگاه', 'هواپیما است با آسمان', 'کشتی است با بندر']\n","3\n","هواپیما است با آسمان\n","350\n","350\n","350\n","350\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZEKAoe8eGSBH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950663063,"user_tz":-270,"elapsed":726,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"379e7a2c-321f-47f0-e3a3-f064bddc4024"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Sat Aug 14 14:17:42 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   74C    P0    74W / 149W |   2789MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               63\n","Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n","Stepping:            0\n","CPU MHz:             2299.998\n","BogoMIPS:            4599.99\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            256K\n","L3 cache:            46080K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"riVxSRbv138W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950709756,"user_tz":-270,"elapsed":46699,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"b8bd59c9-d4dc-42b2-df0b-0bcf4253b95d"},"source":["evaluation_output = mcqa_model.mt5_evaluation(test_questions_lit, test_candidates_lit, test_choices_lit, test_answers_lit, device, max_length=512, batch_size=128)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["#question:350, #candidates:350, #answer:350\n","#batch: 3\n","Start to evaluate test data ...\n","inference time for step 0: 16.82330255399995\n","inference time for step 1: 16.626356681999937\n","inference time for step 2: 12.463789421000001\n","total inference time: 45.91344865699989\n","total inference time / #samples: 0.13118128187714254\n","Test Accuracy: 0.38571428571428573\n","Test Precision: 0.38585234585234585\n","Test Recall: 0.38571428571428573\n","Test F1-Score(weighted average): 0.3855496289424861\n","Test classification Report:\n","              precision    recall  f1-score   support\n","\n","           1  0.3333333333 0.3333333333 0.3333333333        75\n","           2  0.4215686275 0.4215686275 0.4215686275       102\n","           3  0.3838383838 0.4086021505 0.3958333333        93\n","           4  0.3918918919 0.3625000000 0.3766233766        80\n","\n","    accuracy                      0.3857142857       350\n","   macro avg  0.3826580591 0.3815010278 0.3818396677       350\n","weighted avg  0.3858523459 0.3857142857 0.3855496289       350\n","\n","evaluation results:\n"," OrderedDict([('exact', 33.42857142857143), ('f1', 45.45081899753222), ('total', 350)])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9qlyRQVDe7m8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950709757,"user_tz":-270,"elapsed":26,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"c922e5e7-0a5e-4ddf-f697-7286e0adfdd8"},"source":["for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer, exact_value, f1_value in evaluation_output[:25]:\n","  print('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer, exact_value, f1_value))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["رابطه‌ی شیر با جنگل مثل رابطه‌ی\t['سرباز است با پادگان', 'اتوبوس است با ایستگاه', 'هواپیما است با آسمان', 'کشتی است با بندر']\t3\tهواپیما است با آسمان\t3\tهواپیما است با آسمان\t1\t1.0\n","رابطه ي بخار با یخ مثل رابطه ي:\t['خمیر است با نان', 'گندم است با آرد', 'غوره است با کشمش', 'باران است با برف']\t3\tغوره است با کشمش\t3\tغوره است با کشمش\t1\t1.0\n","در عبارت زیر، به‌ترتیب « مضاف‌الیه مضاف‌الیه، صفت مضاف‌الیه و متمم اسم» کدام است؟\r\n","«مطالعه تفاسیر قرآن، روح اشعار حافظ شیراز را جلایی خاص بخشیده و از غزلیات این شاعر بی‌بدیل می‌توان به مهارت\r\n","خاص او در کشف رموز عرفانی پی برد.»\r\t['قرآن، این، کشف', 'حافظ، عرفانی، غزلیات', 'شیراز، این شاعر، مهارت', 'رموز، بی\\u200cبدیل، کشف رموز عرفانی']\t1\tقرآن، این، کشف\t1\tقرآن، این، کشف\t1\t1.0\n","مشهورترین شاعر رمانتیک قرن نوزدهم فرانسه چه کسی است؟\t['ولتر', 'ویکتورهوگو', 'لافونتن', 'ژان ژاک  روسو']\t2\tویکتورهوگو\t1\tولتر\t0\t0\n","مفرد كدام كلمه صحيح است\t['الوان : لون', 'حواس : احساس', 'اعضا: عضوها', 'الف وب']\t3\tاعضا: عضوها\t1\tالوان : لون\t0\t0\n","کدام عبارت، نادرست است؟\t['شاعر منظومه\\u200cهای حماسی مصنوع، با داستان\\u200cهای پهلوانی مدوّن و معینی سر و کار دارد.', 'قهرمانان حماسه، با نام رقّتی که از نظر عاطفی و احساسی در ان\\u200cها وجود دارد، فهرمانان ملّی هستند.', 'در حماسه مجموعه ای از وصف\\u200cها، خطبه\\u200cها و تصویرها وجود دارد امّا همه\\u200cی این عناصر نسبت به «داستانی بودن» در مرتبه ی دوم هستند.', 'در هر حماسه\\u200cای، رویدادهای غیرطبیعی و بیرون از نظام عادت دیده می\\u200cشود که تنها از رهگذر عقاید دینی عصر خود، توجیه\\u200cپذیر هستند.\\n']\t1\tشاعر منظومه‌های حماسی مصنوع، با داستان‌های پهلوانی مدوّن و معینی سر و کار دارد.\t4\tدر هر حماسه ای، رویدادهای غیرطبیعی و بیرون از نظام عاد\t0\t0.08\n","متضاد کلمات مورد سؤال چیست؟ منصوب \t['مطرود', 'معزول', 'مغضوب', 'معذور']\t2\tمعزول\t2\tمعزول\t1\t1.0\n","متضاد کلمات مورد سؤال چیست؟ شیفته\t['نومید', 'دلسرد', 'بی قرار', 'بیزار']\t4\tبیزار\t4\tبیزار\t1\t1.0\n","کدام واژه زیر با سه واژه دیگر تفاوت بسیار دارد؟\t['سیمبر', 'عنبر', 'دلبر', 'بریر']\t1\tسیمبر\t2\tعنبر\t0\t0\n","کدام کلمه مفرد می باشد؟\t['بیگانگان', 'آفات', 'الوان', 'عضو']\t4\tعضو\t3\tالوان\t0\t0\n","تعداد باب‌های «گلستان» چند است؟\t[' ده', 'هشت', 'نه', 'هفت']\t2\tهشت\t3\tنه\t0\t0\n","به غلط تصور کرده بود که با .............. خطاها می‌تواند از عواقب آنها مصون بماند\t['اصلاح', 'تشخیص', 'نادیده گرفتن', 'جلوگیری از']\t3\tنادیده گرفتن\t3\tنادیده گرفتن\t1\t1.0\n","کدام کلمه با سه کلمه دیگر هیچگونه مناسبتی ندارد؟\t['قنددان', 'خندان', 'گلدان', 'نمکدان']\t2\tخندان\t2\tخندان\t1\t1.0\n","آنچه که از ارزش واقعی چیزی بکاهد :؟\t['انتقاد', 'شایعه', 'فراوانی', 'نقص']\t4\tنقص\t1\tانتقاد\t0\t0\n","معنی واژه‌های «مضغ، لابه، عقار، لطیفه» به‌ترتیب کدام است؟\t['بلعیدن- تضرع- زمین زراعی- نکته\\u200cی باریک', 'جویدن- تضرع- آب و زمین- گفتار نغز', 'فرو بردن- عجز و ناتوانی- آب و زمین- ظریف و باریک', 'آسیا کردن غذا در زیر دندان- التماس- کشت\\u200cزار- نغز و شیرین']\t2\tجویدن- تضرع- آب و زمین- گفتار نغز\t2\tجویدن- تضرع- آب و زمین- گفتار نغز\t1\t1.0\n","کدام گزینه ازموضوعات شعری عصررودکی نیست؟\t['وصف', 'عرفان', 'مدح', 'اندرز']\t2\tعرفان\t2\tعرفان\t1\t1.0\n","مفهوم کلی عبارات زیر در کدام بیت مشهود است؟«به نام آن خدای که نام او راحت روح است و پیغام او مفتاح فتوح است. ذکر او مرهم دل مجروح است و مهر او بلانشینان را کشتی نوح است».\t['کاروانی که بود بدرقه\\u200cاش حفظ خدا    به تجمل بنشیند به جلالت برود', 'موج از این بار چنان کشتی طاقت بشکست    که عجب دارم اگر تخته به ساحل برود', 'زخم شمشیر غمت را به شکیبایی و عقل    چند مرهم بنهادیم و اثر می\\u200cنرود', 'سیاه نامه\\u200cتر از خود کسی نمی\\u200cبینم    چگونه چون قلمم، دود دل، به سر نرود']\t1\tکاروانی که بود بدرقه‌اش حفظ خدا    به تجمل بنشیند به جلالت برود\t3\tزخم شمشیر غمت را به شکیبایی و عقل چند مرهم ب\t0\t0.08695652173913043\n","کدام کتاب قصه است که «جنبه‌های واقعی و تاریخی و اخلاقی آن به هم آمیخته است؟»\t['عقل سرخ', 'آواز پر جبرئیل', 'مقامات حمیدی', 'تذکره\\u200cالاولیا']\t3\tمقامات حمیدی\t3\tمقامات حمیدی\t1\t1.0\n","رابطه نقاش با تصویر مثل رابطه :\t['معلم با دانش آموز', 'مولف با کتاب', 'باغبان با گل ', 'رئیس با کارمند']\t2\tمولف با کتاب\t2\tمولف با کتاب\t1\t1.0\n","کدام گزینه از آثارناصرخسرو نیست؟\t['زادالعارفین', 'خوان واخوان', 'جام \\xadالحکمتین', 'سفرنام']\t1\tزادالعارفین\t3\tجام ­الحکمتین\t0\t0\n","كدام گزينه اسم وصفت نيست؟\t['پروردگار بي همتا', 'چاپلوسان ثنا گو', 'وزيران لايق', 'منادي آزادي']\t4\tمنادي آزادي\t3\tوزيران لايق\t0\t0\n","معنی کدام گروه از واژه‌ها «همگی» درست است؟\t['(بارقه: اسب تندرو)، (درره: بسته)', '(نسق: روش)، (صائب: درست)', '(اساطیر: خدایان)، (آبزن: برکه آب)', '(آژنگ: چین و شکن مو)، (اعصار: دوران)']\t2\t(نسق: روش)، (صائب: درست)\t2\t(نسق: روش)، (صائب: درست)\t1\t1.0\n","در باره ي جمله ي از هفت خوان رستم گذشته است . كدام مورد زير درست است\t['كنايه', 'مبالغه', 'تشبيه', 'ضرب المثل']\t1\tكنايه\t2\tمبالغه\t0\t0\n","طامع یعنی ؟\t['آزمند', 'خوش شانس', 'محتاج', 'مطمئن']\t1\tآزمند\t3\tمحتاج\t0\t0\n","متضاد کلمات مورد سؤال چیست؟ قریب\t['مأنوس', 'آشنا', 'عجیب', 'دور']\t4\tدور\t1\tمأنوس\t0\t0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cgSPjuTYe71x","executionInfo":{"status":"ok","timestamp":1628950711454,"user_tz":-270,"elapsed":1715,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}}},"source":["output_file_name = \"multiple_choice_qa_literature_testset_{}_outputs.txt\".format(model_name.replace('/','-'))\n","with open(output_file_name, \"w\", encoding='utf8') as output_file:\n","  for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer, exact_value, f1_value in evaluation_output:\n","    output_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer, exact_value, f1_value))\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","upload = drive.CreateFile({'title': output_file_name})\n","upload.SetContentFile(output_file_name)\n","upload.Upload()"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AAcLHWgKGSHv"},"source":["### Samples with math_and_logic as their category"]},{"cell_type":"code","metadata":{"id":"bDozlPsr2Bp3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950711454,"user_tz":-270,"elapsed":14,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"37b8b4b6-dd7f-41eb-9f47-c796aa8e9a6d"},"source":["test_questions_ml, test_candidates_ml, test_choices_ml, test_answers_ml = mcqa_model.load_dataset_test_file(\n","    dataset_name=\"parsinlu-math_and_logic\", dataset_file=\"./parsinlu/data/multiple-choice/test_ml.jsonl\")\n","print(test_questions_ml[0])\n","print(test_candidates_ml[0])\n","print(test_choices_ml[0])\n","print(test_answers_ml[0])\n","print(len(test_questions_ml))\n","print(len(test_candidates_ml))\n","print(len(test_choices_ml))\n","print(len(test_answers_ml))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["تفاوت سن علیرضا و خواهرش A سال است B سال دیگر سن علیرضا دوبرابر سن امروز خواهرش خواهد بود .سن خواهر علیرضا کدام است؟\n","['2A', '2A+B', '3A+B', 'A-B']\n","2\n","2A+B\n","350\n","350\n","350\n","350\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uIbQCKZ1Igho","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950712926,"user_tz":-270,"elapsed":1482,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"38c46f0a-38e5-4a55-d4d8-7d3d4517a7d4"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Sat Aug 14 14:18:30 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   72C    P0    83W / 149W |   8935MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               63\n","Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n","Stepping:            0\n","CPU MHz:             2299.998\n","BogoMIPS:            4599.99\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            256K\n","L3 cache:            46080K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V0yABKemCZnv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950758619,"user_tz":-270,"elapsed":45700,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"6f7363ab-d674-4948-c5f3-e41e2c387839"},"source":["evaluation_output = mcqa_model.mt5_evaluation(test_questions_ml, test_candidates_ml, test_choices_ml, test_answers_ml, device, max_length=512, batch_size=128)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["#question:350, #candidates:350, #answer:350\n","#batch: 3\n","Start to evaluate test data ...\n","inference time for step 0: 16.210131040999954\n","inference time for step 1: 16.556340665999983\n","inference time for step 2: 12.44238550099999\n","total inference time: 45.20885720799993\n","total inference time / #samples: 0.12916816345142837\n","Test Accuracy: 0.4057142857142857\n","Test Precision: 0.415560059687854\n","Test Recall: 0.4057142857142857\n","Test F1-Score(weighted average): 0.40822719430343607\n","Test classification Report:\n","              precision    recall  f1-score   support\n","\n","           1  0.5000000000 0.4152542373 0.4537037037       118\n","           2  0.4226804124 0.4141414141 0.4183673469        99\n","           3  0.3366336634 0.4197530864 0.3736263736        81\n","           4  0.3333333333 0.3461538462 0.3396226415        52\n","\n","    accuracy                      0.4057142857       350\n","   macro avg  0.3981618523 0.3988256460 0.3963300164       350\n","weighted avg  0.4155600597 0.4057142857 0.4082271943       350\n","\n","evaluation results:\n"," OrderedDict([('exact', 37.42857142857143), ('f1', 42.49275248560963), ('total', 350)])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O8Dgqmc1GAtz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950758620,"user_tz":-270,"elapsed":14,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"0807579c-3c03-4f3a-ed6e-5fbf96be0c27"},"source":["for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer, exact_value, f1_value in evaluation_output[:25]:\n","  print('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer, exact_value, f1_value))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["تفاوت سن علیرضا و خواهرش A سال است B سال دیگر سن علیرضا دوبرابر سن امروز خواهرش خواهد بود .سن خواهر علیرضا کدام است؟\t['2A', '2A+B', '3A+B', 'A-B']\t2\t2A+B\t2\t2A+B\t1\t1.0\n","در ادامه این رشته چه عددی باید نوشت؟ ۹۱،۸۶،۷۶،۶۱،...\t['۴۶', '۴۱', '۵۱', '۳۶']\t2\t۴۱\t2\t۲۱\t0\t0\n","50 تا 20 تا برابر است با ......\t['10000', '100', '1000', '500']\t3\t1000\t3\t1000\t1\t1.0\n","در ادامه این رشته چه عددی باید نوشت؟             3, 5, 5, 9, 7, 13, 9, …\t['17', '11', '14', '15']\t1\t17\t3\t14\t0\t0\n","مساحت مربع ۸ ،p برابر مساحت مربع Q است. نسبت قطر مربع p به ضلع مربع Q کدامست؟\t['۴', '۲', '۳', '۱']\t1\t۴\t4\t۱\t0\t0\n","%50 عدد 24 برابر است با ....\t['4', '6', '10', '12']\t4\t12\t2\t6\t0\t0\n","کدام عدد نزدیکتر۷ به است؟\t['۴', '۶', '۹', '۱۱']\t2\t۶\t3\t۹\t0\t0\n","چند درصد ۵۰۰ برابر ۵۰ می‌شود؟\t['۱', '۱۰', '۲۰', '۳۰']\t2\t۱۰\t4\t۳۰\t0\t0\n","قیمت یک کالا %۲۵ تخفیف داده شده است برای آنکه این کالا به قیمت قبل از تخفیف فروخته شود چند درصد باید به قیمت آن افزوده گردد؟\t['۲۵', '۲۰', '۳۳.۳۳', 'هیچکدام']\t3\t۳۳.۳۳\t3\t۳۳.۳۳\t1\t1.0\n","حاصل عبارت ۵ - ۳ برابر است با ؟\t['-2', '2', '1', '-1']\t1\t-2\t1\t-2\t1\t1.0\n","حاصل عبارت ۴۴ + ۲۳ برابر است با ؟\t['68', '65', '57', '67']\t4\t67\t1\t66\t0\t0\n","سرمایه دو شریک به نسبت او ۱ می‌باشد سود نفر دوم در یک معامله ۹۰۰ تومان است کل مبلغ سود\r\n","چند تومان است. کل مبلغ سود چند تومان می‌شود؟\r\t['۷۲۰', '۳۶۰۰', '۱۶۲۰', '۴۵۰۰']\t3\t۱۶۲۰\t4\t۴۵۰۰\t0\t0\n","۵۴۰۰ لیتر بنزین برای مصرف ۹ اتومبیل یک شرکت راهسازی در مدت ۲۰ روز مأموریت داده شده است. با\n","افزوده شدن ۳ اتومبیل دیگر ۲ روز از مدت مأموریت کم می‌شود در صورتی که مقدار بنزین دریافتی تغییر\n","نکند. سهمیه بنزین روزانه هر اتومبیل:\n","\t['زیاد شده است', 'کم شده است', 'تغییر نکرده است', 'قابل تعیین نیست']\t2\tکم شده است\t2\tکم شده است\t1\t1.0\n","نسبت اسید دریک ماده شیمیایی %۳ است، ۶۰ لیتر از این ماده را با چند لیتر ماده بدون اسید باید مخلوط کرد تا نسبت اسید مخلوط %۱ شود؟\t['۸۰', '۱۰۰', '۱۲۰', '۱۵۰']\t3\t۱۲۰\t2\t۱۰۰\t0\t0\n","اگر یک سوم چوبی در زمین و یک دوم « در آب و قسمت بالائی‌آن که بیرون از آب قرار دارد ۱/۵ متر باشد،طول چوب چقدر است؟\t['4.5', '6', '9', '10.5']\t3\t9\t2\t6\t0\t0\n","کدامیک ازاعداد زیرازعدد 43 کوچکتراست؟\t['45', '54', '49', '34']\t4\t34\t1\t45\t0\t0\n"," ﻜﺪاﻡ عبارت صحیح نیست ؟\t['اﺯﺪو نقطه فقط یک خط راست می ﮔﺬارﺪ.', 'اﮔﺮخطی بر خط ﺪﻴﮔﺮعموﺪباﺷﺪبر خطوط مواﺯی آن ﻨﻳﺯعموﺪاست.', 'هر خط عموﺪبر خط ﺪﻴﮔﺮعموﺪمنصف آن خط است.', 'هر قطر لوﺯی عموﺪمنصف قطر ﺪﻴﮔﺮاست.']\t3\tهر خط عموﺪبر خط ﺪﻴﮔﺮعموﺪمنصف آن خط است.\t4\tهر قطر لوزی عمودمنصف قطر ديگراست.\t0\t0.14285714285714288\n","حاصل 10*9*8  با فاکتوریل کدام عدد طبیعی است؟\t['۶', '۷', '۸', '۹']\t1\t۶\t2\t۷\t0\t0\n","شعاع دایره ای یک دهم افزایش یافته است. مساحت مربع محاطی آن چند درصد افزایش می‌یابد؟\t['۷۹', '۲۱', '۱۹', '۸۱']\t2\t۲۱\t3\t۱۹\t0\t0\n","پدری نصف دارائی خود را بین ۳ فرزندش تقسیم کرده چه کسری از کل دارائی پدر به هر پسر می رسد؟\t['یک ششم', 'یک پنجم', 'یک چهارم', 'یک سوم']\t1\tیک ششم\t1\tیک ششم\t1\t1.0\n","شخصی جنسی را به ۲۰۰۰ ریال خریده بود به ۲۴۰۰ ریال فروخت. حال اگر جنسی را به ۶۰۰۰ ریال بفروشد به چند ریال خریده بود؟\t['۵۴۰۰', '۵۲۰۰', '۵۰۰۰', '۲۸۰۰']\t3\t۵۰۰۰\t2\t۵۲۰۰\t0\t0\n","یک مخزن بنزین، دو مجرا دارد، اولی مخزن را در ۶ ساعت و هر دو مجرا با هم آن را در ۴ ساعت خالی\n","می‌کنند، در صورتی که مخزن خالی و فقط مجرای دوم باز باشد مخزن در چند ساعت خالی می‌شود؟\n","\t['۱۲ ساعت', '۸ ساعت', '۴ ساعت', '۳ ساعت']\t2\t۸ ساعت\t3\t۴ ساعت\t0\t0.5\n"," برای انجام عمل تقسیم به ﺪوﻋﺪﺪ نیاﺯﻤﻧﺪﻴﻡ که  عبارﺗﻧﺪﺍﺯ:۟۟۟۟۟۰۰۰۰۰۰۰۰ ۟۟۟۟۟۰۰۰۰۰۰۰۰\t['مقسوم علیه وخارج قسمت', 'مقسوم ومقسوم علیه', 'مقسوم وباقی ماﻧﺪﻩ', 'خارج قسمت و باقی ماﻧﺪﻩ']\t2\tمقسوم ومقسوم علیه\t3\tمقسوم وباقی مانده\t0\t0.3333333333333333\n","موتورسواری با سرعت متوسط ۶۰ کیلومتر در ساعت فاصله بین دو شهر را طی می‌کند و همین فاصله را با سرعت متوسط ۴۰ کیلومتر در ساعت برمی گردد.\r\n","سرعت متوسط او برای تمام مسیر رفت و برگشت عبارت است از\r\t['۵۳ کیلومتر در ساعت', '۵ کیلومتر در ساعت', '۴۸ کیلومتر در ساعت', '۵۲ کیلومتر در ساعت']\t3\t۴۸ کیلومتر در ساعت\t3\t۴۸ کیلومتر در ساعت\t1\t1.0\n","به یک نوع کالا نسبت به هشتاد درصد قیمت آن صد و بیست درصد سود بازرگانی تعلـق مـیگیـرد. افـزایش\n","قیمت با محاسبۀ سود بازرگانی چند درصد است؟ \t['۹۶', '۷۶', '۱۹۶', '۱۷۶']\t1\t۹۶\t1\t۹۶\t1\t1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"afCYGzT6ImPn","executionInfo":{"status":"ok","timestamp":1628950759368,"user_tz":-270,"elapsed":759,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}}},"source":["output_file_name = \"multiple_choice_qa_math_and_logic_testset_{}_outputs.txt\".format(model_name.replace('/','-'))\n","with open(output_file_name, \"w\", encoding='utf8') as output_file:\n","  for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer, exact_value, f1_value in evaluation_output:\n","    output_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer, exact_value, f1_value))\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","upload = drive.CreateFile({'title': output_file_name})\n","upload.SetContentFile(output_file_name)\n","upload.Upload()"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nkj_IXan2xiP"},"source":["### Samples with common_knowledge as their category"]},{"cell_type":"code","metadata":{"id":"mLsuGEuQIgkO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950759369,"user_tz":-270,"elapsed":38,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"90da72a0-bbe8-4a6d-9f95-e4416704b90b"},"source":["test_questions_ck, test_candidates_ck, test_choices_ck, test_answers_ck = mcqa_model.load_dataset_test_file(\n","    dataset_name=\"parsinlu-common_knowledge\", dataset_file=\"./parsinlu/data/multiple-choice/test_ck.jsonl\")\n","print(test_questions_ck[0])\n","print(test_candidates_ck[0])\n","print(test_choices_ck[0])\n","print(test_answers_ck[0])\n","print(len(test_questions_ck))\n","print(len(test_candidates_ck))\n","print(len(test_choices_ck))\n","print(len(test_answers_ck))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["کدام کشور اولین تولید کننده خرما در جهان است؟\n","['ایران', 'عربستان', 'عراق', 'سوریه']\n","1\n","ایران\n","350\n","350\n","350\n","350\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4L8td12qDZCP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950759370,"user_tz":-270,"elapsed":13,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"fbe9ba1e-3ffd-4017-a751-664dc454832e"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Sat Aug 14 14:19:18 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   71C    P0    83W / 149W |   8935MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               63\n","Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n","Stepping:            0\n","CPU MHz:             2299.998\n","BogoMIPS:            4599.99\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            256K\n","L3 cache:            46080K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5LjF9gcR2uXK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950806814,"user_tz":-270,"elapsed":47450,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"0b8e95ef-1a72-48e6-c1f0-4e4fc921b92e"},"source":["evaluation_output = mcqa_model.mt5_evaluation(test_questions_ck, test_candidates_ck, test_choices_ck, test_answers_ck, device, max_length=512, batch_size=128)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["#question:350, #candidates:350, #answer:350\n","#batch: 3\n","Start to evaluate test data ...\n","inference time for step 0: 16.52870419099986\n","inference time for step 1: 16.55262644300001\n","inference time for step 2: 12.407136788000116\n","total inference time: 45.488467421999985\n","total inference time / #samples: 0.12996704977714282\n","Test Accuracy: 0.24571428571428572\n","Test Precision: 0.24580062794348512\n","Test Recall: 0.24571428571428572\n","Test F1-Score(weighted average): 0.24551789908460653\n","Test classification Report:\n","              precision    recall  f1-score   support\n","\n","           1  0.2500000000 0.2346938776 0.2421052632        98\n","           2  0.2142857143 0.2045454545 0.2093023256        88\n","           3  0.2916666667 0.2978723404 0.2947368421        94\n","           4  0.2179487179 0.2428571429 0.2297297297        70\n","\n","    accuracy                      0.2457142857       350\n","   macro avg  0.2434752747 0.2449922038 0.2439685401       350\n","weighted avg  0.2458006279 0.2457142857 0.2455178991       350\n","\n","evaluation results:\n"," OrderedDict([('exact', 23.428571428571427), ('f1', 34.01362918863842), ('total', 350)])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"huGRjXMT3Pay","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950806816,"user_tz":-270,"elapsed":28,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"ad8ac070-eec5-4d2b-ee64-23b14f4e0add"},"source":["for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer, exact_value, f1_value in evaluation_output[:25]:\n","  print('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer, exact_value, f1_value))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["کدام کشور اولین تولید کننده خرما در جهان است؟\t['ایران', 'عربستان', 'عراق', 'سوریه']\t1\tایران\t1\tایران\t1\t1.0\n","مقام رهبری در قانون اساسی جمهوری اسلامی دارای چه کار ویژه ای است؟\t['ریاست کشور', 'نظارت عالیه', 'تنظیم کننده قوای سه گانه', 'حاکمیت مطلق']\t3\tتنظیم کننده قوای سه گانه\t3\tتنظیم کننده قوای سه گانه\t1\t1.0\n","الماس سخت تر است یا گرانیت؟\t['الماس', 'گرانیت', '', '']\t1\tالماس\t2\tگرانیت\t0\t0\n","طبق قانون اساسی شورای نگهبان طی چند روز از تاریخ وصول باید نظر خود را نسبت به مصوبات مجلس\r\n","اعلام نماید؟\r\t['یک ماه', 'ده روز', 'دو هفته', 'تا حصول اطمینان']\t2\tده روز\t3\tدو هفته\t0\t0\n","در کشور ایران بیشترین نرخ بیکاری متعلق به کدام یک از گزینه های زیر میباشد؟\t['دارندگان مدرک تحصیلی تکمیلی', 'افراد زیر دیپلم', 'افراد بالای 50 سال', 'فارغ التحصیلان دانشگاهها']\t1\tدارندگان مدرک تحصیلی تکمیلی\t3\tافراد بالای 50 سال\t0\t0\n","ریاست اولین دوره مجلس شورای اسلامی بر عهده چه کسی بود؟\t['آیت الله بهشتی', 'آیت الله کروبی', 'آیت الله رفسنجانی', 'آیت الله ناطق نوری']\t4\tآیت الله ناطق نوری\t2\tآیت الله کروبی\t0\t0.5714285714285715\n","سوره بیست و هفتم قرآن کریم کدامست؟\t['سوره اسراء', 'سوره توبه', 'سوره واقعه', 'سوره نحل']\t3\tسوره واقعه\t4\tسوره نحل\t0\t0.5\n","در ترمز ضد قفل برای ترمز گیری باید پا رابه صورت ……………..روی پدال ترمزفشرد.\t['ممتد', 'منقطع', 'آهسته', 'محکم']\t1\tممتد\t2\tمنقطع\t0\t0\n","«تفسیر سور آبادی» تألیف کدام شخص است؟\t['ابوبکر عتیق نیشابوری', 'علامه مجلسی', 'علامه طباطبائی', 'شیخ طوسی']\t1\tابوبکر عتیق نیشابوری\t1\tابوبکر عتیق نیشابوری\t1\t1.0\n","حضرت علی “ع” در کدام جنگ در مقابل خوارج ایستاد؟\t['نهروان', 'صفین', 'جمل', 'خیبر']\t1\tنهروان\t2\tصفین\t0\t0\n","مصوبات مجمع تشخیص مصلحت نظام باید به تأیید ......... برسد.\t['مجلس خبرگان', 'رئیس جمهور', 'شورای نگهبان', 'مقام رهبری']\t4\tمقام رهبری\t4\tمقام رهبری\t1\t1.0\n","کدام مورد معادل مناسب تری برای واژه “کارنگ” است؟\t['سیاست مدار', 'چرب زبان', 'کارشناس', 'آرامش دهنده']\t2\tچرب زبان\t4\tآرامش دهنده\t0\t0\n","تصویب عهدنامه‌ها، مقاوله‌نامه‌ها، قراردادها و موافقت‌نامه‌های بین‌المللی برعهده کدام مرجع می‌باشد؟\t['مجلس شورای اسلامی', 'هیأت دولت', 'وزارت امور خارجه', 'مجمع تشخیص مصلحت نظام']\t1\tمجلس شورای اسلامی\t1\tمجلس شورای اسلامی\t1\t1.0\n","چرا نجوم از مهم ترين دانش هايي بود كه مردم ميان دو رود در آن پيشرفت چشمگيري كردند؟\t['وجود دادو ستد و امور بازرگاني', 'رواج خرافات', 'پرستش ستارگان و تاثير آنها در سرنوشت انسان', 'اعتقاد به ارواحي كه در بدن نفوذ مي كردند.']\t3\tپرستش ستارگان و تاثير آنها در سرنوشت انسان\t1\tوجود دادو ستد و امور بازرگاني\t0\t0.14285714285714288\n","پنج کشوری که در سازمان ملل متحد دارای حق« وتو » می باشند، کدامند؟\t['چین ، فرانسه، انگلیس ، آمریکا ، شوروی', 'آمریکا، انگلیس، آلمان، سوئیس، شوروی', 'آمریکا، شوروی، فرانسه، آلمان، چین', 'چین ، فرانسه ، ایتالیا ، آمریکا ، انگلیس']\t1\tچین ، فرانسه، انگلیس ، آمریکا ، شوروی\t1\tچین ، فرانسه، انگلیس ، آمریکا ، شوروی\t1\t1.0\n","وسیع ترین کشور جهان کدام است؟\t['آمریکا', 'کانادا', 'روسیه', 'چین']\t3\tروسیه\t4\tچین\t0\t0\n","مشهورترین ملاك برای طبقه بندی حز ب های سیاسی کدامند؟\t['ملاك فرهنگی', 'ملاك اجتماعی', 'ملاك جهان بینی', 'ملاك ایدئولوژی']\t4\tملاك ایدئولوژی\t4\tملاك ایدئولوژی\t1\t1.0\n","مراجعه به افکار عمومی توسط کدام مرجع زیر صورت می‌گیرد؟\t['مجلس شورای اسلامی', 'شورای نگهبان', 'مجمع تشخیص مصلحت نظام', 'مجلس خبرگان رهبری']\t2\tشورای نگهبان\t2\tشورای نگهبان\t1\t1.0\n","IT مخفف چیست ؟\t['Information Technical', 'Information Types', 'Information Training', 'Information Technology']\t4\tInformation Technology\t4\tInformation Technology\t1\t1.0\n","« بیمه » قراردادی است که ، اعتبار آن ......................\t['مادام العمر، به شرط دادن حق بیمه است.', 'مادام العمر است.', 'چند سال معین ، از چهل سالگی به بعد است.', 'چند سال معین تا زمانی است که حق بیمه منقضی می شود.']\t4\tچند سال معین تا زمانی است که حق بیمه منقضی می شود.\t2\tمادام العمر است.\t0\t0.13333333333333333\n","دعوت نهانی پیامبر (ص) به اسلام چند سال به طول انجامید؟\t['۷ سال', '۳ سال', '۲۳ سال', '۶ سال']\t2\t۳ سال\t3\t۲۳ سال\t0\t0.5\n","ماد و لودیه با وساطت چه حکومتی صلح کردند؟\t['مصر', 'بابل', 'آتن', 'اسپارت']\t2\tبابل\t4\tاسپارت\t0\t0\n","»Talweg» تالوگ چیست؟\t['خطی که از میان عمیقترین نقطه بستر رودخانه بین المللی عبور و مرز را مشخص می کند.', 'خطی که رودخانه بین المللی را به دو بخش تقسیم و مرز را تعیین می کند.', 'خطی فرضی که بستر رودخانه را به دو نیم تقسیم و مرز را معین می کند.', 'خطی فرضی که مرز رودخانه بین المللی را مشخص می کند.']\t1\tخطی که از میان عمیقترین نقطه بستر رودخانه بین المللی عبور و مرز را مشخص می کند.\t3\tخطی فرضی که بستر رودخانه را به دو نیم تقسیم و مرز\t0\t0.4827586206896552\n","تعداد فقهای شورای نگهبان چند نفر است؟\t['۶', '۱۲', '۵', '۹']\t1\t۶\t4\t۹\t0\t0\n","سطح روغن موتور هر چند وقت یکبار باید بررسی گردد ؟\t['هر روز', 'یک بار در ماه', 'هر دو هزار کیلومتر کارکرد', 'هفته ای یکبار']\t4\tهفته ای یکبار\t4\tهفته ای یکبار\t1\t1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1mO_rEyM3Pd_","executionInfo":{"status":"ok","timestamp":1628950807779,"user_tz":-270,"elapsed":984,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}}},"source":["output_file_name = \"multiple_choice_qa_common_knowledge_testset_{}_outputs.txt\".format(model_name.replace('/','-'))\n","with open(output_file_name, \"w\", encoding='utf8') as output_file:\n","  for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer, exact_value, f1_value in evaluation_output:\n","    output_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer, exact_value, f1_value))\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","upload = drive.CreateFile({'title': output_file_name})\n","upload.SetContentFile(output_file_name)\n","upload.Upload()"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9th_LvQz9HWH"},"source":["### All Samples"]},{"cell_type":"code","metadata":{"id":"OZqiKAMW2uUE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950807780,"user_tz":-270,"elapsed":18,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"d8576ff3-70b4-497f-afc8-00ff5c40ec37"},"source":["test_questions_all, test_candidates_all, test_choices_all, test_answers_all = mcqa_model.load_dataset_test_file(\n","    dataset_name=\"parsinlu\", dataset_file=\"./parsinlu/data/multiple-choice/test.jsonl\")\n","print(test_questions_all[0])\n","print(test_candidates_all[0])\n","print(test_choices_all[0])\n","print(test_answers_all[0])\n","print(len(test_questions_all))\n","print(len(test_candidates_all))\n","print(len(test_choices_all))\n","print(len(test_answers_all))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["تفاوت سن علیرضا و خواهرش A سال است B سال دیگر سن علیرضا دوبرابر سن امروز خواهرش خواهد بود .سن خواهر علیرضا کدام است؟\n","['2A', '2A+B', '3A+B', 'A-B']\n","2\n","2A+B\n","1050\n","1050\n","1050\n","1050\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WH51PCVZ9LvB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950807781,"user_tz":-270,"elapsed":14,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"761e94af-a745-40b0-840b-21e71f8de613"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Sat Aug 14 14:20:06 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   71C    P0    82W / 149W |   8935MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               63\n","Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n","Stepping:            0\n","CPU MHz:             2299.998\n","BogoMIPS:            4599.99\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            256K\n","L3 cache:            46080K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"laMQutR_9YYl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950945517,"user_tz":-270,"elapsed":137742,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"dd735c56-19f7-4d20-df04-d4881d2368f6"},"source":["evaluation_output = mcqa_model.mt5_evaluation(test_questions_all, test_candidates_all, test_choices_all, test_answers_all, device, max_length=512, batch_size=128)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["#question:1050, #candidates:1050, #answer:1050\n","#batch: 9\n","Start to evaluate test data ...\n","inference time for step 0: 16.22692546600001\n","inference time for step 1: 16.513621458999978\n","inference time for step 2: 16.58862887600003\n","inference time for step 3: 16.551200136999796\n","inference time for step 4: 16.560216886000035\n","inference time for step 5: 16.55131984700006\n","inference time for step 6: 16.54500222699994\n","inference time for step 7: 16.539657833999854\n","inference time for step 8: 3.7818631860000096\n","total inference time: 135.8584359179997\n","total inference time / #samples: 0.12938898658857115\n","Test Accuracy: 0.3457142857142857\n","Test Precision: 0.34664509275773847\n","Test Recall: 0.3457142857142857\n","Test F1-Score(weighted average): 0.3457275345766356\n","Test classification Report:\n","              precision    recall  f1-score   support\n","\n","           1  0.3660377358 0.3333333333 0.3489208633       291\n","           2  0.3604240283 0.3529411765 0.3566433566       289\n","           3  0.3378378378 0.3731343284 0.3546099291       268\n","           4  0.3106796117 0.3168316832 0.3137254902       202\n","\n","    accuracy                      0.3457142857      1050\n","   macro avg  0.3437448034 0.3440601303 0.3434749098      1050\n","weighted avg  0.3466450928 0.3457142857 0.3457275346      1050\n","\n","evaluation results:\n"," OrderedDict([('exact', 31.428571428571427), ('f1', 40.65240022392675), ('total', 1050)])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"La5YYuVJ9Lx-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628950945518,"user_tz":-270,"elapsed":28,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"f1abd19b-1e4e-42a1-89f1-f6023a6cb1d4"},"source":["for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer, exact_value, f1_value in evaluation_output[:25]:\n","  print('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer, exact_value, f1_value))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["تفاوت سن علیرضا و خواهرش A سال است B سال دیگر سن علیرضا دوبرابر سن امروز خواهرش خواهد بود .سن خواهر علیرضا کدام است؟\t['2A', '2A+B', '3A+B', 'A-B']\t2\t2A+B\t2\t2A+B\t1\t1.0\n","در ادامه این رشته چه عددی باید نوشت؟ ۹۱،۸۶،۷۶،۶۱،...\t['۴۶', '۴۱', '۵۱', '۳۶']\t2\t۴۱\t2\t۲۱\t0\t0\n","50 تا 20 تا برابر است با ......\t['10000', '100', '1000', '500']\t3\t1000\t3\t1000\t1\t1.0\n","در ادامه این رشته چه عددی باید نوشت؟             3, 5, 5, 9, 7, 13, 9, …\t['17', '11', '14', '15']\t1\t17\t3\t14\t0\t0\n","مساحت مربع ۸ ،p برابر مساحت مربع Q است. نسبت قطر مربع p به ضلع مربع Q کدامست؟\t['۴', '۲', '۳', '۱']\t1\t۴\t4\t۱\t0\t0\n","%50 عدد 24 برابر است با ....\t['4', '6', '10', '12']\t4\t12\t2\t6\t0\t0\n","کدام عدد نزدیکتر۷ به است؟\t['۴', '۶', '۹', '۱۱']\t2\t۶\t3\t۹\t0\t0\n","چند درصد ۵۰۰ برابر ۵۰ می‌شود؟\t['۱', '۱۰', '۲۰', '۳۰']\t2\t۱۰\t4\t۳۰\t0\t0\n","قیمت یک کالا %۲۵ تخفیف داده شده است برای آنکه این کالا به قیمت قبل از تخفیف فروخته شود چند درصد باید به قیمت آن افزوده گردد؟\t['۲۵', '۲۰', '۳۳.۳۳', 'هیچکدام']\t3\t۳۳.۳۳\t3\t۳۳.۳۳\t1\t1.0\n","حاصل عبارت ۵ - ۳ برابر است با ؟\t['-2', '2', '1', '-1']\t1\t-2\t1\t-2\t1\t1.0\n","حاصل عبارت ۴۴ + ۲۳ برابر است با ؟\t['68', '65', '57', '67']\t4\t67\t1\t66\t0\t0\n","سرمایه دو شریک به نسبت او ۱ می‌باشد سود نفر دوم در یک معامله ۹۰۰ تومان است کل مبلغ سود\r\n","چند تومان است. کل مبلغ سود چند تومان می‌شود؟\r\t['۷۲۰', '۳۶۰۰', '۱۶۲۰', '۴۵۰۰']\t3\t۱۶۲۰\t4\t۴۵۰۰\t0\t0\n","۵۴۰۰ لیتر بنزین برای مصرف ۹ اتومبیل یک شرکت راهسازی در مدت ۲۰ روز مأموریت داده شده است. با\n","افزوده شدن ۳ اتومبیل دیگر ۲ روز از مدت مأموریت کم می‌شود در صورتی که مقدار بنزین دریافتی تغییر\n","نکند. سهمیه بنزین روزانه هر اتومبیل:\n","\t['زیاد شده است', 'کم شده است', 'تغییر نکرده است', 'قابل تعیین نیست']\t2\tکم شده است\t2\tکم شده است\t1\t1.0\n","نسبت اسید دریک ماده شیمیایی %۳ است، ۶۰ لیتر از این ماده را با چند لیتر ماده بدون اسید باید مخلوط کرد تا نسبت اسید مخلوط %۱ شود؟\t['۸۰', '۱۰۰', '۱۲۰', '۱۵۰']\t3\t۱۲۰\t2\t۱۰۰\t0\t0\n","اگر یک سوم چوبی در زمین و یک دوم « در آب و قسمت بالائی‌آن که بیرون از آب قرار دارد ۱/۵ متر باشد،طول چوب چقدر است؟\t['4.5', '6', '9', '10.5']\t3\t9\t2\t6\t0\t0\n","کدامیک ازاعداد زیرازعدد 43 کوچکتراست؟\t['45', '54', '49', '34']\t4\t34\t1\t45\t0\t0\n"," ﻜﺪاﻡ عبارت صحیح نیست ؟\t['اﺯﺪو نقطه فقط یک خط راست می ﮔﺬارﺪ.', 'اﮔﺮخطی بر خط ﺪﻴﮔﺮعموﺪباﺷﺪبر خطوط مواﺯی آن ﻨﻳﺯعموﺪاست.', 'هر خط عموﺪبر خط ﺪﻴﮔﺮعموﺪمنصف آن خط است.', 'هر قطر لوﺯی عموﺪمنصف قطر ﺪﻴﮔﺮاست.']\t3\tهر خط عموﺪبر خط ﺪﻴﮔﺮعموﺪمنصف آن خط است.\t4\tهر قطر لوزی عمودمنصف قطر ديگراست.\t0\t0.14285714285714288\n","حاصل 10*9*8  با فاکتوریل کدام عدد طبیعی است؟\t['۶', '۷', '۸', '۹']\t1\t۶\t2\t۷\t0\t0\n","شعاع دایره ای یک دهم افزایش یافته است. مساحت مربع محاطی آن چند درصد افزایش می‌یابد؟\t['۷۹', '۲۱', '۱۹', '۸۱']\t2\t۲۱\t3\t۱۹\t0\t0\n","پدری نصف دارائی خود را بین ۳ فرزندش تقسیم کرده چه کسری از کل دارائی پدر به هر پسر می رسد؟\t['یک ششم', 'یک پنجم', 'یک چهارم', 'یک سوم']\t1\tیک ششم\t1\tیک ششم\t1\t1.0\n","شخصی جنسی را به ۲۰۰۰ ریال خریده بود به ۲۴۰۰ ریال فروخت. حال اگر جنسی را به ۶۰۰۰ ریال بفروشد به چند ریال خریده بود؟\t['۵۴۰۰', '۵۲۰۰', '۵۰۰۰', '۲۸۰۰']\t3\t۵۰۰۰\t2\t۵۲۰۰\t0\t0\n","یک مخزن بنزین، دو مجرا دارد، اولی مخزن را در ۶ ساعت و هر دو مجرا با هم آن را در ۴ ساعت خالی\n","می‌کنند، در صورتی که مخزن خالی و فقط مجرای دوم باز باشد مخزن در چند ساعت خالی می‌شود؟\n","\t['۱۲ ساعت', '۸ ساعت', '۴ ساعت', '۳ ساعت']\t2\t۸ ساعت\t3\t۴ ساعت\t0\t0.5\n"," برای انجام عمل تقسیم به ﺪوﻋﺪﺪ نیاﺯﻤﻧﺪﻴﻡ که  عبارﺗﻧﺪﺍﺯ:۟۟۟۟۟۰۰۰۰۰۰۰۰ ۟۟۟۟۟۰۰۰۰۰۰۰۰\t['مقسوم علیه وخارج قسمت', 'مقسوم ومقسوم علیه', 'مقسوم وباقی ماﻧﺪﻩ', 'خارج قسمت و باقی ماﻧﺪﻩ']\t2\tمقسوم ومقسوم علیه\t3\tمقسوم وباقی مانده\t0\t0.3333333333333333\n","موتورسواری با سرعت متوسط ۶۰ کیلومتر در ساعت فاصله بین دو شهر را طی می‌کند و همین فاصله را با سرعت متوسط ۴۰ کیلومتر در ساعت برمی گردد.\r\n","سرعت متوسط او برای تمام مسیر رفت و برگشت عبارت است از\r\t['۵۳ کیلومتر در ساعت', '۵ کیلومتر در ساعت', '۴۸ کیلومتر در ساعت', '۵۲ کیلومتر در ساعت']\t3\t۴۸ کیلومتر در ساعت\t3\t۴۸ کیلومتر در ساعت\t1\t1.0\n","به یک نوع کالا نسبت به هشتاد درصد قیمت آن صد و بیست درصد سود بازرگانی تعلـق مـیگیـرد. افـزایش\n","قیمت با محاسبۀ سود بازرگانی چند درصد است؟ \t['۹۶', '۷۶', '۱۹۶', '۱۷۶']\t1\t۹۶\t1\t۹۶\t1\t1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T_YDCiUN9gYV","executionInfo":{"status":"ok","timestamp":1628950946243,"user_tz":-270,"elapsed":746,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}}},"source":["output_file_name = \"multiple_choice_qa_all_testset_{}_outputs.txt\".format(model_name.replace('/','-'))\n","with open(output_file_name, \"w\", encoding='utf8') as output_file:\n","  for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer, exact_value, f1_value in evaluation_output:\n","    output_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer, exact_value, f1_value))\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","upload = drive.CreateFile({'title': output_file_name})\n","upload.SetContentFile(output_file_name)\n","upload.Upload()"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpBvPple9gbd"},"source":[""],"execution_count":null,"outputs":[]}]}