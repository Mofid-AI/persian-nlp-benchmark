{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MultipleChoiceQA/persiannlp/wikibert-base-parsinlu-multiple-choice.ipynb","provenance":[{"file_id":"1c5WvqQKKZnab7GsUVa6fi1Q8vYwvlLTc","timestamp":1624943579756}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2fde185a8d3c410891a8036df748daea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5df7a300fd3842de8e25b3cd1bca4cda","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dfdfd85229de41b2a986b8b5a99205ec","IPY_MODEL_b3439c58770a47999ea39f86cf63e194","IPY_MODEL_7aa5d3f9ecb545d4baeefcf70fec3241"]}},"5df7a300fd3842de8e25b3cd1bca4cda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dfdfd85229de41b2a986b8b5a99205ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ce1d3de2e3714287a9b92826256b7388","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aaae1c0940bd4bcb9165b8d5c0fe501f"}},"b3439c58770a47999ea39f86cf63e194":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e77bea490d674c96b542ef198fd73c8a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":710,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":710,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e44932f57ee64ac9968d4d42f36e1f19"}},"7aa5d3f9ecb545d4baeefcf70fec3241":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ebcc2d1a93f14f61936264ea8904ccf3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 710/710 [00:00&lt;00:00, 13.7kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ebc5d25c4a0c4ffbbe2744e4890d3801"}},"ce1d3de2e3714287a9b92826256b7388":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aaae1c0940bd4bcb9165b8d5c0fe501f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e77bea490d674c96b542ef198fd73c8a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e44932f57ee64ac9968d4d42f36e1f19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ebcc2d1a93f14f61936264ea8904ccf3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ebc5d25c4a0c4ffbbe2744e4890d3801":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d37fadfab6954f1b9c161a3ad1d2a93f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_78bd22eb634b45dd8f4ec22725b57d5a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9fd00575e94748619e87cb7bb88eb355","IPY_MODEL_d9f2ad4f359b4c9fafbcf37242d791f7","IPY_MODEL_4b18b7e6eec7421d8945f89cac3545e4"]}},"78bd22eb634b45dd8f4ec22725b57d5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9fd00575e94748619e87cb7bb88eb355":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_22db81221f204f06b6e7a5117145186b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ea2064d73a994b96af41a1434529e6d8"}},"d9f2ad4f359b4c9fafbcf37242d791f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9abdfef10b3e44b4a0567223eedce61f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":201974,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":201974,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2c31215105a6476a924231675f0181bd"}},"4b18b7e6eec7421d8945f89cac3545e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8dcdcf23bcaf4164871d4664959d93b4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 202k/202k [00:00&lt;00:00, 558kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_744ae49678b64aa98ff300bc66781a65"}},"22db81221f204f06b6e7a5117145186b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ea2064d73a994b96af41a1434529e6d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9abdfef10b3e44b4a0567223eedce61f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2c31215105a6476a924231675f0181bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8dcdcf23bcaf4164871d4664959d93b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"744ae49678b64aa98ff300bc66781a65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a865979df788408bb65b70e33ebce313":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4358216f61614e649151b474eac41a8d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e9f58be811ea4820835b2284f4e82779","IPY_MODEL_082885f8fcc241e48220f2fec1725c62","IPY_MODEL_c25272954132414ea1f8dfe3ed3e9c37"]}},"4358216f61614e649151b474eac41a8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e9f58be811ea4820835b2284f4e82779":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f74d52255c5f4852a44a1bae4d3303b4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bbdc0008827a4440b372e9e673cd98d1"}},"082885f8fcc241e48220f2fec1725c62":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6e68adbbe5d648558aee2c5368977731","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_edd1cb221655437eb460f6e5bb071ecb"}},"c25272954132414ea1f8dfe3ed3e9c37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7f5f28ddf3d74f2ab23b9444727b20d2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 2.39kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7f37161a9c994b80b6e929f1fd7a5384"}},"f74d52255c5f4852a44a1bae4d3303b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bbdc0008827a4440b372e9e673cd98d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6e68adbbe5d648558aee2c5368977731":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"edd1cb221655437eb460f6e5bb071ecb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7f5f28ddf3d74f2ab23b9444727b20d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7f37161a9c994b80b6e929f1fd7a5384":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d4befd35f4914a8f902e2364a6d75c83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a04b788a607d414ebf7714ad682ad3b6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ebc144428cad487e8337c0966c446483","IPY_MODEL_e7a18d4d59dc4d39a6292ac90c389289","IPY_MODEL_7032991e8db947448a4bf3112a54d4d5"]}},"a04b788a607d414ebf7714ad682ad3b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ebc144428cad487e8337c0966c446483":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_47c89b0aeadc4e8db440fc961cd1eb9f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_90f073f552fa47aca55b41bf7dcce8c0"}},"e7a18d4d59dc4d39a6292ac90c389289":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8e23c26ce939413bb3d052d49d77be1f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":62,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":62,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_95546dc68dc14884a4a39d4dc29330b7"}},"7032991e8db947448a4bf3112a54d4d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_05f4e195eab147f6b304cb71c04e7997","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 62.0/62.0 [00:00&lt;00:00, 1.12kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1d14ad47ec9b40058be6253e8014aef0"}},"47c89b0aeadc4e8db440fc961cd1eb9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"90f073f552fa47aca55b41bf7dcce8c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8e23c26ce939413bb3d052d49d77be1f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"95546dc68dc14884a4a39d4dc29330b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"05f4e195eab147f6b304cb71c04e7997":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1d14ad47ec9b40058be6253e8014aef0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9497f6e287934dbea90c9017ad917fe2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bd27ede39ff54343b59eda6917a75b66","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3dcea63894a0481393bd8d0e5bc1e235","IPY_MODEL_8fd3683ba85a43de9186d6c9f9bb2e3d","IPY_MODEL_eb8fcb5ce33f467abd49cf5ecc90a4d1"]}},"bd27ede39ff54343b59eda6917a75b66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3dcea63894a0481393bd8d0e5bc1e235":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b1ab0d97cdd94f0993fb13c0c41f6971","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e44b5b56988546b3908a6bc7e92ce85b"}},"8fd3683ba85a43de9186d6c9f9bb2e3d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_889cf11c7ed443f8adec63c958dff8b4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":406005257,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":406005257,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9f02f95a1fc94776b04a4403f7e29b7d"}},"eb8fcb5ce33f467abd49cf5ecc90a4d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7ef6204c85b6461d97536c807b527dee","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 406M/406M [00:35&lt;00:00, 12.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ce7ac0c9f49849febdfa1750e5e09c0c"}},"b1ab0d97cdd94f0993fb13c0c41f6971":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e44b5b56988546b3908a6bc7e92ce85b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"889cf11c7ed443f8adec63c958dff8b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9f02f95a1fc94776b04a4403f7e29b7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ef6204c85b6461d97536c807b527dee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ce7ac0c9f49849febdfa1750e5e09c0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"EVTLnae70XUx"},"source":["# Multiple-Choice Question Answering"]},{"cell_type":"code","metadata":{"id":"o_zHi1zlwyXb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958303406,"user_tz":-270,"elapsed":26,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"a4d9e1f4-f0aa-4107-9a10-5fa17bf25e7c"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sat Aug 14 16:25:02 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   68C    P8    34W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               63\n","Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n","Stepping:            0\n","CPU MHz:             2299.998\n","BogoMIPS:            4599.99\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            256K\n","L3 cache:            46080K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4knw0YgC0SfX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958344542,"user_tz":-270,"elapsed":41144,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"23c95777-5c7c-40e4-e99c-ae888954a849"},"source":["!pip install hazm==0.7.0\n","!pip install seqeval==1.2.2\n","!pip install sentencepiece==0.1.96\n","!pip install transformers==4.7.0\n","!pip install clean-text[gpl]==0.4.0\n","!pip install editdistance==0.5.3"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting hazm==0.7.0\n","  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n","\u001b[K     |████████████████████████████████| 316 kB 4.2 MB/s \n","\u001b[?25hCollecting nltk==3.3\n","  Downloading nltk-3.3.0.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 33.8 MB/s \n","\u001b[?25hCollecting libwapiti>=0.2.1\n","  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n","\u001b[K     |████████████████████████████████| 233 kB 40.2 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm==0.7.0) (1.15.0)\n","Building wheels for collected packages: nltk, libwapiti\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394483 sha256=f8f2c145d7c0a95285d42f792c13e036698194b7299de56b35c08b77aacc88d7\n","  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n","  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154617 sha256=b9595d7df41122a980d9bd4cb3bbe026099c35e5964a058485161d8b985abdcf\n","  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n","Successfully built nltk libwapiti\n","Installing collected packages: nltk, libwapiti, hazm\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n","Collecting seqeval==1.2.2\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 919 kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.4.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=57d671e85ba9afaac78eb40732526248408e9b18cc3f038e4c314e64d3a7d9f9\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Collecting sentencepiece==0.1.96\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 4.1 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting transformers==4.7.0\n","  Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (3.0.12)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (4.6.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (21.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 40.7 MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.8\n","  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 33.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (4.62.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (1.19.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (3.13)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0) (3.5.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.7.0) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (2021.5.30)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.7.0\n","Collecting clean-text[gpl]==0.4.0\n","  Downloading clean_text-0.4.0-py3-none-any.whl (9.8 kB)\n","Collecting emoji\n","  Downloading emoji-1.4.2.tar.gz (184 kB)\n","\u001b[K     |████████████████████████████████| 184 kB 5.8 MB/s \n","\u001b[?25hCollecting ftfy<7.0,>=6.0\n","  Downloading ftfy-6.0.3.tar.gz (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 3.0 MB/s \n","\u001b[?25hCollecting unidecode<2.0.0,>=1.1.1\n","  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n","\u001b[K     |████████████████████████████████| 241 kB 40.0 MB/s \n","\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy<7.0,>=6.0->clean-text[gpl]==0.4.0) (0.2.5)\n","Building wheels for collected packages: ftfy, emoji\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=4f9dfd0530dbd60dda965f220f1bb0a51bffa43b6968d0d40a353b0ae93f344b\n","  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186469 sha256=61846a1436b5854dda825b978206b69fa4bdc328b1461303f1f2168e58292349\n","  Stored in directory: /root/.cache/pip/wheels/e4/61/e7/2fc1ac8f306848fc66c6c013ab511f0a39ef4b1825b11363b2\n","Successfully built ftfy emoji\n","Installing collected packages: ftfy, emoji, unidecode, clean-text\n","Successfully installed clean-text-0.4.0 emoji-1.4.2 ftfy-6.0.3 unidecode-1.2.0\n","Requirement already satisfied: editdistance==0.5.3 in /usr/local/lib/python3.7/dist-packages (0.5.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rS4Rw-0iYEtd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958369301,"user_tz":-270,"elapsed":24788,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"fab4dac3-7a2a-4685-d846-dfc562131fe3"},"source":["!pip install PyDrive\n","import os\n","import IPython.display as ipd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: PyDrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (1.12.8)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.26.3)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.34.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.23.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (57.2.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2018.9)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.17.3)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.53.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (21.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.7.2)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HjQo6WGZ2aK5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958380698,"user_tz":-270,"elapsed":8451,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"abf7dd2c-30aa-4aa6-98e5-a1d29c1c0d8f"},"source":["# Import required packages\n","import os\n","import gc\n","import re\n","import hazm\n","import time\n","import json\n","import collections\n","import numpy as np\n","import pandas as pd\n","import editdistance\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","import transformers\n","from transformers import AutoConfig, AutoTokenizer\n","from transformers import AutoModelForMultipleChoice\n","from transformers import MT5Config, MT5ForConditionalGeneration, MT5Tokenizer\n","from transformers.data.metrics.squad_metrics import compute_exact, compute_f1\n","\n","from cleantext import clean\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","\n","print()\n","print('numpy', np.__version__)\n","print('pandas', pd.__version__)\n","print('transformers', transformers.__version__)\n","print('torch', torch.__version__)\n","print()\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\n","numpy 1.19.5\n","pandas 1.1.5\n","transformers 4.7.0\n","torch 1.9.0+cu102\n","\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5vC31D-N0Shj","executionInfo":{"status":"ok","timestamp":1628958381732,"user_tz":-270,"elapsed":1037,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}}},"source":["class MultipleChoiceQADataset(torch.utils.data.Dataset):\n","    \"\"\" Create a PyTorch dataset for Multiple Choice Question Answering. \"\"\"\n","\n","    def __init__(self, questions, candidates, choices, answers, tokenizer, max_length, model_type):\n","        self.questions = questions\n","        self.candidates = candidates\n","        self.choices = choices\n","        self.answers = answers\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.model_type = model_type\n","\n","    def __len__(self):\n","        return len(self.questions)\n","\n","    def __getitem__(self, item):\n","        if self.model_type == \"mt5\":\n","            input_text = self.questions[item] + ' <sep> ' + ' <sep> '.join(self.candidates[item])\n","            encoding = self.tokenizer(\n","                input_text,\n","                add_special_tokens=True,\n","                max_length=self.max_length,\n","                truncation=True,\n","                padding='max_length',\n","                return_tensors=\"pt\"\n","            )\n","            inputs = {\n","                'item': str(item),\n","                'question': self.questions[item],\n","                'candidates': ' <sep> '.join(self.candidates[item]),\n","                'input_text': input_text,\n","                'choice': self.choices[item],\n","                'answer': self.answers[item],\n","                'input_ids': encoding.input_ids.flatten(),\n","                'attention_mask': encoding.attention_mask.flatten()\n","            }\n","            return inputs\n","        else:\n","            choices_input_ids, choices_attention_masks, choices_token_type_ids = [], [], []\n","            for c in self.candidates[item]:\n","                text_a = \"\"  # empty context\n","                text_b = self.questions[item] + \" \" + c\n","                inputs = self.tokenizer(\n","                    text_a,\n","                    text_b,\n","                    add_special_tokens=True,\n","                    max_length=self.max_length,\n","                    padding=\"max_length\",\n","                    truncation=True,\n","                    return_overflowing_tokens=True\n","                )\n","                choices_input_ids.append(inputs.input_ids[0])\n","                choices_attention_masks.append(inputs.attention_mask[0])\n","                choices_token_type_ids.append(inputs.token_type_ids[0])\n","\n","            inputs = {\n","                'item': str(item),\n","                'question': self.questions[item],\n","                'candidates': ' <sep> '.join(self.candidates[item]),\n","                'choice': int(self.choices[item]) - 1,\n","                'answer': self.answers[item],\n","                'input_ids': torch.LongTensor(choices_input_ids),\n","                'attention_mask': torch.LongTensor(choices_attention_masks),\n","                'token_type_ids': torch.LongTensor(choices_token_type_ids)\n","            }\n","            return inputs\n","\n","\n","class MultipleChoiceQA:\n","    def __init__(self, model_name, model_type):\n","        self.normalizer = hazm.Normalizer()\n","        self.model_name = model_name\n","        if model_type.lower() == \"mt5\":\n","            self.tokenizer = MT5Tokenizer.from_pretrained(model_name)\n","            self.model = MT5ForConditionalGeneration.from_pretrained(model_name)\n","            self.config = MT5Config.from_pretrained(self.model_name)\n","        elif model_type.lower() in [\"mbert\", \"parsbert\", \"wikibert\"]:\n","            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n","            self.config = AutoConfig.from_pretrained(self.model_name)\n","            self.model = AutoModelForMultipleChoice.from_pretrained(self.model_name, config=self.config)\n","            self.model_type = model_type.lower()\n","        else:\n","            print(f'model_type not supported!')\n","            return\n","\n","    def load_dataset_test_file(self, dataset_name, dataset_file, **kwargs):\n","        if dataset_name.lower() in [\"parsinlu\", \"parsinlu-literature\", \"parsinlu-math_and_logic\",\n","                                    \"parsinlu-common_knowledge\"]:\n","            if not os.path.exists(dataset_file):\n","                print(f'{dataset_file} not exists!')\n","                return\n","            questions, candidates, choices, answers = [], [], [], []\n","            with open(dataset_file, encoding=\"utf8\") as infile:\n","                for line in infile:\n","                    json_line = json.loads(line.strip())\n","                    question = json_line['question']\n","                    candidate_answers = json_line['candidates']\n","                    choice = json_line['answer']\n","                    answer = candidate_answers[int(json_line['answer']) - 1]\n","\n","                    questions.append(question)\n","                    candidates.append(candidate_answers)\n","                    choices.append(choice)\n","                    answers.append(answer)\n","            return questions, candidates, choices, answers\n","\n","    def multiple_choice_qa_inference(self, questions, candidates, device, max_length=512):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        input_ids, attention_masks, token_type_ids = [], [], []\n","        for q, cs in zip(questions, candidates):\n","            choices_input_ids, choices_attention_masks, choices_token_type_ids = [], [], []\n","            for c in cs:\n","                text_a = \"\"  # empty context\n","                text_b = q + \" \" + c\n","                inputs = self.tokenizer(\n","                    text_a,\n","                    text_b,\n","                    add_special_tokens=True,\n","                    max_length=max_length,\n","                    padding=\"max_length\",\n","                    truncation=True,\n","                    return_overflowing_tokens=True,\n","                )\n","                choices_input_ids.append(inputs.input_ids[0])\n","                choices_attention_masks.append(inputs.attention_mask[0])\n","                choices_token_type_ids.append(inputs.token_type_ids[0])\n","            input_ids.append(choices_input_ids)\n","            attention_masks.append(choices_attention_masks)\n","            token_type_ids.append(choices_token_type_ids)\n","\n","        input_ids = torch.LongTensor(input_ids).to(device)\n","        attention_masks = torch.LongTensor(attention_masks).to(device)\n","        token_type_ids = torch.LongTensor(token_type_ids).to(device)\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        outputs = self.model(input_ids=input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids)\n","        predictions = torch.argmax(outputs.logits, dim=1)\n","        return [(questions[i], candidates[i], candidates[i][p.item()]) for i, p in enumerate(predictions)]\n","\n","    def mt5_multiple_choice_qa_inference(self, questions, candidates, device):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        new_input = []\n","        for q, cs in zip(questions, candidates):\n","            new_input.append(q + ' <sep> ' + ' <sep> '.join(cs))\n","\n","        tokenized_batch = self.tokenizer(\n","            new_input,\n","            padding=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        input_ids = tokenized_batch.input_ids.to(device)\n","        attention_mask = tokenized_batch.attention_mask.to(device)\n","\n","        outputs = self.model.generate(input_ids=input_ids, attention_mask=attention_mask)\n","        predictions = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","        return [(questions[i], candidates[i], p) for i, p in enumerate(predictions)]\n","\n","    def evaluation(self, questions, candidates, choices, answers, device, max_length, batch_size=4):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","        if len(questions) != len(candidates):\n","            print('length of two inputs is not equal!!')\n","            return\n","        if len(choices) != len(answers):\n","            print('length of choices and answers is not equal!!')\n","            return\n","        if len(questions) != len(answers):\n","            print('length of inputs and answers is not equal!!')\n","            return\n","\n","        dataset = MultipleChoiceQADataset(questions=questions, candidates=candidates, choices=choices, answers=answers,\n","                                          tokenizer=self.tokenizer, max_length=max_length, model_type=self.model_type)\n","        data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n","        print(f'#question:{len(questions)}, #candidates:{len(candidates)}, #answer:{len(answers)}')\n","        print(\"#batch:\", len(data_loader))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        total_loss, total_time = 0, 0\n","        output_predictions = []\n","        golden_choices, predicted_choices = [], []\n","        print(\"Start to evaluate test data ...\")\n","        for step, batch in enumerate(data_loader):\n","            b_input_ids = batch['input_ids']\n","            b_attention_mask = batch['attention_mask']\n","            b_token_type_ids = batch['token_type_ids']\n","            b_choices = batch['choice']\n","\n","            # move tensors to GPU if CUDA is available\n","            b_input_ids = b_input_ids.to(device)\n","            b_attention_mask = b_attention_mask.to(device)\n","            b_token_type_ids = b_token_type_ids.to(device)\n","            b_choices = b_choices.to(device)\n","\n","            # This will return the loss (rather than the model output) because we have provided the `labels`.\n","            with torch.no_grad():\n","                start = time.monotonic()\n","                b_outputs = self.model(input_ids=b_input_ids, attention_mask=b_attention_mask,\n","                                       token_type_ids=b_token_type_ids, labels=b_choices)\n","                end = time.monotonic()\n","                total_time += end - start\n","                print(f'inference time for step {step}: {end - start}')\n","            # get the loss\n","            total_loss += b_outputs.loss.item()\n","\n","            golden_choices.extend(b_choices.cpu().detach().numpy().tolist())\n","            b_predictions = torch.argmax(b_outputs.logits, dim=1)\n","            b_predictions = b_predictions.cpu().detach().numpy().tolist()\n","            predicted_choices.extend(b_predictions)\n","\n","            for i in range(len(b_input_ids)):\n","                output_predictions.append((\n","                    batch['question'][i],\n","                    batch['candidates'][i].split(' <sep> '),\n","                    batch['choice'][i].item(),\n","                    batch['answer'][i],\n","                    b_predictions[i],\n","                    batch['candidates'][i].split(' <sep> ')[b_predictions[i]]\n","                ))\n","\n","        # Calculate the average loss over the training data.\n","        avg_train_loss = total_loss / len(data_loader)\n","        print(\"average loss:\", avg_train_loss)\n","\n","        print(\"total inference time:\", total_time)\n","        print(\"total inference time / #samples:\", total_time / len(questions))\n","\n","        # evaluate\n","        print(\"Test Accuracy: {}\".format(accuracy_score(golden_choices, predicted_choices)))\n","        print(\"Test Precision: {}\".format(precision_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test Recall: {}\".format(recall_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test F1-Score(weighted average): {}\".format(\n","            f1_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test classification Report:\\n{}\".format(\n","            classification_report(golden_choices, predicted_choices, digits=10)))\n","        return output_predictions\n","\n","    def mt5_evaluation(self, questions, candidates, choices, answers, device, max_length, batch_size=4):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","        if len(questions) != len(candidates):\n","            print('length of two inputs is not equal!!')\n","            return\n","        if len(choices) != len(answers):\n","            print('length of choices and answers is not equal!!')\n","            return\n","        if len(questions) != len(answers):\n","            print('length of inputs and answers is not equal!!')\n","            return\n","\n","        dataset = MultipleChoiceQADataset(questions=questions, candidates=candidates, choices=choices, answers=answers,\n","                                          tokenizer=self.tokenizer, max_length=max_length, model_type=\"mt5\")\n","        data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n","        print(f'#question:{len(questions)}, #candidates:{len(candidates)}, #answer:{len(answers)}')\n","        print(\"#batch:\", len(data_loader))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        total_time = 0\n","        output_predictions = []\n","        golden_choices, predicted_choices, exact_score_list, f1_score_list = [], [], [], []\n","        print(\"Start to evaluate test data ...\")\n","        for step, batch in enumerate(data_loader):\n","            b_input_ids = batch['input_ids']\n","            b_attention_mask = batch['attention_mask']\n","\n","            # move tensors to GPU if CUDA is available\n","            b_input_ids = b_input_ids.to(device)\n","            b_attention_mask = b_attention_mask.to(device)\n","\n","            # This will return the loss (rather than the model output) because we have provided the `labels`.\n","            with torch.no_grad():\n","                start = time.monotonic()\n","                b_outputs = self.model.generate(input_ids=b_input_ids, attention_mask=b_attention_mask)\n","                end = time.monotonic()\n","                total_time += end - start\n","                print(f'inference time for step {step}: {end - start}')\n","\n","            b_predictions = self.tokenizer.batch_decode(b_outputs, skip_special_tokens=True)\n","\n","            for i in range(len(b_input_ids)):\n","                if b_predictions[i] in batch['candidates'][i].split(' <sep> '):\n","                    predicted_choice = str(batch['candidates'][i].split(' <sep> ').index(b_predictions[i]) + 1)\n","                else:\n","                    normalized_edit_distance_list = [\n","                        editdistance.distance(ca, b_predictions[i]) / max(len(ca), len(b_predictions[i])) for ca in\n","                        batch['candidates'][i].split(' <sep> ')\n","                    ]\n","                    predicted_choice = str(normalized_edit_distance_list.index(min(normalized_edit_distance_list)) + 1)\n","\n","                golden_choices.append(batch['choice'][i])\n","                predicted_choices.append(predicted_choice)\n","\n","                exact_score_list.append(compute_exact(batch['answer'][i], b_predictions[i]))\n","                f1_score_list.append(compute_f1(batch['answer'][i], b_predictions[i]))\n","\n","                output_predictions.append((\n","                    batch['question'][i],\n","                    batch['candidates'][i].split(' <sep> '),\n","                    batch['choice'][i],\n","                    batch['answer'][i],\n","                    predicted_choice,\n","                    b_predictions[i],\n","                    exact_score_list[-1],\n","                    f1_score_list[-1]\n","                ))\n","\n","        print(\"total inference time:\", total_time)\n","        print(\"total inference time / #samples:\", total_time / len(questions))\n","\n","        # evaluate\n","        print(\"Test Accuracy: {}\".format(accuracy_score(golden_choices, predicted_choices)))\n","        print(\"Test Precision: {}\".format(precision_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test Recall: {}\".format(recall_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test F1-Score(weighted average): {}\".format(\n","            f1_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test classification Report:\\n{}\".format(\n","            classification_report(golden_choices, predicted_choices, digits=10)))\n","\n","        total = len(exact_score_list)\n","        evaluation_results = collections.OrderedDict(\n","            [\n","                (\"exact\", 100.0 * sum(exact_score_list) / total),\n","                (\"f1\", 100.0 * sum(f1_score_list) / total),\n","                (\"total\", total),\n","            ]\n","        )\n","        print(\"evaluation results:\\n\", evaluation_results)\n","\n","        return output_predictions\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"VD0FH_FF2oTy","colab":{"base_uri":"https://localhost:8080/","height":815,"referenced_widgets":["2fde185a8d3c410891a8036df748daea","5df7a300fd3842de8e25b3cd1bca4cda","dfdfd85229de41b2a986b8b5a99205ec","b3439c58770a47999ea39f86cf63e194","7aa5d3f9ecb545d4baeefcf70fec3241","ce1d3de2e3714287a9b92826256b7388","aaae1c0940bd4bcb9165b8d5c0fe501f","e77bea490d674c96b542ef198fd73c8a","e44932f57ee64ac9968d4d42f36e1f19","ebcc2d1a93f14f61936264ea8904ccf3","ebc5d25c4a0c4ffbbe2744e4890d3801","d37fadfab6954f1b9c161a3ad1d2a93f","78bd22eb634b45dd8f4ec22725b57d5a","9fd00575e94748619e87cb7bb88eb355","d9f2ad4f359b4c9fafbcf37242d791f7","4b18b7e6eec7421d8945f89cac3545e4","22db81221f204f06b6e7a5117145186b","ea2064d73a994b96af41a1434529e6d8","9abdfef10b3e44b4a0567223eedce61f","2c31215105a6476a924231675f0181bd","8dcdcf23bcaf4164871d4664959d93b4","744ae49678b64aa98ff300bc66781a65","a865979df788408bb65b70e33ebce313","4358216f61614e649151b474eac41a8d","e9f58be811ea4820835b2284f4e82779","082885f8fcc241e48220f2fec1725c62","c25272954132414ea1f8dfe3ed3e9c37","f74d52255c5f4852a44a1bae4d3303b4","bbdc0008827a4440b372e9e673cd98d1","6e68adbbe5d648558aee2c5368977731","edd1cb221655437eb460f6e5bb071ecb","7f5f28ddf3d74f2ab23b9444727b20d2","7f37161a9c994b80b6e929f1fd7a5384","d4befd35f4914a8f902e2364a6d75c83","a04b788a607d414ebf7714ad682ad3b6","ebc144428cad487e8337c0966c446483","e7a18d4d59dc4d39a6292ac90c389289","7032991e8db947448a4bf3112a54d4d5","47c89b0aeadc4e8db440fc961cd1eb9f","90f073f552fa47aca55b41bf7dcce8c0","8e23c26ce939413bb3d052d49d77be1f","95546dc68dc14884a4a39d4dc29330b7","05f4e195eab147f6b304cb71c04e7997","1d14ad47ec9b40058be6253e8014aef0","9497f6e287934dbea90c9017ad917fe2","bd27ede39ff54343b59eda6917a75b66","3dcea63894a0481393bd8d0e5bc1e235","8fd3683ba85a43de9186d6c9f9bb2e3d","eb8fcb5ce33f467abd49cf5ecc90a4d1","b1ab0d97cdd94f0993fb13c0c41f6971","e44b5b56988546b3908a6bc7e92ce85b","889cf11c7ed443f8adec63c958dff8b4","9f02f95a1fc94776b04a4403f7e29b7d","7ef6204c85b6461d97536c807b527dee","ce7ac0c9f49849febdfa1750e5e09c0c"]},"executionInfo":{"status":"ok","timestamp":1628958429721,"user_tz":-270,"elapsed":47992,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"8a264f43-9efa-442b-d26b-02a81a4b3fe0"},"source":["model_name='persiannlp/wikibert-base-parsinlu-multiple-choice'\n","mcqa_model = MultipleChoiceQA(model_name=model_name, model_type=\"wikibert\")\n","print(mcqa_model.config)"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2fde185a8d3c410891a8036df748daea","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/710 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d37fadfab6954f1b9c161a3ad1d2a93f","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/202k [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a865979df788408bb65b70e33ebce313","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4befd35f4914a8f902e2364a6d75c83","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9497f6e287934dbea90c9017ad917fe2","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/406M [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["BertConfig {\n","  \"_name_or_path\": \"persiannlp/wikibert-base-parsinlu-multiple-choice\",\n","  \"architectures\": [\n","    \"BertForMultipleChoice\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"multiple_choice_all\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.7.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 20101\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_evY3NSRHQFu"},"source":["## Sample Inference"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tzIgo1T-Y-FL","executionInfo":{"status":"ok","timestamp":1628958440716,"user_tz":-270,"elapsed":11008,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"d4da93d6-1f56-427c-9515-269d1b7042ba"},"source":["question_list = [\n","    \"وسیع ترین کشور جهان کدام است؟\",\n","    \"طامع یعنی ؟\",\n","    \"زمینی به ۳۱ قطعه متساوی مفروض شده است و هر روز مساحت آماده شده برای احداث، دو برابر مساحت روز قبل است.اگر پس از (۵ روز) تمام زمین آماده شده باشد، در چه روزی یک قطعه زمین آماده شده\"\n","]\n","candidate_list=[\n","    [\"آمریکا\", \"کانادا\", \"روسیه\", \"چین\"],\n","    [\"آزمند\", \"خوش شانس\", \"محتاج\", \"مطمئن\"],\n","    [\"روز اول\", \"روز دوم\", \"روز سوم\", \"هیچکدام\"]\n","]\n","mcqa_model.multiple_choice_qa_inference(question_list, candidate_list, device)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('وسیع ترین کشور جهان کدام است؟',\n","  ['آمریکا', 'کانادا', 'روسیه', 'چین'],\n","  'آمریکا'),\n"," ('طامع یعنی ؟', ['آزمند', 'خوش شانس', 'محتاج', 'مطمئن'], 'آزمند'),\n"," ('زمینی به ۳۱ قطعه متساوی مفروض شده است و هر روز مساحت آماده شده برای احداث، دو برابر مساحت روز قبل است.اگر پس از (۵ روز) تمام زمین آماده شده باشد، در چه روزی یک قطعه زمین آماده شده',\n","  ['روز اول', 'روز دوم', 'روز سوم', 'هیچکدام'],\n","  'روز اول')]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"XEWiWbu621Tk"},"source":["## Multiple-Choice Dataset\n"]},{"cell_type":"code","metadata":{"id":"pC7QvccoSgPY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958447794,"user_tz":-270,"elapsed":7095,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"d880ec85-4f6f-4f1b-9d25-ac0f137c26ba"},"source":["!git clone https://github.com/persiannlp/parsinlu\n","!ls parsinlu\n","!ls parsinlu/data/multiple-choice/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Cloning into 'parsinlu'...\n","remote: Enumerating objects: 1434, done.\u001b[K\n","remote: Counting objects: 100% (182/182), done.\u001b[K\n","remote: Compressing objects: 100% (98/98), done.\u001b[K\n","remote: Total 1434 (delta 110), reused 139 (delta 82), pack-reused 1252\u001b[K\n","Receiving objects: 100% (1434/1434), 27.81 MiB | 12.45 MiB/s, done.\n","Resolving deltas: 100% (913/913), done.\n","data  LICENSE  README.md  requirements.txt  scripts  src\n","test_ck.jsonl  test_lit.jsonl  train.jsonl\n","test.jsonl     test_ml.jsonl   valid.jsonl\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ilPBM7goGNYW"},"source":["### Samples with literature as their category"]},{"cell_type":"code","metadata":{"id":"Ieg7Y37QSgSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958447795,"user_tz":-270,"elapsed":24,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"5188f161-4125-4753-ec12-a1074d0f92c7"},"source":["test_questions_lit, test_candidates_lit, test_choices_lit, test_answers_lit = mcqa_model.load_dataset_test_file(\n","    dataset_name=\"parsinlu-literature\", dataset_file=\"./parsinlu/data/multiple-choice/test_lit.jsonl\")\n","print(test_questions_lit[0])\n","print(test_candidates_lit[0])\n","print(test_choices_lit[0])\n","print(test_answers_lit[0])\n","print(len(test_questions_lit))\n","print(len(test_candidates_lit))\n","print(len(test_choices_lit))\n","print(len(test_answers_lit))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["رابطه‌ی شیر با جنگل مثل رابطه‌ی\n","['سرباز است با پادگان', 'اتوبوس است با ایستگاه', 'هواپیما است با آسمان', 'کشتی است با بندر']\n","3\n","هواپیما است با آسمان\n","350\n","350\n","350\n","350\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZEKAoe8eGSBH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958448534,"user_tz":-270,"elapsed":759,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"7254efda-bc40-4ca0-ee7c-fdd9126ce879"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Sat Aug 14 16:27:27 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   73C    P0    74W / 149W |   7863MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               63\n","Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n","Stepping:            0\n","CPU MHz:             2299.998\n","BogoMIPS:            4599.99\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            256K\n","L3 cache:            46080K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"riVxSRbv138W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958548401,"user_tz":-270,"elapsed":99876,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"5ed075f4-ed72-4b88-b1cb-94587e0c4068"},"source":["evaluation_output = mcqa_model.evaluation(test_questions_lit, test_candidates_lit, test_choices_lit, test_answers_lit, device, max_length=mcqa_model.config.max_position_embeddings, batch_size=64)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["#question:350, #candidates:350, #answer:350\n","#batch: 6\n","Start to evaluate test data ...\n","inference time for step 0: 0.04099966499995844\n","inference time for step 1: 0.013736687000005077\n","inference time for step 2: 0.012367606999987402\n","inference time for step 3: 0.013564182999971308\n","inference time for step 4: 0.014156677000073614\n","inference time for step 5: 0.013624616000015521\n","average loss: 1.386294960975647\n","total inference time: 0.10844943500001136\n","total inference time / #samples: 0.00030985552857146106\n","Test Accuracy: 0.21428571428571427\n","Test Precision: 0.04591836734693877\n","Test Recall: 0.21428571428571427\n","Test F1-Score(weighted average): 0.07563025210084034\n","Test classification Report:\n","              precision    recall  f1-score   support\n","\n","           0  0.2142857143 1.0000000000 0.3529411765        75\n","           1  0.0000000000 0.0000000000 0.0000000000       102\n","           2  0.0000000000 0.0000000000 0.0000000000        93\n","           3  0.0000000000 0.0000000000 0.0000000000        80\n","\n","    accuracy                      0.2142857143       350\n","   macro avg  0.0535714286 0.2500000000 0.0882352941       350\n","weighted avg  0.0459183673 0.2142857143 0.0756302521       350\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9qlyRQVDe7m8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958548402,"user_tz":-270,"elapsed":19,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"99f95141-352a-47d7-bb54-ce7d2933c590"},"source":["for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer in evaluation_output[:25]:\n","  print('{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["رابطه‌ی شیر با جنگل مثل رابطه‌ی\t['سرباز است با پادگان', 'اتوبوس است با ایستگاه', 'هواپیما است با آسمان', 'کشتی است با بندر']\t2\tهواپیما است با آسمان\t0\tسرباز است با پادگان\n","رابطه ي بخار با یخ مثل رابطه ي:\t['خمیر است با نان', 'گندم است با آرد', 'غوره است با کشمش', 'باران است با برف']\t2\tغوره است با کشمش\t0\tخمیر است با نان\n","در عبارت زیر، به‌ترتیب « مضاف‌الیه مضاف‌الیه، صفت مضاف‌الیه و متمم اسم» کدام است؟\r\n","«مطالعه تفاسیر قرآن، روح اشعار حافظ شیراز را جلایی خاص بخشیده و از غزلیات این شاعر بی‌بدیل می‌توان به مهارت\r\n","خاص او در کشف رموز عرفانی پی برد.»\r\t['قرآن، این، کشف', 'حافظ، عرفانی، غزلیات', 'شیراز، این شاعر، مهارت', 'رموز، بی\\u200cبدیل، کشف رموز عرفانی']\t0\tقرآن، این، کشف\t0\tقرآن، این، کشف\n","مشهورترین شاعر رمانتیک قرن نوزدهم فرانسه چه کسی است؟\t['ولتر', 'ویکتورهوگو', 'لافونتن', 'ژان ژاک  روسو']\t1\tویکتورهوگو\t0\tولتر\n","مفرد كدام كلمه صحيح است\t['الوان : لون', 'حواس : احساس', 'اعضا: عضوها', 'الف وب']\t2\tاعضا: عضوها\t0\tالوان : لون\n","کدام عبارت، نادرست است؟\t['شاعر منظومه\\u200cهای حماسی مصنوع، با داستان\\u200cهای پهلوانی مدوّن و معینی سر و کار دارد.', 'قهرمانان حماسه، با نام رقّتی که از نظر عاطفی و احساسی در ان\\u200cها وجود دارد، فهرمانان ملّی هستند.', 'در حماسه مجموعه ای از وصف\\u200cها، خطبه\\u200cها و تصویرها وجود دارد امّا همه\\u200cی این عناصر نسبت به «داستانی بودن» در مرتبه ی دوم هستند.', 'در هر حماسه\\u200cای، رویدادهای غیرطبیعی و بیرون از نظام عادت دیده می\\u200cشود که تنها از رهگذر عقاید دینی عصر خود، توجیه\\u200cپذیر هستند.\\n']\t0\tشاعر منظومه‌های حماسی مصنوع، با داستان‌های پهلوانی مدوّن و معینی سر و کار دارد.\t0\tشاعر منظومه‌های حماسی مصنوع، با داستان‌های پهلوانی مدوّن و معینی سر و کار دارد.\n","متضاد کلمات مورد سؤال چیست؟ منصوب \t['مطرود', 'معزول', 'مغضوب', 'معذور']\t1\tمعزول\t0\tمطرود\n","متضاد کلمات مورد سؤال چیست؟ شیفته\t['نومید', 'دلسرد', 'بی قرار', 'بیزار']\t3\tبیزار\t0\tنومید\n","کدام واژه زیر با سه واژه دیگر تفاوت بسیار دارد؟\t['سیمبر', 'عنبر', 'دلبر', 'بریر']\t0\tسیمبر\t0\tسیمبر\n","کدام کلمه مفرد می باشد؟\t['بیگانگان', 'آفات', 'الوان', 'عضو']\t3\tعضو\t0\tبیگانگان\n","تعداد باب‌های «گلستان» چند است؟\t[' ده', 'هشت', 'نه', 'هفت']\t1\tهشت\t0\t ده\n","به غلط تصور کرده بود که با .............. خطاها می‌تواند از عواقب آنها مصون بماند\t['اصلاح', 'تشخیص', 'نادیده گرفتن', 'جلوگیری از']\t2\tنادیده گرفتن\t0\tاصلاح\n","کدام کلمه با سه کلمه دیگر هیچگونه مناسبتی ندارد؟\t['قنددان', 'خندان', 'گلدان', 'نمکدان']\t1\tخندان\t0\tقنددان\n","آنچه که از ارزش واقعی چیزی بکاهد :؟\t['انتقاد', 'شایعه', 'فراوانی', 'نقص']\t3\tنقص\t0\tانتقاد\n","معنی واژه‌های «مضغ، لابه، عقار، لطیفه» به‌ترتیب کدام است؟\t['بلعیدن- تضرع- زمین زراعی- نکته\\u200cی باریک', 'جویدن- تضرع- آب و زمین- گفتار نغز', 'فرو بردن- عجز و ناتوانی- آب و زمین- ظریف و باریک', 'آسیا کردن غذا در زیر دندان- التماس- کشت\\u200cزار- نغز و شیرین']\t1\tجویدن- تضرع- آب و زمین- گفتار نغز\t0\tبلعیدن- تضرع- زمین زراعی- نکته‌ی باریک\n","کدام گزینه ازموضوعات شعری عصررودکی نیست؟\t['وصف', 'عرفان', 'مدح', 'اندرز']\t1\tعرفان\t0\tوصف\n","مفهوم کلی عبارات زیر در کدام بیت مشهود است؟«به نام آن خدای که نام او راحت روح است و پیغام او مفتاح فتوح است. ذکر او مرهم دل مجروح است و مهر او بلانشینان را کشتی نوح است».\t['کاروانی که بود بدرقه\\u200cاش حفظ خدا    به تجمل بنشیند به جلالت برود', 'موج از این بار چنان کشتی طاقت بشکست    که عجب دارم اگر تخته به ساحل برود', 'زخم شمشیر غمت را به شکیبایی و عقل    چند مرهم بنهادیم و اثر می\\u200cنرود', 'سیاه نامه\\u200cتر از خود کسی نمی\\u200cبینم    چگونه چون قلمم، دود دل، به سر نرود']\t0\tکاروانی که بود بدرقه‌اش حفظ خدا    به تجمل بنشیند به جلالت برود\t0\tکاروانی که بود بدرقه‌اش حفظ خدا    به تجمل بنشیند به جلالت برود\n","کدام کتاب قصه است که «جنبه‌های واقعی و تاریخی و اخلاقی آن به هم آمیخته است؟»\t['عقل سرخ', 'آواز پر جبرئیل', 'مقامات حمیدی', 'تذکره\\u200cالاولیا']\t2\tمقامات حمیدی\t0\tعقل سرخ\n","رابطه نقاش با تصویر مثل رابطه :\t['معلم با دانش آموز', 'مولف با کتاب', 'باغبان با گل ', 'رئیس با کارمند']\t1\tمولف با کتاب\t0\tمعلم با دانش آموز\n","کدام گزینه از آثارناصرخسرو نیست؟\t['زادالعارفین', 'خوان واخوان', 'جام \\xadالحکمتین', 'سفرنام']\t0\tزادالعارفین\t0\tزادالعارفین\n","كدام گزينه اسم وصفت نيست؟\t['پروردگار بي همتا', 'چاپلوسان ثنا گو', 'وزيران لايق', 'منادي آزادي']\t3\tمنادي آزادي\t0\tپروردگار بي همتا\n","معنی کدام گروه از واژه‌ها «همگی» درست است؟\t['(بارقه: اسب تندرو)، (درره: بسته)', '(نسق: روش)، (صائب: درست)', '(اساطیر: خدایان)، (آبزن: برکه آب)', '(آژنگ: چین و شکن مو)، (اعصار: دوران)']\t1\t(نسق: روش)، (صائب: درست)\t0\t(بارقه: اسب تندرو)، (درره: بسته)\n","در باره ي جمله ي از هفت خوان رستم گذشته است . كدام مورد زير درست است\t['كنايه', 'مبالغه', 'تشبيه', 'ضرب المثل']\t0\tكنايه\t0\tكنايه\n","طامع یعنی ؟\t['آزمند', 'خوش شانس', 'محتاج', 'مطمئن']\t0\tآزمند\t0\tآزمند\n","متضاد کلمات مورد سؤال چیست؟ قریب\t['مأنوس', 'آشنا', 'عجیب', 'دور']\t3\tدور\t0\tمأنوس\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cgSPjuTYe71x","executionInfo":{"status":"ok","timestamp":1628958549711,"user_tz":-270,"elapsed":1323,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}}},"source":["output_file_name = \"multiple_choice_qa_literature_testset_{}_outputs.txt\".format(model_name.replace('/','-'))\n","with open(output_file_name, \"w\", encoding='utf8') as output_file:\n","  for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer in evaluation_output:\n","    output_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer))\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","upload = drive.CreateFile({'title': output_file_name})\n","upload.SetContentFile(output_file_name)\n","upload.Upload()"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AAcLHWgKGSHv"},"source":["### Samples with math_and_logic as their category"]},{"cell_type":"code","metadata":{"id":"bDozlPsr2Bp3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958549712,"user_tz":-270,"elapsed":14,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"0f1e1133-4ba9-4342-a383-05237635a475"},"source":["test_questions_ml, test_candidates_ml, test_choices_ml, test_answers_ml = mcqa_model.load_dataset_test_file(\n","    dataset_name=\"parsinlu-math_and_logic\", dataset_file=\"./parsinlu/data/multiple-choice/test_ml.jsonl\")\n","print(test_questions_ml[0])\n","print(test_candidates_ml[0])\n","print(test_choices_ml[0])\n","print(test_answers_ml[0])\n","print(len(test_questions_ml))\n","print(len(test_candidates_ml))\n","print(len(test_choices_ml))\n","print(len(test_answers_ml))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["تفاوت سن علیرضا و خواهرش A سال است B سال دیگر سن علیرضا دوبرابر سن امروز خواهرش خواهد بود .سن خواهر علیرضا کدام است؟\n","['2A', '2A+B', '3A+B', 'A-B']\n","2\n","2A+B\n","350\n","350\n","350\n","350\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uIbQCKZ1Igho","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958550471,"user_tz":-270,"elapsed":766,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"9b496171-e3b3-442a-947e-bf26201b1cf2"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Sat Aug 14 16:29:09 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P0    75W / 149W |   9737MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               63\n","Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n","Stepping:            0\n","CPU MHz:             2299.998\n","BogoMIPS:            4599.99\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            256K\n","L3 cache:            46080K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V0yABKemCZnv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958650248,"user_tz":-270,"elapsed":99780,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"82fa86a4-a68b-4fe2-8479-d359ae94ba5d"},"source":["evaluation_output = mcqa_model.evaluation(test_questions_ml, test_candidates_ml, test_choices_ml, test_answers_ml, device, max_length=mcqa_model.config.max_position_embeddings, batch_size=64)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["#question:350, #candidates:350, #answer:350\n","#batch: 6\n","Start to evaluate test data ...\n","inference time for step 0: 0.03240455399986786\n","inference time for step 1: 0.014611565999985032\n","inference time for step 2: 0.014465612000094552\n","inference time for step 3: 0.012961128999904759\n","inference time for step 4: 0.013460268000017095\n","inference time for step 5: 0.012797116000001552\n","average loss: 1.386294960975647\n","total inference time: 0.10070024499987085\n","total inference time / #samples: 0.0002877149857139167\n","Test Accuracy: 0.33714285714285713\n","Test Precision: 0.11366530612244898\n","Test Recall: 0.33714285714285713\n","Test F1-Score(weighted average): 0.17001221001221\n","Test classification Report:\n","              precision    recall  f1-score   support\n","\n","           0  0.3371428571 1.0000000000 0.5042735043       118\n","           1  0.0000000000 0.0000000000 0.0000000000        99\n","           2  0.0000000000 0.0000000000 0.0000000000        81\n","           3  0.0000000000 0.0000000000 0.0000000000        52\n","\n","    accuracy                      0.3371428571       350\n","   macro avg  0.0842857143 0.2500000000 0.1260683761       350\n","weighted avg  0.1136653061 0.3371428571 0.1700122100       350\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"O8Dgqmc1GAtz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958650248,"user_tz":-270,"elapsed":27,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"c88b6302-8f95-44f3-dd0d-8563f449e8c9"},"source":["for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer in evaluation_output[:25]:\n","  print('{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["تفاوت سن علیرضا و خواهرش A سال است B سال دیگر سن علیرضا دوبرابر سن امروز خواهرش خواهد بود .سن خواهر علیرضا کدام است؟\t['2A', '2A+B', '3A+B', 'A-B']\t1\t2A+B\t0\t2A\n","در ادامه این رشته چه عددی باید نوشت؟ ۹۱،۸۶،۷۶،۶۱،...\t['۴۶', '۴۱', '۵۱', '۳۶']\t1\t۴۱\t0\t۴۶\n","50 تا 20 تا برابر است با ......\t['10000', '100', '1000', '500']\t2\t1000\t0\t10000\n","در ادامه این رشته چه عددی باید نوشت؟             3, 5, 5, 9, 7, 13, 9, …\t['17', '11', '14', '15']\t0\t17\t0\t17\n","مساحت مربع ۸ ،p برابر مساحت مربع Q است. نسبت قطر مربع p به ضلع مربع Q کدامست؟\t['۴', '۲', '۳', '۱']\t0\t۴\t0\t۴\n","%50 عدد 24 برابر است با ....\t['4', '6', '10', '12']\t3\t12\t0\t4\n","کدام عدد نزدیکتر۷ به است؟\t['۴', '۶', '۹', '۱۱']\t1\t۶\t0\t۴\n","چند درصد ۵۰۰ برابر ۵۰ می‌شود؟\t['۱', '۱۰', '۲۰', '۳۰']\t1\t۱۰\t0\t۱\n","قیمت یک کالا %۲۵ تخفیف داده شده است برای آنکه این کالا به قیمت قبل از تخفیف فروخته شود چند درصد باید به قیمت آن افزوده گردد؟\t['۲۵', '۲۰', '۳۳.۳۳', 'هیچکدام']\t2\t۳۳.۳۳\t0\t۲۵\n","حاصل عبارت ۵ - ۳ برابر است با ؟\t['-2', '2', '1', '-1']\t0\t-2\t0\t-2\n","حاصل عبارت ۴۴ + ۲۳ برابر است با ؟\t['68', '65', '57', '67']\t3\t67\t0\t68\n","سرمایه دو شریک به نسبت او ۱ می‌باشد سود نفر دوم در یک معامله ۹۰۰ تومان است کل مبلغ سود\r\n","چند تومان است. کل مبلغ سود چند تومان می‌شود؟\r\t['۷۲۰', '۳۶۰۰', '۱۶۲۰', '۴۵۰۰']\t2\t۱۶۲۰\t0\t۷۲۰\n","۵۴۰۰ لیتر بنزین برای مصرف ۹ اتومبیل یک شرکت راهسازی در مدت ۲۰ روز مأموریت داده شده است. با\n","افزوده شدن ۳ اتومبیل دیگر ۲ روز از مدت مأموریت کم می‌شود در صورتی که مقدار بنزین دریافتی تغییر\n","نکند. سهمیه بنزین روزانه هر اتومبیل:\n","\t['زیاد شده است', 'کم شده است', 'تغییر نکرده است', 'قابل تعیین نیست']\t1\tکم شده است\t0\tزیاد شده است\n","نسبت اسید دریک ماده شیمیایی %۳ است، ۶۰ لیتر از این ماده را با چند لیتر ماده بدون اسید باید مخلوط کرد تا نسبت اسید مخلوط %۱ شود؟\t['۸۰', '۱۰۰', '۱۲۰', '۱۵۰']\t2\t۱۲۰\t0\t۸۰\n","اگر یک سوم چوبی در زمین و یک دوم « در آب و قسمت بالائی‌آن که بیرون از آب قرار دارد ۱/۵ متر باشد،طول چوب چقدر است؟\t['4.5', '6', '9', '10.5']\t2\t9\t0\t4.5\n","کدامیک ازاعداد زیرازعدد 43 کوچکتراست؟\t['45', '54', '49', '34']\t3\t34\t0\t45\n"," ﻜﺪاﻡ عبارت صحیح نیست ؟\t['اﺯﺪو نقطه فقط یک خط راست می ﮔﺬارﺪ.', 'اﮔﺮخطی بر خط ﺪﻴﮔﺮعموﺪباﺷﺪبر خطوط مواﺯی آن ﻨﻳﺯعموﺪاست.', 'هر خط عموﺪبر خط ﺪﻴﮔﺮعموﺪمنصف آن خط است.', 'هر قطر لوﺯی عموﺪمنصف قطر ﺪﻴﮔﺮاست.']\t2\tهر خط عموﺪبر خط ﺪﻴﮔﺮعموﺪمنصف آن خط است.\t0\tاﺯﺪو نقطه فقط یک خط راست می ﮔﺬارﺪ.\n","حاصل 10*9*8  با فاکتوریل کدام عدد طبیعی است؟\t['۶', '۷', '۸', '۹']\t0\t۶\t0\t۶\n","شعاع دایره ای یک دهم افزایش یافته است. مساحت مربع محاطی آن چند درصد افزایش می‌یابد؟\t['۷۹', '۲۱', '۱۹', '۸۱']\t1\t۲۱\t0\t۷۹\n","پدری نصف دارائی خود را بین ۳ فرزندش تقسیم کرده چه کسری از کل دارائی پدر به هر پسر می رسد؟\t['یک ششم', 'یک پنجم', 'یک چهارم', 'یک سوم']\t0\tیک ششم\t0\tیک ششم\n","شخصی جنسی را به ۲۰۰۰ ریال خریده بود به ۲۴۰۰ ریال فروخت. حال اگر جنسی را به ۶۰۰۰ ریال بفروشد به چند ریال خریده بود؟\t['۵۴۰۰', '۵۲۰۰', '۵۰۰۰', '۲۸۰۰']\t2\t۵۰۰۰\t0\t۵۴۰۰\n","یک مخزن بنزین، دو مجرا دارد، اولی مخزن را در ۶ ساعت و هر دو مجرا با هم آن را در ۴ ساعت خالی\n","می‌کنند، در صورتی که مخزن خالی و فقط مجرای دوم باز باشد مخزن در چند ساعت خالی می‌شود؟\n","\t['۱۲ ساعت', '۸ ساعت', '۴ ساعت', '۳ ساعت']\t1\t۸ ساعت\t0\t۱۲ ساعت\n"," برای انجام عمل تقسیم به ﺪوﻋﺪﺪ نیاﺯﻤﻧﺪﻴﻡ که  عبارﺗﻧﺪﺍﺯ:۟۟۟۟۟۰۰۰۰۰۰۰۰ ۟۟۟۟۟۰۰۰۰۰۰۰۰\t['مقسوم علیه وخارج قسمت', 'مقسوم ومقسوم علیه', 'مقسوم وباقی ماﻧﺪﻩ', 'خارج قسمت و باقی ماﻧﺪﻩ']\t1\tمقسوم ومقسوم علیه\t0\tمقسوم علیه وخارج قسمت\n","موتورسواری با سرعت متوسط ۶۰ کیلومتر در ساعت فاصله بین دو شهر را طی می‌کند و همین فاصله را با سرعت متوسط ۴۰ کیلومتر در ساعت برمی گردد.\r\n","سرعت متوسط او برای تمام مسیر رفت و برگشت عبارت است از\r\t['۵۳ کیلومتر در ساعت', '۵ کیلومتر در ساعت', '۴۸ کیلومتر در ساعت', '۵۲ کیلومتر در ساعت']\t2\t۴۸ کیلومتر در ساعت\t0\t۵۳ کیلومتر در ساعت\n","به یک نوع کالا نسبت به هشتاد درصد قیمت آن صد و بیست درصد سود بازرگانی تعلـق مـیگیـرد. افـزایش\n","قیمت با محاسبۀ سود بازرگانی چند درصد است؟ \t['۹۶', '۷۶', '۱۹۶', '۱۷۶']\t0\t۹۶\t0\t۹۶\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"afCYGzT6ImPn","executionInfo":{"status":"ok","timestamp":1628958651635,"user_tz":-270,"elapsed":1405,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}}},"source":["output_file_name = \"multiple_choice_qa_math_and_logic_testset_{}_outputs.txt\".format(model_name.replace('/','-'))\n","with open(output_file_name, \"w\", encoding='utf8') as output_file:\n","  for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer in evaluation_output:\n","    output_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer))\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","upload = drive.CreateFile({'title': output_file_name})\n","upload.SetContentFile(output_file_name)\n","upload.Upload()"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nkj_IXan2xiP"},"source":["### Samples with common_knowledge as their category"]},{"cell_type":"code","metadata":{"id":"mLsuGEuQIgkO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958651636,"user_tz":-270,"elapsed":10,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"8642e673-ac2c-49fa-ba46-9c2c15e111b4"},"source":["test_questions_ck, test_candidates_ck, test_choices_ck, test_answers_ck = mcqa_model.load_dataset_test_file(\n","    dataset_name=\"parsinlu-common_knowledge\", dataset_file=\"./parsinlu/data/multiple-choice/test_ck.jsonl\")\n","print(test_questions_ck[0])\n","print(test_candidates_ck[0])\n","print(test_choices_ck[0])\n","print(test_answers_ck[0])\n","print(len(test_questions_ck))\n","print(len(test_candidates_ck))\n","print(len(test_choices_ck))\n","print(len(test_answers_ck))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["کدام کشور اولین تولید کننده خرما در جهان است؟\n","['ایران', 'عربستان', 'عراق', 'سوریه']\n","1\n","ایران\n","350\n","350\n","350\n","350\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4L8td12qDZCP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958652536,"user_tz":-270,"elapsed":907,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"6a39752e-e4da-45bc-9892-9b68a8fb7850"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Sat Aug 14 16:30:51 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P0    75W / 149W |   9737MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               63\n","Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n","Stepping:            0\n","CPU MHz:             2299.998\n","BogoMIPS:            4599.99\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            256K\n","L3 cache:            46080K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5LjF9gcR2uXK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958752157,"user_tz":-270,"elapsed":99625,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"d418d72b-fcd7-42a8-f980-00fbb553d56b"},"source":["evaluation_output = mcqa_model.evaluation(test_questions_ck, test_candidates_ck, test_choices_ck, test_answers_ck, device, max_length=mcqa_model.config.max_position_embeddings, batch_size=64)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["#question:350, #candidates:350, #answer:350\n","#batch: 6\n","Start to evaluate test data ...\n","inference time for step 0: 0.028676126999926055\n","inference time for step 1: 0.013654233999886856\n","inference time for step 2: 0.012828121999973519\n","inference time for step 3: 0.013481522000120094\n","inference time for step 4: 0.013668872999915038\n","inference time for step 5: 0.014449926999986928\n","average loss: 1.386294960975647\n","total inference time: 0.09675880499980849\n","total inference time / #samples: 0.0002764537285708814\n","Test Accuracy: 0.28\n","Test Precision: 0.0784\n","Test Recall: 0.28\n","Test F1-Score(weighted average): 0.12250000000000003\n","Test classification Report:\n","              precision    recall  f1-score   support\n","\n","           0  0.2800000000 1.0000000000 0.4375000000        98\n","           1  0.0000000000 0.0000000000 0.0000000000        88\n","           2  0.0000000000 0.0000000000 0.0000000000        94\n","           3  0.0000000000 0.0000000000 0.0000000000        70\n","\n","    accuracy                      0.2800000000       350\n","   macro avg  0.0700000000 0.2500000000 0.1093750000       350\n","weighted avg  0.0784000000 0.2800000000 0.1225000000       350\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"huGRjXMT3Pay","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958752158,"user_tz":-270,"elapsed":23,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"9a1adcc5-59a2-4f29-f880-f72fc164e571"},"source":["for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer in evaluation_output[:25]:\n","  print('{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["کدام کشور اولین تولید کننده خرما در جهان است؟\t['ایران', 'عربستان', 'عراق', 'سوریه']\t0\tایران\t0\tایران\n","مقام رهبری در قانون اساسی جمهوری اسلامی دارای چه کار ویژه ای است؟\t['ریاست کشور', 'نظارت عالیه', 'تنظیم کننده قوای سه گانه', 'حاکمیت مطلق']\t2\tتنظیم کننده قوای سه گانه\t0\tریاست کشور\n","الماس سخت تر است یا گرانیت؟\t['الماس', 'گرانیت', '', '']\t0\tالماس\t0\tالماس\n","طبق قانون اساسی شورای نگهبان طی چند روز از تاریخ وصول باید نظر خود را نسبت به مصوبات مجلس\r\n","اعلام نماید؟\r\t['یک ماه', 'ده روز', 'دو هفته', 'تا حصول اطمینان']\t1\tده روز\t0\tیک ماه\n","در کشور ایران بیشترین نرخ بیکاری متعلق به کدام یک از گزینه های زیر میباشد؟\t['دارندگان مدرک تحصیلی تکمیلی', 'افراد زیر دیپلم', 'افراد بالای 50 سال', 'فارغ التحصیلان دانشگاهها']\t0\tدارندگان مدرک تحصیلی تکمیلی\t0\tدارندگان مدرک تحصیلی تکمیلی\n","ریاست اولین دوره مجلس شورای اسلامی بر عهده چه کسی بود؟\t['آیت الله بهشتی', 'آیت الله کروبی', 'آیت الله رفسنجانی', 'آیت الله ناطق نوری']\t3\tآیت الله ناطق نوری\t0\tآیت الله بهشتی\n","سوره بیست و هفتم قرآن کریم کدامست؟\t['سوره اسراء', 'سوره توبه', 'سوره واقعه', 'سوره نحل']\t2\tسوره واقعه\t0\tسوره اسراء\n","در ترمز ضد قفل برای ترمز گیری باید پا رابه صورت ……………..روی پدال ترمزفشرد.\t['ممتد', 'منقطع', 'آهسته', 'محکم']\t0\tممتد\t0\tممتد\n","«تفسیر سور آبادی» تألیف کدام شخص است؟\t['ابوبکر عتیق نیشابوری', 'علامه مجلسی', 'علامه طباطبائی', 'شیخ طوسی']\t0\tابوبکر عتیق نیشابوری\t0\tابوبکر عتیق نیشابوری\n","حضرت علی “ع” در کدام جنگ در مقابل خوارج ایستاد؟\t['نهروان', 'صفین', 'جمل', 'خیبر']\t0\tنهروان\t0\tنهروان\n","مصوبات مجمع تشخیص مصلحت نظام باید به تأیید ......... برسد.\t['مجلس خبرگان', 'رئیس جمهور', 'شورای نگهبان', 'مقام رهبری']\t3\tمقام رهبری\t0\tمجلس خبرگان\n","کدام مورد معادل مناسب تری برای واژه “کارنگ” است؟\t['سیاست مدار', 'چرب زبان', 'کارشناس', 'آرامش دهنده']\t1\tچرب زبان\t0\tسیاست مدار\n","تصویب عهدنامه‌ها، مقاوله‌نامه‌ها، قراردادها و موافقت‌نامه‌های بین‌المللی برعهده کدام مرجع می‌باشد؟\t['مجلس شورای اسلامی', 'هیأت دولت', 'وزارت امور خارجه', 'مجمع تشخیص مصلحت نظام']\t0\tمجلس شورای اسلامی\t0\tمجلس شورای اسلامی\n","چرا نجوم از مهم ترين دانش هايي بود كه مردم ميان دو رود در آن پيشرفت چشمگيري كردند؟\t['وجود دادو ستد و امور بازرگاني', 'رواج خرافات', 'پرستش ستارگان و تاثير آنها در سرنوشت انسان', 'اعتقاد به ارواحي كه در بدن نفوذ مي كردند.']\t2\tپرستش ستارگان و تاثير آنها در سرنوشت انسان\t0\tوجود دادو ستد و امور بازرگاني\n","پنج کشوری که در سازمان ملل متحد دارای حق« وتو » می باشند، کدامند؟\t['چین ، فرانسه، انگلیس ، آمریکا ، شوروی', 'آمریکا، انگلیس، آلمان، سوئیس، شوروی', 'آمریکا، شوروی، فرانسه، آلمان، چین', 'چین ، فرانسه ، ایتالیا ، آمریکا ، انگلیس']\t0\tچین ، فرانسه، انگلیس ، آمریکا ، شوروی\t0\tچین ، فرانسه، انگلیس ، آمریکا ، شوروی\n","وسیع ترین کشور جهان کدام است؟\t['آمریکا', 'کانادا', 'روسیه', 'چین']\t2\tروسیه\t0\tآمریکا\n","مشهورترین ملاك برای طبقه بندی حز ب های سیاسی کدامند؟\t['ملاك فرهنگی', 'ملاك اجتماعی', 'ملاك جهان بینی', 'ملاك ایدئولوژی']\t3\tملاك ایدئولوژی\t0\tملاك فرهنگی\n","مراجعه به افکار عمومی توسط کدام مرجع زیر صورت می‌گیرد؟\t['مجلس شورای اسلامی', 'شورای نگهبان', 'مجمع تشخیص مصلحت نظام', 'مجلس خبرگان رهبری']\t1\tشورای نگهبان\t0\tمجلس شورای اسلامی\n","IT مخفف چیست ؟\t['Information Technical', 'Information Types', 'Information Training', 'Information Technology']\t3\tInformation Technology\t0\tInformation Technical\n","« بیمه » قراردادی است که ، اعتبار آن ......................\t['مادام العمر، به شرط دادن حق بیمه است.', 'مادام العمر است.', 'چند سال معین ، از چهل سالگی به بعد است.', 'چند سال معین تا زمانی است که حق بیمه منقضی می شود.']\t3\tچند سال معین تا زمانی است که حق بیمه منقضی می شود.\t0\tمادام العمر، به شرط دادن حق بیمه است.\n","دعوت نهانی پیامبر (ص) به اسلام چند سال به طول انجامید؟\t['۷ سال', '۳ سال', '۲۳ سال', '۶ سال']\t1\t۳ سال\t0\t۷ سال\n","ماد و لودیه با وساطت چه حکومتی صلح کردند؟\t['مصر', 'بابل', 'آتن', 'اسپارت']\t1\tبابل\t0\tمصر\n","»Talweg» تالوگ چیست؟\t['خطی که از میان عمیقترین نقطه بستر رودخانه بین المللی عبور و مرز را مشخص می کند.', 'خطی که رودخانه بین المللی را به دو بخش تقسیم و مرز را تعیین می کند.', 'خطی فرضی که بستر رودخانه را به دو نیم تقسیم و مرز را معین می کند.', 'خطی فرضی که مرز رودخانه بین المللی را مشخص می کند.']\t0\tخطی که از میان عمیقترین نقطه بستر رودخانه بین المللی عبور و مرز را مشخص می کند.\t0\tخطی که از میان عمیقترین نقطه بستر رودخانه بین المللی عبور و مرز را مشخص می کند.\n","تعداد فقهای شورای نگهبان چند نفر است؟\t['۶', '۱۲', '۵', '۹']\t0\t۶\t0\t۶\n","سطح روغن موتور هر چند وقت یکبار باید بررسی گردد ؟\t['هر روز', 'یک بار در ماه', 'هر دو هزار کیلومتر کارکرد', 'هفته ای یکبار']\t3\tهفته ای یکبار\t0\tهر روز\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1mO_rEyM3Pd_","executionInfo":{"status":"ok","timestamp":1628958753520,"user_tz":-270,"elapsed":1377,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}}},"source":["output_file_name = \"multiple_choice_qa_common_knowledge_testset_{}_outputs.txt\".format(model_name.replace('/','-'))\n","with open(output_file_name, \"w\", encoding='utf8') as output_file:\n","  for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer in evaluation_output:\n","    output_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer))\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","upload = drive.CreateFile({'title': output_file_name})\n","upload.SetContentFile(output_file_name)\n","upload.Upload()"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9th_LvQz9HWH"},"source":["### All Samples"]},{"cell_type":"code","metadata":{"id":"OZqiKAMW2uUE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958753521,"user_tz":-270,"elapsed":14,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"13cef5cb-76be-4897-ea61-a3a5f02e246b"},"source":["test_questions_all, test_candidates_all, test_choices_all, test_answers_all = mcqa_model.load_dataset_test_file(\n","    dataset_name=\"parsinlu\", dataset_file=\"./parsinlu/data/multiple-choice/test.jsonl\")\n","print(test_questions_all[0])\n","print(test_candidates_all[0])\n","print(test_choices_all[0])\n","print(test_answers_all[0])\n","print(len(test_questions_all))\n","print(len(test_candidates_all))\n","print(len(test_choices_all))\n","print(len(test_answers_all))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["تفاوت سن علیرضا و خواهرش A سال است B سال دیگر سن علیرضا دوبرابر سن امروز خواهرش خواهد بود .سن خواهر علیرضا کدام است؟\n","['2A', '2A+B', '3A+B', 'A-B']\n","2\n","2A+B\n","1050\n","1050\n","1050\n","1050\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WH51PCVZ9LvB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958753523,"user_tz":-270,"elapsed":12,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"8bda0b4c-1f08-4afd-f0d4-59ce3d1884fb"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Sat Aug 14 16:32:32 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P0    75W / 149W |   9737MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               63\n","Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n","Stepping:            0\n","CPU MHz:             2299.998\n","BogoMIPS:            4599.99\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            256K\n","L3 cache:            46080K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"laMQutR_9YYl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959048719,"user_tz":-270,"elapsed":295203,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"edbc02e2-8387-44f1-c302-819540c4e7a5"},"source":["evaluation_output = mcqa_model.evaluation(test_questions_all, test_candidates_all, test_choices_all, test_answers_all, device, max_length=mcqa_model.config.max_position_embeddings, batch_size=64)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["#question:1050, #candidates:1050, #answer:1050\n","#batch: 17\n","Start to evaluate test data ...\n","inference time for step 0: 0.030340919999844118\n","inference time for step 1: 0.013511065999864513\n","inference time for step 2: 0.01319325399981608\n","inference time for step 3: 0.013195635000101902\n","inference time for step 4: 0.01410048499997174\n","inference time for step 5: 0.014772160999882544\n","inference time for step 6: 0.013950459000170667\n","inference time for step 7: 0.01314560699984213\n","inference time for step 8: 0.012997301000041261\n","inference time for step 9: 0.013062275000038426\n","inference time for step 10: 0.013444698000057542\n","inference time for step 11: 0.012968922000027305\n","inference time for step 12: 0.012907688000041162\n","inference time for step 13: 0.01359299499995359\n","inference time for step 14: 0.013277947999995376\n","inference time for step 15: 0.013954045999980735\n","inference time for step 16: 0.012814939000008962\n","average loss: 1.3862949539633358\n","total inference time: 0.24523039899963806\n","total inference time / #samples: 0.00023355276095203624\n","Test Accuracy: 0.27714285714285714\n","Test Precision: 0.07680816326530612\n","Test Recall: 0.27714285714285714\n","Test F1-Score(weighted average): 0.12028124001278363\n","Test classification Report:\n","              precision    recall  f1-score   support\n","\n","           0  0.2771428571 1.0000000000 0.4340044743       291\n","           1  0.0000000000 0.0000000000 0.0000000000       289\n","           2  0.0000000000 0.0000000000 0.0000000000       268\n","           3  0.0000000000 0.0000000000 0.0000000000       202\n","\n","    accuracy                      0.2771428571      1050\n","   macro avg  0.0692857143 0.2500000000 0.1085011186      1050\n","weighted avg  0.0768081633 0.2771428571 0.1202812400      1050\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"La5YYuVJ9Lx-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959048720,"user_tz":-270,"elapsed":27,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"a63c3245-4ef0-4175-ddca-78697b2be1e3"},"source":["for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer in evaluation_output[:25]:\n","  print('{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["تفاوت سن علیرضا و خواهرش A سال است B سال دیگر سن علیرضا دوبرابر سن امروز خواهرش خواهد بود .سن خواهر علیرضا کدام است؟\t['2A', '2A+B', '3A+B', 'A-B']\t1\t2A+B\t0\t2A\n","در ادامه این رشته چه عددی باید نوشت؟ ۹۱،۸۶،۷۶،۶۱،...\t['۴۶', '۴۱', '۵۱', '۳۶']\t1\t۴۱\t0\t۴۶\n","50 تا 20 تا برابر است با ......\t['10000', '100', '1000', '500']\t2\t1000\t0\t10000\n","در ادامه این رشته چه عددی باید نوشت؟             3, 5, 5, 9, 7, 13, 9, …\t['17', '11', '14', '15']\t0\t17\t0\t17\n","مساحت مربع ۸ ،p برابر مساحت مربع Q است. نسبت قطر مربع p به ضلع مربع Q کدامست؟\t['۴', '۲', '۳', '۱']\t0\t۴\t0\t۴\n","%50 عدد 24 برابر است با ....\t['4', '6', '10', '12']\t3\t12\t0\t4\n","کدام عدد نزدیکتر۷ به است؟\t['۴', '۶', '۹', '۱۱']\t1\t۶\t0\t۴\n","چند درصد ۵۰۰ برابر ۵۰ می‌شود؟\t['۱', '۱۰', '۲۰', '۳۰']\t1\t۱۰\t0\t۱\n","قیمت یک کالا %۲۵ تخفیف داده شده است برای آنکه این کالا به قیمت قبل از تخفیف فروخته شود چند درصد باید به قیمت آن افزوده گردد؟\t['۲۵', '۲۰', '۳۳.۳۳', 'هیچکدام']\t2\t۳۳.۳۳\t0\t۲۵\n","حاصل عبارت ۵ - ۳ برابر است با ؟\t['-2', '2', '1', '-1']\t0\t-2\t0\t-2\n","حاصل عبارت ۴۴ + ۲۳ برابر است با ؟\t['68', '65', '57', '67']\t3\t67\t0\t68\n","سرمایه دو شریک به نسبت او ۱ می‌باشد سود نفر دوم در یک معامله ۹۰۰ تومان است کل مبلغ سود\r\n","چند تومان است. کل مبلغ سود چند تومان می‌شود؟\r\t['۷۲۰', '۳۶۰۰', '۱۶۲۰', '۴۵۰۰']\t2\t۱۶۲۰\t0\t۷۲۰\n","۵۴۰۰ لیتر بنزین برای مصرف ۹ اتومبیل یک شرکت راهسازی در مدت ۲۰ روز مأموریت داده شده است. با\n","افزوده شدن ۳ اتومبیل دیگر ۲ روز از مدت مأموریت کم می‌شود در صورتی که مقدار بنزین دریافتی تغییر\n","نکند. سهمیه بنزین روزانه هر اتومبیل:\n","\t['زیاد شده است', 'کم شده است', 'تغییر نکرده است', 'قابل تعیین نیست']\t1\tکم شده است\t0\tزیاد شده است\n","نسبت اسید دریک ماده شیمیایی %۳ است، ۶۰ لیتر از این ماده را با چند لیتر ماده بدون اسید باید مخلوط کرد تا نسبت اسید مخلوط %۱ شود؟\t['۸۰', '۱۰۰', '۱۲۰', '۱۵۰']\t2\t۱۲۰\t0\t۸۰\n","اگر یک سوم چوبی در زمین و یک دوم « در آب و قسمت بالائی‌آن که بیرون از آب قرار دارد ۱/۵ متر باشد،طول چوب چقدر است؟\t['4.5', '6', '9', '10.5']\t2\t9\t0\t4.5\n","کدامیک ازاعداد زیرازعدد 43 کوچکتراست؟\t['45', '54', '49', '34']\t3\t34\t0\t45\n"," ﻜﺪاﻡ عبارت صحیح نیست ؟\t['اﺯﺪو نقطه فقط یک خط راست می ﮔﺬارﺪ.', 'اﮔﺮخطی بر خط ﺪﻴﮔﺮعموﺪباﺷﺪبر خطوط مواﺯی آن ﻨﻳﺯعموﺪاست.', 'هر خط عموﺪبر خط ﺪﻴﮔﺮعموﺪمنصف آن خط است.', 'هر قطر لوﺯی عموﺪمنصف قطر ﺪﻴﮔﺮاست.']\t2\tهر خط عموﺪبر خط ﺪﻴﮔﺮعموﺪمنصف آن خط است.\t0\tاﺯﺪو نقطه فقط یک خط راست می ﮔﺬارﺪ.\n","حاصل 10*9*8  با فاکتوریل کدام عدد طبیعی است؟\t['۶', '۷', '۸', '۹']\t0\t۶\t0\t۶\n","شعاع دایره ای یک دهم افزایش یافته است. مساحت مربع محاطی آن چند درصد افزایش می‌یابد؟\t['۷۹', '۲۱', '۱۹', '۸۱']\t1\t۲۱\t0\t۷۹\n","پدری نصف دارائی خود را بین ۳ فرزندش تقسیم کرده چه کسری از کل دارائی پدر به هر پسر می رسد؟\t['یک ششم', 'یک پنجم', 'یک چهارم', 'یک سوم']\t0\tیک ششم\t0\tیک ششم\n","شخصی جنسی را به ۲۰۰۰ ریال خریده بود به ۲۴۰۰ ریال فروخت. حال اگر جنسی را به ۶۰۰۰ ریال بفروشد به چند ریال خریده بود؟\t['۵۴۰۰', '۵۲۰۰', '۵۰۰۰', '۲۸۰۰']\t2\t۵۰۰۰\t0\t۵۴۰۰\n","یک مخزن بنزین، دو مجرا دارد، اولی مخزن را در ۶ ساعت و هر دو مجرا با هم آن را در ۴ ساعت خالی\n","می‌کنند، در صورتی که مخزن خالی و فقط مجرای دوم باز باشد مخزن در چند ساعت خالی می‌شود؟\n","\t['۱۲ ساعت', '۸ ساعت', '۴ ساعت', '۳ ساعت']\t1\t۸ ساعت\t0\t۱۲ ساعت\n"," برای انجام عمل تقسیم به ﺪوﻋﺪﺪ نیاﺯﻤﻧﺪﻴﻡ که  عبارﺗﻧﺪﺍﺯ:۟۟۟۟۟۰۰۰۰۰۰۰۰ ۟۟۟۟۟۰۰۰۰۰۰۰۰\t['مقسوم علیه وخارج قسمت', 'مقسوم ومقسوم علیه', 'مقسوم وباقی ماﻧﺪﻩ', 'خارج قسمت و باقی ماﻧﺪﻩ']\t1\tمقسوم ومقسوم علیه\t0\tمقسوم علیه وخارج قسمت\n","موتورسواری با سرعت متوسط ۶۰ کیلومتر در ساعت فاصله بین دو شهر را طی می‌کند و همین فاصله را با سرعت متوسط ۴۰ کیلومتر در ساعت برمی گردد.\r\n","سرعت متوسط او برای تمام مسیر رفت و برگشت عبارت است از\r\t['۵۳ کیلومتر در ساعت', '۵ کیلومتر در ساعت', '۴۸ کیلومتر در ساعت', '۵۲ کیلومتر در ساعت']\t2\t۴۸ کیلومتر در ساعت\t0\t۵۳ کیلومتر در ساعت\n","به یک نوع کالا نسبت به هشتاد درصد قیمت آن صد و بیست درصد سود بازرگانی تعلـق مـیگیـرد. افـزایش\n","قیمت با محاسبۀ سود بازرگانی چند درصد است؟ \t['۹۶', '۷۶', '۱۹۶', '۱۷۶']\t0\t۹۶\t0\t۹۶\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T_YDCiUN9gYV","executionInfo":{"status":"ok","timestamp":1628959050053,"user_tz":-270,"elapsed":1350,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}}},"source":["output_file_name = \"multiple_choice_qa_all_testset_{}_outputs.txt\".format(model_name.replace('/','-'))\n","with open(output_file_name, \"w\", encoding='utf8') as output_file:\n","  for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer in evaluation_output:\n","    output_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer))\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","upload = drive.CreateFile({'title': output_file_name})\n","upload.SetContentFile(output_file_name)\n","upload.Upload()"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpBvPple9gbd"},"source":[""],"execution_count":null,"outputs":[]}]}