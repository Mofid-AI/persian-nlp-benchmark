{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MultipleChoiceQA/persiannlp/parsbert-base-parsinlu-multiple-choice.ipynb","provenance":[{"file_id":"1c5WvqQKKZnab7GsUVa6fi1Q8vYwvlLTc","timestamp":1624943579756}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a1b895c6723a4d15bebbe59509ea9dab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_aca444741f304acabe4c83f45d2acd2c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dc49e26a0ec348528e32cca4e1171e4f","IPY_MODEL_719e18ff4286401da0da1d3fc3e32ede","IPY_MODEL_d29b028e12584df88bf3b453b0dfdaae"]}},"aca444741f304acabe4c83f45d2acd2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dc49e26a0ec348528e32cca4e1171e4f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1087a32310fe4691b1a92fd1421411fe","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3abff727fdd44e9fbb21d9fc190017ef"}},"719e18ff4286401da0da1d3fc3e32ede":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_60a70ffad39b40b2965d1a180815634e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":711,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":711,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9b861a29531b4f8a98625e8b67cb3f3f"}},"d29b028e12584df88bf3b453b0dfdaae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_21f19b323da14f3691ed6e01b302bc30","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 711/711 [00:00&lt;00:00, 16.4kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9941b55554c843739fbb211f2abcc4e8"}},"1087a32310fe4691b1a92fd1421411fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3abff727fdd44e9fbb21d9fc190017ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"60a70ffad39b40b2965d1a180815634e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9b861a29531b4f8a98625e8b67cb3f3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21f19b323da14f3691ed6e01b302bc30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9941b55554c843739fbb211f2abcc4e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"777627ba95eb45fb9a440f835c47613b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8a000abbf4944570915c6b531909d87e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_af5c69836c604e2e9fb64f628ff56d24","IPY_MODEL_9ec063dbe07e4d14a2c45c122ad9bb80","IPY_MODEL_7a8dd56ff3c2437ead2973c33b83686d"]}},"8a000abbf4944570915c6b531909d87e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"af5c69836c604e2e9fb64f628ff56d24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_44ebbd5586e2474b9876fe397a1a32f3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_13dd92a00ee54a26aa793df33ff13d6a"}},"9ec063dbe07e4d14a2c45c122ad9bb80":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_38a192075ec847e9b055ca72d8e25457","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1215509,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1215509,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_652fe48bb7ac402393d9aa158f80f3ad"}},"7a8dd56ff3c2437ead2973c33b83686d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9c3d01e5855449f485d665dbe5dc2820","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.22M/1.22M [00:00&lt;00:00, 4.47MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a8a1cb3ef2c54752a2acecd11e997a24"}},"44ebbd5586e2474b9876fe397a1a32f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"13dd92a00ee54a26aa793df33ff13d6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"38a192075ec847e9b055ca72d8e25457":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"652fe48bb7ac402393d9aa158f80f3ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c3d01e5855449f485d665dbe5dc2820":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a8a1cb3ef2c54752a2acecd11e997a24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"44995cce9df7468182febf1b00f5f386":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_10ec382d3c4f4c2683739ec80108faf5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_013aca15956c466790b31309bfdac046","IPY_MODEL_1f354b425cba49e8aa2ea131da97b6aa","IPY_MODEL_13a7947f1d5b440eb6f38ef7495bef05"]}},"10ec382d3c4f4c2683739ec80108faf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"013aca15956c466790b31309bfdac046":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2f0800f7ccda40e3913ab939f23323df","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_34a0fad0fda04b719aa8c827179ac146"}},"1f354b425cba49e8aa2ea131da97b6aa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4a751baf19e24b19b8da494dc0662f6a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_452f9df99c4743dfbee31e911e91ba78"}},"13a7947f1d5b440eb6f38ef7495bef05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f3613eaf96004de4b4af3680ebb0d0d6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 3.22kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_122939d169534992aec9cc95eea7d2c6"}},"2f0800f7ccda40e3913ab939f23323df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"34a0fad0fda04b719aa8c827179ac146":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a751baf19e24b19b8da494dc0662f6a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"452f9df99c4743dfbee31e911e91ba78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f3613eaf96004de4b4af3680ebb0d0d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"122939d169534992aec9cc95eea7d2c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"82038b8f2d674b6e843a043a5e449e67":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3b035415d86f42fdad8e6667b2283c26","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_22f8dc65f7ae49dea3082ecd34e91104","IPY_MODEL_acdb62426a4f4b59a06ea89207ba943c","IPY_MODEL_f78d8655700840e79f65b3e455ffc1a9"]}},"3b035415d86f42fdad8e6667b2283c26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"22f8dc65f7ae49dea3082ecd34e91104":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2344eba2688e435ba08817e29dca0aaa","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a9f15b33a9ac41f6a4157db871415b4e"}},"acdb62426a4f4b59a06ea89207ba943c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_09b7eb5bd53949c0be43aa572d584335","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":62,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":62,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fc681464f04047e4b8495ae0c2f432d3"}},"f78d8655700840e79f65b3e455ffc1a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f8c92a24adf84acc8a73369aa7e3752b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 62.0/62.0 [00:00&lt;00:00, 1.78kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6a69efd779284f41b3f11355e8e25763"}},"2344eba2688e435ba08817e29dca0aaa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a9f15b33a9ac41f6a4157db871415b4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"09b7eb5bd53949c0be43aa572d584335":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fc681464f04047e4b8495ae0c2f432d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f8c92a24adf84acc8a73369aa7e3752b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6a69efd779284f41b3f11355e8e25763":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5306a63d57ec4a7aa9956e099f2ae88a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_210b5907e8a54e1a9cc486bfc51883d5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e995baf256b74288ae22c8c2a40d76f9","IPY_MODEL_333f39848046420ab89a63da1cfd5b60","IPY_MODEL_cc4ee0d28d4743ccb96f905ebcf00f41"]}},"210b5907e8a54e1a9cc486bfc51883d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e995baf256b74288ae22c8c2a40d76f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f47b04233d4c418aad8e93ffd404a9cb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2c5f5d2008fd434680b6ace0d16f9f08"}},"333f39848046420ab89a63da1cfd5b60":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d7cfaa32b3f74365943a214bca889d96","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":651454985,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":651454985,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6a216faca938431699ea3fa756577e1d"}},"cc4ee0d28d4743ccb96f905ebcf00f41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_379eb892c17e4240ae34718a75e74a2a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 651M/651M [00:15&lt;00:00, 42.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ca2fc4eb9c994cc2a2f1dbdab98aa3d1"}},"f47b04233d4c418aad8e93ffd404a9cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2c5f5d2008fd434680b6ace0d16f9f08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7cfaa32b3f74365943a214bca889d96":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6a216faca938431699ea3fa756577e1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"379eb892c17e4240ae34718a75e74a2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ca2fc4eb9c994cc2a2f1dbdab98aa3d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"EVTLnae70XUx"},"source":["# Multiple-Choice Question Answering"]},{"cell_type":"code","metadata":{"id":"o_zHi1zlwyXb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959184954,"user_tz":-270,"elapsed":14,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"27da2c95-7676-414b-8517-e11ab90bc4ea"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sat Aug 14 16:39:44 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               85\n","Model name:          Intel(R) Xeon(R) CPU @ 2.00GHz\n","Stepping:            3\n","CPU MHz:             2000.186\n","BogoMIPS:            4000.37\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            1024K\n","L3 cache:            39424K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4knw0YgC0SfX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959214780,"user_tz":-270,"elapsed":29830,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"c9e81d50-52db-4671-8629-185de6ab58c7"},"source":["!pip install hazm==0.7.0\n","!pip install seqeval==1.2.2\n","!pip install sentencepiece==0.1.96\n","!pip install transformers==4.7.0\n","!pip install clean-text[gpl]==0.4.0\n","!pip install editdistance==0.5.3"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting hazm==0.7.0\n","  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 36.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40 kB 17.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 51 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 61 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 71 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 81 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 92 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 102 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 112 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 122 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 133 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 143 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 153 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 163 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 174 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 184 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 194 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 204 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 215 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 225 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 235 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 245 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 256 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 266 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 276 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 286 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 296 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 307 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 316 kB 9.3 MB/s \n","\u001b[?25hCollecting nltk==3.3\n","  Downloading nltk-3.3.0.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 58.6 MB/s \n","\u001b[?25hCollecting libwapiti>=0.2.1\n","  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n","\u001b[K     |████████████████████████████████| 233 kB 64.2 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm==0.7.0) (1.15.0)\n","Building wheels for collected packages: nltk, libwapiti\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394485 sha256=d7ae812a1f3cd4aa99e7fb81c801f9985aadadc96d5f3df95bed47c3c4f2ae7e\n","  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n","  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154591 sha256=deec26424ee6c3a8360d19d35f3e9ba6b79729946271987d09390e5a0dd0dbb5\n","  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n","Successfully built nltk libwapiti\n","Installing collected packages: nltk, libwapiti, hazm\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n","Collecting seqeval==1.2.2\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2) (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.0.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=4cbe17a9d0efa312d02ae1695c18bfa4ae9a7e6b9c6c87f579b190949b99c9b7\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Collecting sentencepiece==0.1.96\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 6.7 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting transformers==4.7.0\n","  Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 8.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (3.13)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 56.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (21.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (2.23.0)\n","Collecting huggingface-hub==0.0.8\n","  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (3.0.12)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 63.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (1.19.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (4.6.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (4.62.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0) (3.5.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.7.0) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.7.0\n","Collecting clean-text[gpl]==0.4.0\n","  Downloading clean_text-0.4.0-py3-none-any.whl (9.8 kB)\n","Collecting ftfy<7.0,>=6.0\n","  Downloading ftfy-6.0.3.tar.gz (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 3.0 MB/s \n","\u001b[?25hCollecting emoji\n","  Downloading emoji-1.4.2.tar.gz (184 kB)\n","\u001b[K     |████████████████████████████████| 184 kB 15.1 MB/s \n","\u001b[?25hCollecting unidecode<2.0.0,>=1.1.1\n","  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n","\u001b[K     |████████████████████████████████| 241 kB 59.2 MB/s \n","\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy<7.0,>=6.0->clean-text[gpl]==0.4.0) (0.2.5)\n","Building wheels for collected packages: ftfy, emoji\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=88ce1a584018423f1d1e6ed0cf5fa746ac0b416481c534f4826d7e2d80c2abce\n","  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186469 sha256=f77ddc90beaf49224bc03527e10eb4977bb1b5990c29e8d6e89a9a0dd338956d\n","  Stored in directory: /root/.cache/pip/wheels/e4/61/e7/2fc1ac8f306848fc66c6c013ab511f0a39ef4b1825b11363b2\n","Successfully built ftfy emoji\n","Installing collected packages: ftfy, emoji, unidecode, clean-text\n","Successfully installed clean-text-0.4.0 emoji-1.4.2 ftfy-6.0.3 unidecode-1.2.0\n","Requirement already satisfied: editdistance==0.5.3 in /usr/local/lib/python3.7/dist-packages (0.5.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rS4Rw-0iYEtd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959240121,"user_tz":-270,"elapsed":25355,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"1f8a4c87-7cde-47e1-f951-b0afcc8e91df"},"source":["!pip install PyDrive\n","import os\n","import IPython.display as ipd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: PyDrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (1.12.8)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.34.0)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.26.3)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.53.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.23.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (21.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.17.3)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (57.2.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2018.9)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.2.2)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HjQo6WGZ2aK5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959254739,"user_tz":-270,"elapsed":6807,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"7fb1fa6d-4a3a-4e5d-9db2-d78ad77dfe4c"},"source":["# Import required packages\n","import os\n","import gc\n","import re\n","import hazm\n","import time\n","import json\n","import collections\n","import numpy as np\n","import pandas as pd\n","import editdistance\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","import transformers\n","from transformers import AutoConfig, AutoTokenizer\n","from transformers import AutoModelForMultipleChoice\n","from transformers import MT5Config, MT5ForConditionalGeneration, MT5Tokenizer\n","from transformers.data.metrics.squad_metrics import compute_exact, compute_f1\n","\n","from cleantext import clean\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","\n","print()\n","print('numpy', np.__version__)\n","print('pandas', pd.__version__)\n","print('transformers', transformers.__version__)\n","print('torch', torch.__version__)\n","print()\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\n","numpy 1.19.5\n","pandas 1.1.5\n","transformers 4.7.0\n","torch 1.9.0+cu102\n","\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5vC31D-N0Shj","executionInfo":{"status":"ok","timestamp":1628959255865,"user_tz":-270,"elapsed":473,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}}},"source":["class MultipleChoiceQADataset(torch.utils.data.Dataset):\n","    \"\"\" Create a PyTorch dataset for Multiple Choice Question Answering. \"\"\"\n","\n","    def __init__(self, questions, candidates, choices, answers, tokenizer, max_length, model_type):\n","        self.questions = questions\n","        self.candidates = candidates\n","        self.choices = choices\n","        self.answers = answers\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.model_type = model_type\n","\n","    def __len__(self):\n","        return len(self.questions)\n","\n","    def __getitem__(self, item):\n","        if self.model_type == \"mt5\":\n","            input_text = self.questions[item] + ' <sep> ' + ' <sep> '.join(self.candidates[item])\n","            encoding = self.tokenizer(\n","                input_text,\n","                add_special_tokens=True,\n","                max_length=self.max_length,\n","                truncation=True,\n","                padding='max_length',\n","                return_tensors=\"pt\"\n","            )\n","            inputs = {\n","                'item': str(item),\n","                'question': self.questions[item],\n","                'candidates': ' <sep> '.join(self.candidates[item]),\n","                'input_text': input_text,\n","                'choice': self.choices[item],\n","                'answer': self.answers[item],\n","                'input_ids': encoding.input_ids.flatten(),\n","                'attention_mask': encoding.attention_mask.flatten()\n","            }\n","            return inputs\n","        else:\n","            choices_input_ids, choices_attention_masks, choices_token_type_ids = [], [], []\n","            for c in self.candidates[item]:\n","                text_a = \"\"  # empty context\n","                text_b = self.questions[item] + \" \" + c\n","                inputs = self.tokenizer(\n","                    text_a,\n","                    text_b,\n","                    add_special_tokens=True,\n","                    max_length=self.max_length,\n","                    padding=\"max_length\",\n","                    truncation=True,\n","                    return_overflowing_tokens=True\n","                )\n","                choices_input_ids.append(inputs.input_ids[0])\n","                choices_attention_masks.append(inputs.attention_mask[0])\n","                choices_token_type_ids.append(inputs.token_type_ids[0])\n","\n","            inputs = {\n","                'item': str(item),\n","                'question': self.questions[item],\n","                'candidates': ' <sep> '.join(self.candidates[item]),\n","                'choice': int(self.choices[item]) - 1,\n","                'answer': self.answers[item],\n","                'input_ids': torch.LongTensor(choices_input_ids),\n","                'attention_mask': torch.LongTensor(choices_attention_masks),\n","                'token_type_ids': torch.LongTensor(choices_token_type_ids)\n","            }\n","            return inputs\n","\n","\n","class MultipleChoiceQA:\n","    def __init__(self, model_name, model_type):\n","        self.normalizer = hazm.Normalizer()\n","        self.model_name = model_name\n","        if model_type.lower() == \"mt5\":\n","            self.tokenizer = MT5Tokenizer.from_pretrained(model_name)\n","            self.model = MT5ForConditionalGeneration.from_pretrained(model_name)\n","            self.config = MT5Config.from_pretrained(self.model_name)\n","        elif model_type.lower() in [\"mbert\", \"parsbert\", \"wikibert\"]:\n","            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n","            self.config = AutoConfig.from_pretrained(self.model_name)\n","            self.model = AutoModelForMultipleChoice.from_pretrained(self.model_name, config=self.config)\n","            self.model_type = model_type.lower()\n","        else:\n","            print(f'model_type not supported!')\n","            return\n","\n","    def load_dataset_test_file(self, dataset_name, dataset_file, **kwargs):\n","        if dataset_name.lower() in [\"parsinlu\", \"parsinlu-literature\", \"parsinlu-math_and_logic\",\n","                                    \"parsinlu-common_knowledge\"]:\n","            if not os.path.exists(dataset_file):\n","                print(f'{dataset_file} not exists!')\n","                return\n","            questions, candidates, choices, answers = [], [], [], []\n","            with open(dataset_file, encoding=\"utf8\") as infile:\n","                for line in infile:\n","                    json_line = json.loads(line.strip())\n","                    question = json_line['question']\n","                    candidate_answers = json_line['candidates']\n","                    choice = json_line['answer']\n","                    answer = candidate_answers[int(json_line['answer']) - 1]\n","\n","                    questions.append(question)\n","                    candidates.append(candidate_answers)\n","                    choices.append(choice)\n","                    answers.append(answer)\n","            return questions, candidates, choices, answers\n","\n","    def multiple_choice_qa_inference(self, questions, candidates, device, max_length=512):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        input_ids, attention_masks, token_type_ids = [], [], []\n","        for q, cs in zip(questions, candidates):\n","            choices_input_ids, choices_attention_masks, choices_token_type_ids = [], [], []\n","            for c in cs:\n","                text_a = \"\"  # empty context\n","                text_b = q + \" \" + c\n","                inputs = self.tokenizer(\n","                    text_a,\n","                    text_b,\n","                    add_special_tokens=True,\n","                    max_length=max_length,\n","                    padding=\"max_length\",\n","                    truncation=True,\n","                    return_overflowing_tokens=True,\n","                )\n","                choices_input_ids.append(inputs.input_ids[0])\n","                choices_attention_masks.append(inputs.attention_mask[0])\n","                choices_token_type_ids.append(inputs.token_type_ids[0])\n","            input_ids.append(choices_input_ids)\n","            attention_masks.append(choices_attention_masks)\n","            token_type_ids.append(choices_token_type_ids)\n","\n","        input_ids = torch.LongTensor(input_ids).to(device)\n","        attention_masks = torch.LongTensor(attention_masks).to(device)\n","        token_type_ids = torch.LongTensor(token_type_ids).to(device)\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        outputs = self.model(input_ids=input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids)\n","        predictions = torch.argmax(outputs.logits, dim=1)\n","        return [(questions[i], candidates[i], candidates[i][p.item()]) for i, p in enumerate(predictions)]\n","\n","    def mt5_multiple_choice_qa_inference(self, questions, candidates, device):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        new_input = []\n","        for q, cs in zip(questions, candidates):\n","            new_input.append(q + ' <sep> ' + ' <sep> '.join(cs))\n","\n","        tokenized_batch = self.tokenizer(\n","            new_input,\n","            padding=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        input_ids = tokenized_batch.input_ids.to(device)\n","        attention_mask = tokenized_batch.attention_mask.to(device)\n","\n","        outputs = self.model.generate(input_ids=input_ids, attention_mask=attention_mask)\n","        predictions = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","        return [(questions[i], candidates[i], p) for i, p in enumerate(predictions)]\n","\n","    def evaluation(self, questions, candidates, choices, answers, device, max_length, batch_size=4):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","        if len(questions) != len(candidates):\n","            print('length of two inputs is not equal!!')\n","            return\n","        if len(choices) != len(answers):\n","            print('length of choices and answers is not equal!!')\n","            return\n","        if len(questions) != len(answers):\n","            print('length of inputs and answers is not equal!!')\n","            return\n","\n","        dataset = MultipleChoiceQADataset(questions=questions, candidates=candidates, choices=choices, answers=answers,\n","                                          tokenizer=self.tokenizer, max_length=max_length, model_type=self.model_type)\n","        data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n","        print(f'#question:{len(questions)}, #candidates:{len(candidates)}, #answer:{len(answers)}')\n","        print(\"#batch:\", len(data_loader))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        total_loss, total_time = 0, 0\n","        output_predictions = []\n","        golden_choices, predicted_choices = [], []\n","        print(\"Start to evaluate test data ...\")\n","        for step, batch in enumerate(data_loader):\n","            b_input_ids = batch['input_ids']\n","            b_attention_mask = batch['attention_mask']\n","            b_token_type_ids = batch['token_type_ids']\n","            b_choices = batch['choice']\n","\n","            # move tensors to GPU if CUDA is available\n","            b_input_ids = b_input_ids.to(device)\n","            b_attention_mask = b_attention_mask.to(device)\n","            b_token_type_ids = b_token_type_ids.to(device)\n","            b_choices = b_choices.to(device)\n","\n","            # This will return the loss (rather than the model output) because we have provided the `labels`.\n","            with torch.no_grad():\n","                start = time.monotonic()\n","                b_outputs = self.model(input_ids=b_input_ids, attention_mask=b_attention_mask,\n","                                       token_type_ids=b_token_type_ids, labels=b_choices)\n","                end = time.monotonic()\n","                total_time += end - start\n","                print(f'inference time for step {step}: {end - start}')\n","            # get the loss\n","            total_loss += b_outputs.loss.item()\n","\n","            golden_choices.extend(b_choices.cpu().detach().numpy().tolist())\n","            b_predictions = torch.argmax(b_outputs.logits, dim=1)\n","            b_predictions = b_predictions.cpu().detach().numpy().tolist()\n","            predicted_choices.extend(b_predictions)\n","\n","            for i in range(len(b_input_ids)):\n","                output_predictions.append((\n","                    batch['question'][i],\n","                    batch['candidates'][i].split(' <sep> '),\n","                    batch['choice'][i].item(),\n","                    batch['answer'][i],\n","                    b_predictions[i],\n","                    batch['candidates'][i].split(' <sep> ')[b_predictions[i]]\n","                ))\n","\n","        # Calculate the average loss over the training data.\n","        avg_train_loss = total_loss / len(data_loader)\n","        print(\"average loss:\", avg_train_loss)\n","\n","        print(\"total inference time:\", total_time)\n","        print(\"total inference time / #samples:\", total_time / len(questions))\n","\n","        # evaluate\n","        print(\"Test Accuracy: {}\".format(accuracy_score(golden_choices, predicted_choices)))\n","        print(\"Test Precision: {}\".format(precision_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test Recall: {}\".format(recall_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test F1-Score(weighted average): {}\".format(\n","            f1_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test classification Report:\\n{}\".format(\n","            classification_report(golden_choices, predicted_choices, digits=10)))\n","        return output_predictions\n","\n","    def mt5_evaluation(self, questions, candidates, choices, answers, device, max_length, batch_size=4):\n","        if not self.model or not self.tokenizer:\n","            print('Something wrong has been happened!')\n","            return\n","        if len(questions) != len(candidates):\n","            print('length of two inputs is not equal!!')\n","            return\n","        if len(choices) != len(answers):\n","            print('length of choices and answers is not equal!!')\n","            return\n","        if len(questions) != len(answers):\n","            print('length of inputs and answers is not equal!!')\n","            return\n","\n","        dataset = MultipleChoiceQADataset(questions=questions, candidates=candidates, choices=choices, answers=answers,\n","                                          tokenizer=self.tokenizer, max_length=max_length, model_type=\"mt5\")\n","        data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n","        print(f'#question:{len(questions)}, #candidates:{len(candidates)}, #answer:{len(answers)}')\n","        print(\"#batch:\", len(data_loader))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","        self.model.eval()\n","\n","        total_time = 0\n","        output_predictions = []\n","        golden_choices, predicted_choices, exact_score_list, f1_score_list = [], [], [], []\n","        print(\"Start to evaluate test data ...\")\n","        for step, batch in enumerate(data_loader):\n","            b_input_ids = batch['input_ids']\n","            b_attention_mask = batch['attention_mask']\n","\n","            # move tensors to GPU if CUDA is available\n","            b_input_ids = b_input_ids.to(device)\n","            b_attention_mask = b_attention_mask.to(device)\n","\n","            # This will return the loss (rather than the model output) because we have provided the `labels`.\n","            with torch.no_grad():\n","                start = time.monotonic()\n","                b_outputs = self.model.generate(input_ids=b_input_ids, attention_mask=b_attention_mask)\n","                end = time.monotonic()\n","                total_time += end - start\n","                print(f'inference time for step {step}: {end - start}')\n","\n","            b_predictions = self.tokenizer.batch_decode(b_outputs, skip_special_tokens=True)\n","\n","            for i in range(len(b_input_ids)):\n","                if b_predictions[i] in batch['candidates'][i].split(' <sep> '):\n","                    predicted_choice = str(batch['candidates'][i].split(' <sep> ').index(b_predictions[i]) + 1)\n","                else:\n","                    normalized_edit_distance_list = [\n","                        editdistance.distance(ca, b_predictions[i]) / max(len(ca), len(b_predictions[i])) for ca in\n","                        batch['candidates'][i].split(' <sep> ')\n","                    ]\n","                    predicted_choice = str(normalized_edit_distance_list.index(min(normalized_edit_distance_list)) + 1)\n","\n","                golden_choices.append(batch['choice'][i])\n","                predicted_choices.append(predicted_choice)\n","\n","                exact_score_list.append(compute_exact(batch['answer'][i], b_predictions[i]))\n","                f1_score_list.append(compute_f1(batch['answer'][i], b_predictions[i]))\n","\n","                output_predictions.append((\n","                    batch['question'][i],\n","                    batch['candidates'][i].split(' <sep> '),\n","                    batch['choice'][i],\n","                    batch['answer'][i],\n","                    predicted_choice,\n","                    b_predictions[i],\n","                    exact_score_list[-1],\n","                    f1_score_list[-1]\n","                ))\n","\n","        print(\"total inference time:\", total_time)\n","        print(\"total inference time / #samples:\", total_time / len(questions))\n","\n","        # evaluate\n","        print(\"Test Accuracy: {}\".format(accuracy_score(golden_choices, predicted_choices)))\n","        print(\"Test Precision: {}\".format(precision_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test Recall: {}\".format(recall_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test F1-Score(weighted average): {}\".format(\n","            f1_score(golden_choices, predicted_choices, average=\"weighted\")))\n","        print(\"Test classification Report:\\n{}\".format(\n","            classification_report(golden_choices, predicted_choices, digits=10)))\n","\n","        total = len(exact_score_list)\n","        evaluation_results = collections.OrderedDict(\n","            [\n","                (\"exact\", 100.0 * sum(exact_score_list) / total),\n","                (\"f1\", 100.0 * sum(f1_score_list) / total),\n","                (\"total\", total),\n","            ]\n","        )\n","        print(\"evaluation results:\\n\", evaluation_results)\n","\n","        return output_predictions\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"VD0FH_FF2oTy","colab":{"base_uri":"https://localhost:8080/","height":815,"referenced_widgets":["a1b895c6723a4d15bebbe59509ea9dab","aca444741f304acabe4c83f45d2acd2c","dc49e26a0ec348528e32cca4e1171e4f","719e18ff4286401da0da1d3fc3e32ede","d29b028e12584df88bf3b453b0dfdaae","1087a32310fe4691b1a92fd1421411fe","3abff727fdd44e9fbb21d9fc190017ef","60a70ffad39b40b2965d1a180815634e","9b861a29531b4f8a98625e8b67cb3f3f","21f19b323da14f3691ed6e01b302bc30","9941b55554c843739fbb211f2abcc4e8","777627ba95eb45fb9a440f835c47613b","8a000abbf4944570915c6b531909d87e","af5c69836c604e2e9fb64f628ff56d24","9ec063dbe07e4d14a2c45c122ad9bb80","7a8dd56ff3c2437ead2973c33b83686d","44ebbd5586e2474b9876fe397a1a32f3","13dd92a00ee54a26aa793df33ff13d6a","38a192075ec847e9b055ca72d8e25457","652fe48bb7ac402393d9aa158f80f3ad","9c3d01e5855449f485d665dbe5dc2820","a8a1cb3ef2c54752a2acecd11e997a24","44995cce9df7468182febf1b00f5f386","10ec382d3c4f4c2683739ec80108faf5","013aca15956c466790b31309bfdac046","1f354b425cba49e8aa2ea131da97b6aa","13a7947f1d5b440eb6f38ef7495bef05","2f0800f7ccda40e3913ab939f23323df","34a0fad0fda04b719aa8c827179ac146","4a751baf19e24b19b8da494dc0662f6a","452f9df99c4743dfbee31e911e91ba78","f3613eaf96004de4b4af3680ebb0d0d6","122939d169534992aec9cc95eea7d2c6","82038b8f2d674b6e843a043a5e449e67","3b035415d86f42fdad8e6667b2283c26","22f8dc65f7ae49dea3082ecd34e91104","acdb62426a4f4b59a06ea89207ba943c","f78d8655700840e79f65b3e455ffc1a9","2344eba2688e435ba08817e29dca0aaa","a9f15b33a9ac41f6a4157db871415b4e","09b7eb5bd53949c0be43aa572d584335","fc681464f04047e4b8495ae0c2f432d3","f8c92a24adf84acc8a73369aa7e3752b","6a69efd779284f41b3f11355e8e25763","5306a63d57ec4a7aa9956e099f2ae88a","210b5907e8a54e1a9cc486bfc51883d5","e995baf256b74288ae22c8c2a40d76f9","333f39848046420ab89a63da1cfd5b60","cc4ee0d28d4743ccb96f905ebcf00f41","f47b04233d4c418aad8e93ffd404a9cb","2c5f5d2008fd434680b6ace0d16f9f08","d7cfaa32b3f74365943a214bca889d96","6a216faca938431699ea3fa756577e1d","379eb892c17e4240ae34718a75e74a2a","ca2fc4eb9c994cc2a2f1dbdab98aa3d1"]},"executionInfo":{"status":"ok","timestamp":1628959278922,"user_tz":-270,"elapsed":23060,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"bff022f6-1280-4a02-aad4-00eb68779973"},"source":["model_name='persiannlp/parsbert-base-parsinlu-multiple-choice'\n","mcqa_model = MultipleChoiceQA(model_name=model_name, model_type=\"parsbert\")\n","print(mcqa_model.config)"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1b895c6723a4d15bebbe59509ea9dab","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/711 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"777627ba95eb45fb9a440f835c47613b","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.22M [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44995cce9df7468182febf1b00f5f386","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82038b8f2d674b6e843a043a5e449e67","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5306a63d57ec4a7aa9956e099f2ae88a","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/651M [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["BertConfig {\n","  \"_name_or_path\": \"persiannlp/parsbert-base-parsinlu-multiple-choice\",\n","  \"architectures\": [\n","    \"BertForMultipleChoice\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"multiple_choice_all\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.7.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 100000\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_evY3NSRHQFu"},"source":["## Sample Inference"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tzIgo1T-Y-FL","executionInfo":{"status":"ok","timestamp":1628959291624,"user_tz":-270,"elapsed":12715,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"186cefdd-7642-40c8-a3f6-d2b8dabb6a23"},"source":["question_list = [\n","    \"وسیع ترین کشور جهان کدام است؟\",\n","    \"طامع یعنی ؟\",\n","    \"زمینی به ۳۱ قطعه متساوی مفروض شده است و هر روز مساحت آماده شده برای احداث، دو برابر مساحت روز قبل است.اگر پس از (۵ روز) تمام زمین آماده شده باشد، در چه روزی یک قطعه زمین آماده شده\"\n","]\n","candidate_list=[\n","    [\"آمریکا\", \"کانادا\", \"روسیه\", \"چین\"],\n","    [\"آزمند\", \"خوش شانس\", \"محتاج\", \"مطمئن\"],\n","    [\"روز اول\", \"روز دوم\", \"روز سوم\", \"هیچکدام\"]\n","]\n","mcqa_model.multiple_choice_qa_inference(question_list, candidate_list, device)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('وسیع ترین کشور جهان کدام است؟',\n","  ['آمریکا', 'کانادا', 'روسیه', 'چین'],\n","  'آمریکا'),\n"," ('طامع یعنی ؟', ['آزمند', 'خوش شانس', 'محتاج', 'مطمئن'], 'آزمند'),\n"," ('زمینی به ۳۱ قطعه متساوی مفروض شده است و هر روز مساحت آماده شده برای احداث، دو برابر مساحت روز قبل است.اگر پس از (۵ روز) تمام زمین آماده شده باشد، در چه روزی یک قطعه زمین آماده شده',\n","  ['روز اول', 'روز دوم', 'روز سوم', 'هیچکدام'],\n","  'روز اول')]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"XEWiWbu621Tk"},"source":["## Multiple-Choice Dataset\n"]},{"cell_type":"code","metadata":{"id":"pC7QvccoSgPY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959297359,"user_tz":-270,"elapsed":5750,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"ac87721c-2c25-431f-e7ab-e1ce47fcba9d"},"source":["!git clone https://github.com/persiannlp/parsinlu\n","!ls parsinlu\n","!ls parsinlu/data/multiple-choice/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Cloning into 'parsinlu'...\n","remote: Enumerating objects: 1434, done.\u001b[K\n","remote: Counting objects: 100% (182/182), done.\u001b[K\n","remote: Compressing objects: 100% (98/98), done.\u001b[K\n","remote: Total 1434 (delta 110), reused 139 (delta 82), pack-reused 1252\u001b[K\n","Receiving objects: 100% (1434/1434), 27.81 MiB | 18.64 MiB/s, done.\n","Resolving deltas: 100% (913/913), done.\n","data  LICENSE  README.md  requirements.txt  scripts  src\n","test_ck.jsonl  test_lit.jsonl  train.jsonl\n","test.jsonl     test_ml.jsonl   valid.jsonl\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ilPBM7goGNYW"},"source":["### Samples with literature as their category"]},{"cell_type":"code","metadata":{"id":"Ieg7Y37QSgSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959297360,"user_tz":-270,"elapsed":15,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"94f7bc39-f0a2-43a6-a9e1-8c9a1c9910f8"},"source":["test_questions_lit, test_candidates_lit, test_choices_lit, test_answers_lit = mcqa_model.load_dataset_test_file(\n","    dataset_name=\"parsinlu-literature\", dataset_file=\"./parsinlu/data/multiple-choice/test_lit.jsonl\")\n","print(test_questions_lit[0])\n","print(test_candidates_lit[0])\n","print(test_choices_lit[0])\n","print(test_answers_lit[0])\n","print(len(test_questions_lit))\n","print(len(test_candidates_lit))\n","print(len(test_choices_lit))\n","print(len(test_answers_lit))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["رابطه‌ی شیر با جنگل مثل رابطه‌ی\n","['سرباز است با پادگان', 'اتوبوس است با ایستگاه', 'هواپیما است با آسمان', 'کشتی است با بندر']\n","3\n","هواپیما است با آسمان\n","350\n","350\n","350\n","350\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZEKAoe8eGSBH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959297985,"user_tz":-270,"elapsed":636,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"832bce3b-7cfe-46e5-8246-83962328101d"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Sat Aug 14 16:41:37 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P0    26W /  70W |   8718MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               85\n","Model name:          Intel(R) Xeon(R) CPU @ 2.00GHz\n","Stepping:            3\n","CPU MHz:             2000.186\n","BogoMIPS:            4000.37\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            1024K\n","L3 cache:            39424K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"riVxSRbv138W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959345691,"user_tz":-270,"elapsed":47713,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"943f8bb9-876e-46e4-b8da-a48dc71d8bd1"},"source":["evaluation_output = mcqa_model.evaluation(test_questions_lit, test_candidates_lit, test_choices_lit, test_answers_lit, device, max_length=mcqa_model.config.max_position_embeddings, batch_size=64)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["#question:350, #candidates:350, #answer:350\n","#batch: 6\n","Start to evaluate test data ...\n","inference time for step 0: 0.03904973800001699\n","inference time for step 1: 0.00835990299998457\n","inference time for step 2: 0.008402467999985674\n","inference time for step 3: 0.00836894899998697\n","inference time for step 4: 0.00951824199995599\n","inference time for step 5: 0.009337450999964858\n","average loss: 1.3862948218981426\n","total inference time: 0.08303675099989505\n","total inference time / #samples: 0.00023724785999970014\n","Test Accuracy: 0.2057142857142857\n","Test Precision: 0.20554015748031498\n","Test Recall: 0.2057142857142857\n","Test F1-Score(weighted average): 0.15225913632672686\n","Test classification Report:\n","              precision    recall  f1-score   support\n","\n","           0  0.2007874016 0.6800000000 0.3100303951        75\n","           1  0.2549019608 0.1274509804 0.1699346405       102\n","           2  0.1600000000 0.0430107527 0.0677966102        93\n","           3  0.2000000000 0.0500000000 0.0800000000        80\n","\n","    accuracy                      0.2057142857       350\n","   macro avg  0.2039223406 0.2251154333 0.1569404115       350\n","weighted avg  0.2055401575 0.2057142857 0.1522591363       350\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9qlyRQVDe7m8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959345692,"user_tz":-270,"elapsed":16,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"48988465-0b74-42a5-bfaa-40100cc497da"},"source":["for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer in evaluation_output[:25]:\n","  print('{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["رابطه‌ی شیر با جنگل مثل رابطه‌ی\t['سرباز است با پادگان', 'اتوبوس است با ایستگاه', 'هواپیما است با آسمان', 'کشتی است با بندر']\t2\tهواپیما است با آسمان\t0\tسرباز است با پادگان\n","رابطه ي بخار با یخ مثل رابطه ي:\t['خمیر است با نان', 'گندم است با آرد', 'غوره است با کشمش', 'باران است با برف']\t2\tغوره است با کشمش\t0\tخمیر است با نان\n","در عبارت زیر، به‌ترتیب « مضاف‌الیه مضاف‌الیه، صفت مضاف‌الیه و متمم اسم» کدام است؟\r\n","«مطالعه تفاسیر قرآن، روح اشعار حافظ شیراز را جلایی خاص بخشیده و از غزلیات این شاعر بی‌بدیل می‌توان به مهارت\r\n","خاص او در کشف رموز عرفانی پی برد.»\r\t['قرآن، این، کشف', 'حافظ، عرفانی، غزلیات', 'شیراز، این شاعر، مهارت', 'رموز، بی\\u200cبدیل، کشف رموز عرفانی']\t0\tقرآن، این، کشف\t0\tقرآن، این، کشف\n","مشهورترین شاعر رمانتیک قرن نوزدهم فرانسه چه کسی است؟\t['ولتر', 'ویکتورهوگو', 'لافونتن', 'ژان ژاک  روسو']\t1\tویکتورهوگو\t0\tولتر\n","مفرد كدام كلمه صحيح است\t['الوان : لون', 'حواس : احساس', 'اعضا: عضوها', 'الف وب']\t2\tاعضا: عضوها\t0\tالوان : لون\n","کدام عبارت، نادرست است؟\t['شاعر منظومه\\u200cهای حماسی مصنوع، با داستان\\u200cهای پهلوانی مدوّن و معینی سر و کار دارد.', 'قهرمانان حماسه، با نام رقّتی که از نظر عاطفی و احساسی در ان\\u200cها وجود دارد، فهرمانان ملّی هستند.', 'در حماسه مجموعه ای از وصف\\u200cها، خطبه\\u200cها و تصویرها وجود دارد امّا همه\\u200cی این عناصر نسبت به «داستانی بودن» در مرتبه ی دوم هستند.', 'در هر حماسه\\u200cای، رویدادهای غیرطبیعی و بیرون از نظام عادت دیده می\\u200cشود که تنها از رهگذر عقاید دینی عصر خود، توجیه\\u200cپذیر هستند.\\n']\t0\tشاعر منظومه‌های حماسی مصنوع، با داستان‌های پهلوانی مدوّن و معینی سر و کار دارد.\t0\tشاعر منظومه‌های حماسی مصنوع، با داستان‌های پهلوانی مدوّن و معینی سر و کار دارد.\n","متضاد کلمات مورد سؤال چیست؟ منصوب \t['مطرود', 'معزول', 'مغضوب', 'معذور']\t1\tمعزول\t3\tمعذور\n","متضاد کلمات مورد سؤال چیست؟ شیفته\t['نومید', 'دلسرد', 'بی قرار', 'بیزار']\t3\tبیزار\t0\tنومید\n","کدام واژه زیر با سه واژه دیگر تفاوت بسیار دارد؟\t['سیمبر', 'عنبر', 'دلبر', 'بریر']\t0\tسیمبر\t1\tعنبر\n","کدام کلمه مفرد می باشد؟\t['بیگانگان', 'آفات', 'الوان', 'عضو']\t3\tعضو\t0\tبیگانگان\n","تعداد باب‌های «گلستان» چند است؟\t[' ده', 'هشت', 'نه', 'هفت']\t1\tهشت\t2\tنه\n","به غلط تصور کرده بود که با .............. خطاها می‌تواند از عواقب آنها مصون بماند\t['اصلاح', 'تشخیص', 'نادیده گرفتن', 'جلوگیری از']\t2\tنادیده گرفتن\t0\tاصلاح\n","کدام کلمه با سه کلمه دیگر هیچگونه مناسبتی ندارد؟\t['قنددان', 'خندان', 'گلدان', 'نمکدان']\t1\tخندان\t0\tقنددان\n","آنچه که از ارزش واقعی چیزی بکاهد :؟\t['انتقاد', 'شایعه', 'فراوانی', 'نقص']\t3\tنقص\t0\tانتقاد\n","معنی واژه‌های «مضغ، لابه، عقار، لطیفه» به‌ترتیب کدام است؟\t['بلعیدن- تضرع- زمین زراعی- نکته\\u200cی باریک', 'جویدن- تضرع- آب و زمین- گفتار نغز', 'فرو بردن- عجز و ناتوانی- آب و زمین- ظریف و باریک', 'آسیا کردن غذا در زیر دندان- التماس- کشت\\u200cزار- نغز و شیرین']\t1\tجویدن- تضرع- آب و زمین- گفتار نغز\t3\tآسیا کردن غذا در زیر دندان- التماس- کشت‌زار- نغز و شیرین\n","کدام گزینه ازموضوعات شعری عصررودکی نیست؟\t['وصف', 'عرفان', 'مدح', 'اندرز']\t1\tعرفان\t0\tوصف\n","مفهوم کلی عبارات زیر در کدام بیت مشهود است؟«به نام آن خدای که نام او راحت روح است و پیغام او مفتاح فتوح است. ذکر او مرهم دل مجروح است و مهر او بلانشینان را کشتی نوح است».\t['کاروانی که بود بدرقه\\u200cاش حفظ خدا    به تجمل بنشیند به جلالت برود', 'موج از این بار چنان کشتی طاقت بشکست    که عجب دارم اگر تخته به ساحل برود', 'زخم شمشیر غمت را به شکیبایی و عقل    چند مرهم بنهادیم و اثر می\\u200cنرود', 'سیاه نامه\\u200cتر از خود کسی نمی\\u200cبینم    چگونه چون قلمم، دود دل، به سر نرود']\t0\tکاروانی که بود بدرقه‌اش حفظ خدا    به تجمل بنشیند به جلالت برود\t0\tکاروانی که بود بدرقه‌اش حفظ خدا    به تجمل بنشیند به جلالت برود\n","کدام کتاب قصه است که «جنبه‌های واقعی و تاریخی و اخلاقی آن به هم آمیخته است؟»\t['عقل سرخ', 'آواز پر جبرئیل', 'مقامات حمیدی', 'تذکره\\u200cالاولیا']\t2\tمقامات حمیدی\t0\tعقل سرخ\n","رابطه نقاش با تصویر مثل رابطه :\t['معلم با دانش آموز', 'مولف با کتاب', 'باغبان با گل ', 'رئیس با کارمند']\t1\tمولف با کتاب\t0\tمعلم با دانش آموز\n","کدام گزینه از آثارناصرخسرو نیست؟\t['زادالعارفین', 'خوان واخوان', 'جام \\xadالحکمتین', 'سفرنام']\t0\tزادالعارفین\t3\tسفرنام\n","كدام گزينه اسم وصفت نيست؟\t['پروردگار بي همتا', 'چاپلوسان ثنا گو', 'وزيران لايق', 'منادي آزادي']\t3\tمنادي آزادي\t0\tپروردگار بي همتا\n","معنی کدام گروه از واژه‌ها «همگی» درست است؟\t['(بارقه: اسب تندرو)، (درره: بسته)', '(نسق: روش)، (صائب: درست)', '(اساطیر: خدایان)، (آبزن: برکه آب)', '(آژنگ: چین و شکن مو)، (اعصار: دوران)']\t1\t(نسق: روش)، (صائب: درست)\t2\t(اساطیر: خدایان)، (آبزن: برکه آب)\n","در باره ي جمله ي از هفت خوان رستم گذشته است . كدام مورد زير درست است\t['كنايه', 'مبالغه', 'تشبيه', 'ضرب المثل']\t0\tكنايه\t0\tكنايه\n","طامع یعنی ؟\t['آزمند', 'خوش شانس', 'محتاج', 'مطمئن']\t0\tآزمند\t0\tآزمند\n","متضاد کلمات مورد سؤال چیست؟ قریب\t['مأنوس', 'آشنا', 'عجیب', 'دور']\t3\tدور\t1\tآشنا\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cgSPjuTYe71x","executionInfo":{"status":"ok","timestamp":1628959346898,"user_tz":-270,"elapsed":1218,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}}},"source":["output_file_name = \"multiple_choice_qa_literature_testset_{}_outputs.txt\".format(model_name.replace('/','-'))\n","with open(output_file_name, \"w\", encoding='utf8') as output_file:\n","  for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer in evaluation_output:\n","    output_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer))\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","upload = drive.CreateFile({'title': output_file_name})\n","upload.SetContentFile(output_file_name)\n","upload.Upload()"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AAcLHWgKGSHv"},"source":["### Samples with math_and_logic as their category"]},{"cell_type":"code","metadata":{"id":"bDozlPsr2Bp3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959346899,"user_tz":-270,"elapsed":13,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"8024d5f4-a7bf-4b6f-f27e-9562bbf11409"},"source":["test_questions_ml, test_candidates_ml, test_choices_ml, test_answers_ml = mcqa_model.load_dataset_test_file(\n","    dataset_name=\"parsinlu-math_and_logic\", dataset_file=\"./parsinlu/data/multiple-choice/test_ml.jsonl\")\n","print(test_questions_ml[0])\n","print(test_candidates_ml[0])\n","print(test_choices_ml[0])\n","print(test_answers_ml[0])\n","print(len(test_questions_ml))\n","print(len(test_candidates_ml))\n","print(len(test_choices_ml))\n","print(len(test_answers_ml))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["تفاوت سن علیرضا و خواهرش A سال است B سال دیگر سن علیرضا دوبرابر سن امروز خواهرش خواهد بود .سن خواهر علیرضا کدام است؟\n","['2A', '2A+B', '3A+B', 'A-B']\n","2\n","2A+B\n","350\n","350\n","350\n","350\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uIbQCKZ1Igho","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959347512,"user_tz":-270,"elapsed":624,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"fb4ca70a-5e38-4022-b1eb-6c0be1daeb3b"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Sat Aug 14 16:42:26 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   60C    P0    37W /  70W |  10590MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               85\n","Model name:          Intel(R) Xeon(R) CPU @ 2.00GHz\n","Stepping:            3\n","CPU MHz:             2000.186\n","BogoMIPS:            4000.37\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            1024K\n","L3 cache:            39424K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V0yABKemCZnv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959397090,"user_tz":-270,"elapsed":49585,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"4a824071-79a1-4dec-bfc3-fc61cb788fbf"},"source":["evaluation_output = mcqa_model.evaluation(test_questions_ml, test_candidates_ml, test_choices_ml, test_answers_ml, device, max_length=mcqa_model.config.max_position_embeddings, batch_size=64)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["#question:350, #candidates:350, #answer:350\n","#batch: 6\n","Start to evaluate test data ...\n","inference time for step 0: 0.2605414600000131\n","inference time for step 1: 0.008791447000021435\n","inference time for step 2: 0.008380685000020094\n","inference time for step 3: 0.008515162000037435\n","inference time for step 4: 0.008263057000021945\n","inference time for step 5: 0.009169076999967274\n","average loss: 1.3862948417663574\n","total inference time: 0.3036608880000813\n","total inference time / #samples: 0.0008676025371430894\n","Test Accuracy: 0.32285714285714284\n","Test Precision: 0.29744991789819375\n","Test Recall: 0.32285714285714284\n","Test F1-Score(weighted average): 0.23933322003653437\n","Test classification Report:\n","              precision    recall  f1-score   support\n","\n","           0  0.3333333333 0.8050847458 0.4714640199       118\n","           1  0.3103448276 0.0909090909 0.1406250000        99\n","           2  0.3000000000 0.0740740741 0.1188118812        81\n","           3  0.1875000000 0.0576923077 0.0882352941        52\n","\n","    accuracy                      0.3228571429       350\n","   macro avg  0.2827945402 0.2569400546 0.2047840488       350\n","weighted avg  0.2974499179 0.3228571429 0.2393332200       350\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O8Dgqmc1GAtz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959397091,"user_tz":-270,"elapsed":29,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"7c13cd00-ce41-4fcb-e64a-5caf8f2f6246"},"source":["for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer in evaluation_output[:25]:\n","  print('{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["تفاوت سن علیرضا و خواهرش A سال است B سال دیگر سن علیرضا دوبرابر سن امروز خواهرش خواهد بود .سن خواهر علیرضا کدام است؟\t['2A', '2A+B', '3A+B', 'A-B']\t1\t2A+B\t0\t2A\n","در ادامه این رشته چه عددی باید نوشت؟ ۹۱،۸۶،۷۶،۶۱،...\t['۴۶', '۴۱', '۵۱', '۳۶']\t1\t۴۱\t0\t۴۶\n","50 تا 20 تا برابر است با ......\t['10000', '100', '1000', '500']\t2\t1000\t0\t10000\n","در ادامه این رشته چه عددی باید نوشت؟             3, 5, 5, 9, 7, 13, 9, …\t['17', '11', '14', '15']\t0\t17\t0\t17\n","مساحت مربع ۸ ،p برابر مساحت مربع Q است. نسبت قطر مربع p به ضلع مربع Q کدامست؟\t['۴', '۲', '۳', '۱']\t0\t۴\t1\t۲\n","%50 عدد 24 برابر است با ....\t['4', '6', '10', '12']\t3\t12\t0\t4\n","کدام عدد نزدیکتر۷ به است؟\t['۴', '۶', '۹', '۱۱']\t1\t۶\t2\t۹\n","چند درصد ۵۰۰ برابر ۵۰ می‌شود؟\t['۱', '۱۰', '۲۰', '۳۰']\t1\t۱۰\t0\t۱\n","قیمت یک کالا %۲۵ تخفیف داده شده است برای آنکه این کالا به قیمت قبل از تخفیف فروخته شود چند درصد باید به قیمت آن افزوده گردد؟\t['۲۵', '۲۰', '۳۳.۳۳', 'هیچکدام']\t2\t۳۳.۳۳\t0\t۲۵\n","حاصل عبارت ۵ - ۳ برابر است با ؟\t['-2', '2', '1', '-1']\t0\t-2\t1\t2\n","حاصل عبارت ۴۴ + ۲۳ برابر است با ؟\t['68', '65', '57', '67']\t3\t67\t0\t68\n","سرمایه دو شریک به نسبت او ۱ می‌باشد سود نفر دوم در یک معامله ۹۰۰ تومان است کل مبلغ سود\r\n","چند تومان است. کل مبلغ سود چند تومان می‌شود؟\r\t['۷۲۰', '۳۶۰۰', '۱۶۲۰', '۴۵۰۰']\t2\t۱۶۲۰\t0\t۷۲۰\n","۵۴۰۰ لیتر بنزین برای مصرف ۹ اتومبیل یک شرکت راهسازی در مدت ۲۰ روز مأموریت داده شده است. با\n","افزوده شدن ۳ اتومبیل دیگر ۲ روز از مدت مأموریت کم می‌شود در صورتی که مقدار بنزین دریافتی تغییر\n","نکند. سهمیه بنزین روزانه هر اتومبیل:\n","\t['زیاد شده است', 'کم شده است', 'تغییر نکرده است', 'قابل تعیین نیست']\t1\tکم شده است\t0\tزیاد شده است\n","نسبت اسید دریک ماده شیمیایی %۳ است، ۶۰ لیتر از این ماده را با چند لیتر ماده بدون اسید باید مخلوط کرد تا نسبت اسید مخلوط %۱ شود؟\t['۸۰', '۱۰۰', '۱۲۰', '۱۵۰']\t2\t۱۲۰\t0\t۸۰\n","اگر یک سوم چوبی در زمین و یک دوم « در آب و قسمت بالائی‌آن که بیرون از آب قرار دارد ۱/۵ متر باشد،طول چوب چقدر است؟\t['4.5', '6', '9', '10.5']\t2\t9\t0\t4.5\n","کدامیک ازاعداد زیرازعدد 43 کوچکتراست؟\t['45', '54', '49', '34']\t3\t34\t0\t45\n"," ﻜﺪاﻡ عبارت صحیح نیست ؟\t['اﺯﺪو نقطه فقط یک خط راست می ﮔﺬارﺪ.', 'اﮔﺮخطی بر خط ﺪﻴﮔﺮعموﺪباﺷﺪبر خطوط مواﺯی آن ﻨﻳﺯعموﺪاست.', 'هر خط عموﺪبر خط ﺪﻴﮔﺮعموﺪمنصف آن خط است.', 'هر قطر لوﺯی عموﺪمنصف قطر ﺪﻴﮔﺮاست.']\t2\tهر خط عموﺪبر خط ﺪﻴﮔﺮعموﺪمنصف آن خط است.\t2\tهر خط عموﺪبر خط ﺪﻴﮔﺮعموﺪمنصف آن خط است.\n","حاصل 10*9*8  با فاکتوریل کدام عدد طبیعی است؟\t['۶', '۷', '۸', '۹']\t0\t۶\t0\t۶\n","شعاع دایره ای یک دهم افزایش یافته است. مساحت مربع محاطی آن چند درصد افزایش می‌یابد؟\t['۷۹', '۲۱', '۱۹', '۸۱']\t1\t۲۱\t0\t۷۹\n","پدری نصف دارائی خود را بین ۳ فرزندش تقسیم کرده چه کسری از کل دارائی پدر به هر پسر می رسد؟\t['یک ششم', 'یک پنجم', 'یک چهارم', 'یک سوم']\t0\tیک ششم\t0\tیک ششم\n","شخصی جنسی را به ۲۰۰۰ ریال خریده بود به ۲۴۰۰ ریال فروخت. حال اگر جنسی را به ۶۰۰۰ ریال بفروشد به چند ریال خریده بود؟\t['۵۴۰۰', '۵۲۰۰', '۵۰۰۰', '۲۸۰۰']\t2\t۵۰۰۰\t0\t۵۴۰۰\n","یک مخزن بنزین، دو مجرا دارد، اولی مخزن را در ۶ ساعت و هر دو مجرا با هم آن را در ۴ ساعت خالی\n","می‌کنند، در صورتی که مخزن خالی و فقط مجرای دوم باز باشد مخزن در چند ساعت خالی می‌شود؟\n","\t['۱۲ ساعت', '۸ ساعت', '۴ ساعت', '۳ ساعت']\t1\t۸ ساعت\t0\t۱۲ ساعت\n"," برای انجام عمل تقسیم به ﺪوﻋﺪﺪ نیاﺯﻤﻧﺪﻴﻡ که  عبارﺗﻧﺪﺍﺯ:۟۟۟۟۟۰۰۰۰۰۰۰۰ ۟۟۟۟۟۰۰۰۰۰۰۰۰\t['مقسوم علیه وخارج قسمت', 'مقسوم ومقسوم علیه', 'مقسوم وباقی ماﻧﺪﻩ', 'خارج قسمت و باقی ماﻧﺪﻩ']\t1\tمقسوم ومقسوم علیه\t0\tمقسوم علیه وخارج قسمت\n","موتورسواری با سرعت متوسط ۶۰ کیلومتر در ساعت فاصله بین دو شهر را طی می‌کند و همین فاصله را با سرعت متوسط ۴۰ کیلومتر در ساعت برمی گردد.\r\n","سرعت متوسط او برای تمام مسیر رفت و برگشت عبارت است از\r\t['۵۳ کیلومتر در ساعت', '۵ کیلومتر در ساعت', '۴۸ کیلومتر در ساعت', '۵۲ کیلومتر در ساعت']\t2\t۴۸ کیلومتر در ساعت\t0\t۵۳ کیلومتر در ساعت\n","به یک نوع کالا نسبت به هشتاد درصد قیمت آن صد و بیست درصد سود بازرگانی تعلـق مـیگیـرد. افـزایش\n","قیمت با محاسبۀ سود بازرگانی چند درصد است؟ \t['۹۶', '۷۶', '۱۹۶', '۱۷۶']\t0\t۹۶\t3\t۱۷۶\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"afCYGzT6ImPn","executionInfo":{"status":"ok","timestamp":1628959398087,"user_tz":-270,"elapsed":1016,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}}},"source":["output_file_name = \"multiple_choice_qa_math_and_logic_testset_{}_outputs.txt\".format(model_name.replace('/','-'))\n","with open(output_file_name, \"w\", encoding='utf8') as output_file:\n","  for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer in evaluation_output:\n","    output_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer))\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","upload = drive.CreateFile({'title': output_file_name})\n","upload.SetContentFile(output_file_name)\n","upload.Upload()"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nkj_IXan2xiP"},"source":["### Samples with common_knowledge as their category"]},{"cell_type":"code","metadata":{"id":"mLsuGEuQIgkO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959398088,"user_tz":-270,"elapsed":7,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"18946389-8a0f-4c96-baff-0c06ee394aa8"},"source":["test_questions_ck, test_candidates_ck, test_choices_ck, test_answers_ck = mcqa_model.load_dataset_test_file(\n","    dataset_name=\"parsinlu-common_knowledge\", dataset_file=\"./parsinlu/data/multiple-choice/test_ck.jsonl\")\n","print(test_questions_ck[0])\n","print(test_candidates_ck[0])\n","print(test_choices_ck[0])\n","print(test_answers_ck[0])\n","print(len(test_questions_ck))\n","print(len(test_candidates_ck))\n","print(len(test_choices_ck))\n","print(len(test_answers_ck))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["کدام کشور اولین تولید کننده خرما در جهان است؟\n","['ایران', 'عربستان', 'عراق', 'سوریه']\n","1\n","ایران\n","350\n","350\n","350\n","350\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4L8td12qDZCP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959398723,"user_tz":-270,"elapsed":638,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"7406e98c-6344-4dbd-f71e-2841ac335c8d"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Sat Aug 14 16:43:17 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   67C    P0    35W /  70W |  10590MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               85\n","Model name:          Intel(R) Xeon(R) CPU @ 2.00GHz\n","Stepping:            3\n","CPU MHz:             2000.186\n","BogoMIPS:            4000.37\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            1024K\n","L3 cache:            39424K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5LjF9gcR2uXK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959449899,"user_tz":-270,"elapsed":51186,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"9eea91c2-f7c6-4939-d9c5-3179a11bb7a5"},"source":["evaluation_output = mcqa_model.evaluation(test_questions_ck, test_candidates_ck, test_choices_ck, test_answers_ck, device, max_length=mcqa_model.config.max_position_embeddings, batch_size=64)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["#question:350, #candidates:350, #answer:350\n","#batch: 6\n","Start to evaluate test data ...\n","inference time for step 0: 0.26734842100000833\n","inference time for step 1: 0.011430007000001297\n","inference time for step 2: 0.008626352000021598\n","inference time for step 3: 0.00863539699997773\n","inference time for step 4: 0.008734450999952514\n","inference time for step 5: 0.008293420999962109\n","average loss: 1.3862948417663574\n","total inference time: 0.3130680489999236\n","total inference time / #samples: 0.0008944801399997816\n","Test Accuracy: 0.26857142857142857\n","Test Precision: 0.252966130893114\n","Test Recall: 0.26857142857142857\n","Test F1-Score(weighted average): 0.2074875359070669\n","Test classification Report:\n","              precision    recall  f1-score   support\n","\n","           0  0.2633587786 0.7040816327 0.3833333333        98\n","           1  0.3260869565 0.1704545455 0.2238805970        88\n","           2  0.3000000000 0.0957446809 0.1451612903        94\n","           3  0.0833333333 0.0142857143 0.0243902439        70\n","\n","    accuracy                      0.2685714286       350\n","   macro avg  0.2431947671 0.2461416433 0.1941913661       350\n","weighted avg  0.2529661309 0.2685714286 0.2074875359       350\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"huGRjXMT3Pay","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959449899,"user_tz":-270,"elapsed":8,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"4d6794ab-5257-4b44-885d-ff8c4e896b45"},"source":["for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer in evaluation_output[:25]:\n","  print('{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["کدام کشور اولین تولید کننده خرما در جهان است؟\t['ایران', 'عربستان', 'عراق', 'سوریه']\t0\tایران\t0\tایران\n","مقام رهبری در قانون اساسی جمهوری اسلامی دارای چه کار ویژه ای است؟\t['ریاست کشور', 'نظارت عالیه', 'تنظیم کننده قوای سه گانه', 'حاکمیت مطلق']\t2\tتنظیم کننده قوای سه گانه\t0\tریاست کشور\n","الماس سخت تر است یا گرانیت؟\t['الماس', 'گرانیت', '', '']\t0\tالماس\t0\tالماس\n","طبق قانون اساسی شورای نگهبان طی چند روز از تاریخ وصول باید نظر خود را نسبت به مصوبات مجلس\r\n","اعلام نماید؟\r\t['یک ماه', 'ده روز', 'دو هفته', 'تا حصول اطمینان']\t1\tده روز\t0\tیک ماه\n","در کشور ایران بیشترین نرخ بیکاری متعلق به کدام یک از گزینه های زیر میباشد؟\t['دارندگان مدرک تحصیلی تکمیلی', 'افراد زیر دیپلم', 'افراد بالای 50 سال', 'فارغ التحصیلان دانشگاهها']\t0\tدارندگان مدرک تحصیلی تکمیلی\t0\tدارندگان مدرک تحصیلی تکمیلی\n","ریاست اولین دوره مجلس شورای اسلامی بر عهده چه کسی بود؟\t['آیت الله بهشتی', 'آیت الله کروبی', 'آیت الله رفسنجانی', 'آیت الله ناطق نوری']\t3\tآیت الله ناطق نوری\t0\tآیت الله بهشتی\n","سوره بیست و هفتم قرآن کریم کدامست؟\t['سوره اسراء', 'سوره توبه', 'سوره واقعه', 'سوره نحل']\t2\tسوره واقعه\t0\tسوره اسراء\n","در ترمز ضد قفل برای ترمز گیری باید پا رابه صورت ……………..روی پدال ترمزفشرد.\t['ممتد', 'منقطع', 'آهسته', 'محکم']\t0\tممتد\t0\tممتد\n","«تفسیر سور آبادی» تألیف کدام شخص است؟\t['ابوبکر عتیق نیشابوری', 'علامه مجلسی', 'علامه طباطبائی', 'شیخ طوسی']\t0\tابوبکر عتیق نیشابوری\t0\tابوبکر عتیق نیشابوری\n","حضرت علی “ع” در کدام جنگ در مقابل خوارج ایستاد؟\t['نهروان', 'صفین', 'جمل', 'خیبر']\t0\tنهروان\t0\tنهروان\n","مصوبات مجمع تشخیص مصلحت نظام باید به تأیید ......... برسد.\t['مجلس خبرگان', 'رئیس جمهور', 'شورای نگهبان', 'مقام رهبری']\t3\tمقام رهبری\t0\tمجلس خبرگان\n","کدام مورد معادل مناسب تری برای واژه “کارنگ” است؟\t['سیاست مدار', 'چرب زبان', 'کارشناس', 'آرامش دهنده']\t1\tچرب زبان\t0\tسیاست مدار\n","تصویب عهدنامه‌ها، مقاوله‌نامه‌ها، قراردادها و موافقت‌نامه‌های بین‌المللی برعهده کدام مرجع می‌باشد؟\t['مجلس شورای اسلامی', 'هیأت دولت', 'وزارت امور خارجه', 'مجمع تشخیص مصلحت نظام']\t0\tمجلس شورای اسلامی\t0\tمجلس شورای اسلامی\n","چرا نجوم از مهم ترين دانش هايي بود كه مردم ميان دو رود در آن پيشرفت چشمگيري كردند؟\t['وجود دادو ستد و امور بازرگاني', 'رواج خرافات', 'پرستش ستارگان و تاثير آنها در سرنوشت انسان', 'اعتقاد به ارواحي كه در بدن نفوذ مي كردند.']\t2\tپرستش ستارگان و تاثير آنها در سرنوشت انسان\t2\tپرستش ستارگان و تاثير آنها در سرنوشت انسان\n","پنج کشوری که در سازمان ملل متحد دارای حق« وتو » می باشند، کدامند؟\t['چین ، فرانسه، انگلیس ، آمریکا ، شوروی', 'آمریکا، انگلیس، آلمان، سوئیس، شوروی', 'آمریکا، شوروی، فرانسه، آلمان، چین', 'چین ، فرانسه ، ایتالیا ، آمریکا ، انگلیس']\t0\tچین ، فرانسه، انگلیس ، آمریکا ، شوروی\t0\tچین ، فرانسه، انگلیس ، آمریکا ، شوروی\n","وسیع ترین کشور جهان کدام است؟\t['آمریکا', 'کانادا', 'روسیه', 'چین']\t2\tروسیه\t1\tکانادا\n","مشهورترین ملاك برای طبقه بندی حز ب های سیاسی کدامند؟\t['ملاك فرهنگی', 'ملاك اجتماعی', 'ملاك جهان بینی', 'ملاك ایدئولوژی']\t3\tملاك ایدئولوژی\t0\tملاك فرهنگی\n","مراجعه به افکار عمومی توسط کدام مرجع زیر صورت می‌گیرد؟\t['مجلس شورای اسلامی', 'شورای نگهبان', 'مجمع تشخیص مصلحت نظام', 'مجلس خبرگان رهبری']\t1\tشورای نگهبان\t1\tشورای نگهبان\n","IT مخفف چیست ؟\t['Information Technical', 'Information Types', 'Information Training', 'Information Technology']\t3\tInformation Technology\t0\tInformation Technical\n","« بیمه » قراردادی است که ، اعتبار آن ......................\t['مادام العمر، به شرط دادن حق بیمه است.', 'مادام العمر است.', 'چند سال معین ، از چهل سالگی به بعد است.', 'چند سال معین تا زمانی است که حق بیمه منقضی می شود.']\t3\tچند سال معین تا زمانی است که حق بیمه منقضی می شود.\t0\tمادام العمر، به شرط دادن حق بیمه است.\n","دعوت نهانی پیامبر (ص) به اسلام چند سال به طول انجامید؟\t['۷ سال', '۳ سال', '۲۳ سال', '۶ سال']\t1\t۳ سال\t0\t۷ سال\n","ماد و لودیه با وساطت چه حکومتی صلح کردند؟\t['مصر', 'بابل', 'آتن', 'اسپارت']\t1\tبابل\t2\tآتن\n","»Talweg» تالوگ چیست؟\t['خطی که از میان عمیقترین نقطه بستر رودخانه بین المللی عبور و مرز را مشخص می کند.', 'خطی که رودخانه بین المللی را به دو بخش تقسیم و مرز را تعیین می کند.', 'خطی فرضی که بستر رودخانه را به دو نیم تقسیم و مرز را معین می کند.', 'خطی فرضی که مرز رودخانه بین المللی را مشخص می کند.']\t0\tخطی که از میان عمیقترین نقطه بستر رودخانه بین المللی عبور و مرز را مشخص می کند.\t2\tخطی فرضی که بستر رودخانه را به دو نیم تقسیم و مرز را معین می کند.\n","تعداد فقهای شورای نگهبان چند نفر است؟\t['۶', '۱۲', '۵', '۹']\t0\t۶\t0\t۶\n","سطح روغن موتور هر چند وقت یکبار باید بررسی گردد ؟\t['هر روز', 'یک بار در ماه', 'هر دو هزار کیلومتر کارکرد', 'هفته ای یکبار']\t3\tهفته ای یکبار\t0\tهر روز\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1mO_rEyM3Pd_","executionInfo":{"status":"ok","timestamp":1628959451048,"user_tz":-270,"elapsed":1152,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}}},"source":["output_file_name = \"multiple_choice_qa_common_knowledge_testset_{}_outputs.txt\".format(model_name.replace('/','-'))\n","with open(output_file_name, \"w\", encoding='utf8') as output_file:\n","  for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer in evaluation_output:\n","    output_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer))\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","upload = drive.CreateFile({'title': output_file_name})\n","upload.SetContentFile(output_file_name)\n","upload.Upload()"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9th_LvQz9HWH"},"source":["### All Samples"]},{"cell_type":"code","metadata":{"id":"OZqiKAMW2uUE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959451048,"user_tz":-270,"elapsed":7,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"62df36f8-16f5-4b8f-bbc3-065695268b07"},"source":["test_questions_all, test_candidates_all, test_choices_all, test_answers_all = mcqa_model.load_dataset_test_file(\n","    dataset_name=\"parsinlu\", dataset_file=\"./parsinlu/data/multiple-choice/test.jsonl\")\n","print(test_questions_all[0])\n","print(test_candidates_all[0])\n","print(test_choices_all[0])\n","print(test_answers_all[0])\n","print(len(test_questions_all))\n","print(len(test_candidates_all))\n","print(len(test_choices_all))\n","print(len(test_answers_all))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["تفاوت سن علیرضا و خواهرش A سال است B سال دیگر سن علیرضا دوبرابر سن امروز خواهرش خواهد بود .سن خواهر علیرضا کدام است؟\n","['2A', '2A+B', '3A+B', 'A-B']\n","2\n","2A+B\n","1050\n","1050\n","1050\n","1050\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WH51PCVZ9LvB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959451678,"user_tz":-270,"elapsed":633,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"0a74c284-f5ef-4984-bca0-138e82a48fac"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Sat Aug 14 16:44:10 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   73C    P0    41W /  70W |  10590MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               85\n","Model name:          Intel(R) Xeon(R) CPU @ 2.00GHz\n","Stepping:            3\n","CPU MHz:             2000.186\n","BogoMIPS:            4000.37\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            1024K\n","L3 cache:            39424K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"laMQutR_9YYl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959611259,"user_tz":-270,"elapsed":159592,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"6d206e3b-f898-4d7a-af15-fc8b41d0bc24"},"source":["evaluation_output = mcqa_model.evaluation(test_questions_all, test_candidates_all, test_choices_all, test_answers_all, device, max_length=mcqa_model.config.max_position_embeddings, batch_size=64)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["#question:1050, #candidates:1050, #answer:1050\n","#batch: 17\n","Start to evaluate test data ...\n","inference time for step 0: 0.27069728300000406\n","inference time for step 1: 0.008777381000015794\n","inference time for step 2: 0.009008895000022221\n","inference time for step 3: 0.012308103000009396\n","inference time for step 4: 0.008443107999994481\n","inference time for step 5: 0.008468744999959199\n","inference time for step 6: 0.008799344999999903\n","inference time for step 7: 0.008233946000018477\n","inference time for step 8: 0.008365459000003739\n","inference time for step 9: 0.009114326000030815\n","inference time for step 10: 0.00891568700001244\n","inference time for step 11: 0.009660393999979533\n","inference time for step 12: 0.009447060999946189\n","inference time for step 13: 0.008803696000086347\n","inference time for step 14: 0.008681491999936952\n","inference time for step 15: 0.008927753000079974\n","inference time for step 16: 0.009114832000022943\n","average loss: 1.3862948557909798\n","total inference time: 0.41576750600012247\n","total inference time / #samples: 0.00039596905333345\n","Test Accuracy: 0.26857142857142857\n","Test Precision: 0.25846186348750205\n","Test Recall: 0.26857142857142857\n","Test F1-Score(weighted average): 0.20340823027330798\n","Test classification Report:\n","              precision    recall  f1-score   support\n","\n","           0  0.2701005025 0.7388316151 0.3955841766       291\n","           1  0.2880000000 0.1245674740 0.1739130435       289\n","           2  0.2804878049 0.0858208955 0.1314285714       268\n","           3  0.1702127660 0.0396039604 0.0642570281       202\n","\n","    accuracy                      0.2685714286      1050\n","   macro avg  0.2522002683 0.2472059863 0.1912957049      1050\n","weighted avg  0.2584618635 0.2685714286 0.2034082303      1050\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"La5YYuVJ9Lx-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959611259,"user_tz":-270,"elapsed":10,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}},"outputId":"16617eca-91aa-44df-8287-0d772b81f70d"},"source":["for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer in evaluation_output[:25]:\n","  print('{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["تفاوت سن علیرضا و خواهرش A سال است B سال دیگر سن علیرضا دوبرابر سن امروز خواهرش خواهد بود .سن خواهر علیرضا کدام است؟\t['2A', '2A+B', '3A+B', 'A-B']\t1\t2A+B\t0\t2A\n","در ادامه این رشته چه عددی باید نوشت؟ ۹۱،۸۶،۷۶،۶۱،...\t['۴۶', '۴۱', '۵۱', '۳۶']\t1\t۴۱\t0\t۴۶\n","50 تا 20 تا برابر است با ......\t['10000', '100', '1000', '500']\t2\t1000\t0\t10000\n","در ادامه این رشته چه عددی باید نوشت؟             3, 5, 5, 9, 7, 13, 9, …\t['17', '11', '14', '15']\t0\t17\t0\t17\n","مساحت مربع ۸ ،p برابر مساحت مربع Q است. نسبت قطر مربع p به ضلع مربع Q کدامست؟\t['۴', '۲', '۳', '۱']\t0\t۴\t1\t۲\n","%50 عدد 24 برابر است با ....\t['4', '6', '10', '12']\t3\t12\t0\t4\n","کدام عدد نزدیکتر۷ به است؟\t['۴', '۶', '۹', '۱۱']\t1\t۶\t2\t۹\n","چند درصد ۵۰۰ برابر ۵۰ می‌شود؟\t['۱', '۱۰', '۲۰', '۳۰']\t1\t۱۰\t0\t۱\n","قیمت یک کالا %۲۵ تخفیف داده شده است برای آنکه این کالا به قیمت قبل از تخفیف فروخته شود چند درصد باید به قیمت آن افزوده گردد؟\t['۲۵', '۲۰', '۳۳.۳۳', 'هیچکدام']\t2\t۳۳.۳۳\t0\t۲۵\n","حاصل عبارت ۵ - ۳ برابر است با ؟\t['-2', '2', '1', '-1']\t0\t-2\t1\t2\n","حاصل عبارت ۴۴ + ۲۳ برابر است با ؟\t['68', '65', '57', '67']\t3\t67\t0\t68\n","سرمایه دو شریک به نسبت او ۱ می‌باشد سود نفر دوم در یک معامله ۹۰۰ تومان است کل مبلغ سود\r\n","چند تومان است. کل مبلغ سود چند تومان می‌شود؟\r\t['۷۲۰', '۳۶۰۰', '۱۶۲۰', '۴۵۰۰']\t2\t۱۶۲۰\t0\t۷۲۰\n","۵۴۰۰ لیتر بنزین برای مصرف ۹ اتومبیل یک شرکت راهسازی در مدت ۲۰ روز مأموریت داده شده است. با\n","افزوده شدن ۳ اتومبیل دیگر ۲ روز از مدت مأموریت کم می‌شود در صورتی که مقدار بنزین دریافتی تغییر\n","نکند. سهمیه بنزین روزانه هر اتومبیل:\n","\t['زیاد شده است', 'کم شده است', 'تغییر نکرده است', 'قابل تعیین نیست']\t1\tکم شده است\t0\tزیاد شده است\n","نسبت اسید دریک ماده شیمیایی %۳ است، ۶۰ لیتر از این ماده را با چند لیتر ماده بدون اسید باید مخلوط کرد تا نسبت اسید مخلوط %۱ شود؟\t['۸۰', '۱۰۰', '۱۲۰', '۱۵۰']\t2\t۱۲۰\t0\t۸۰\n","اگر یک سوم چوبی در زمین و یک دوم « در آب و قسمت بالائی‌آن که بیرون از آب قرار دارد ۱/۵ متر باشد،طول چوب چقدر است؟\t['4.5', '6', '9', '10.5']\t2\t9\t0\t4.5\n","کدامیک ازاعداد زیرازعدد 43 کوچکتراست؟\t['45', '54', '49', '34']\t3\t34\t0\t45\n"," ﻜﺪاﻡ عبارت صحیح نیست ؟\t['اﺯﺪو نقطه فقط یک خط راست می ﮔﺬارﺪ.', 'اﮔﺮخطی بر خط ﺪﻴﮔﺮعموﺪباﺷﺪبر خطوط مواﺯی آن ﻨﻳﺯعموﺪاست.', 'هر خط عموﺪبر خط ﺪﻴﮔﺮعموﺪمنصف آن خط است.', 'هر قطر لوﺯی عموﺪمنصف قطر ﺪﻴﮔﺮاست.']\t2\tهر خط عموﺪبر خط ﺪﻴﮔﺮعموﺪمنصف آن خط است.\t2\tهر خط عموﺪبر خط ﺪﻴﮔﺮعموﺪمنصف آن خط است.\n","حاصل 10*9*8  با فاکتوریل کدام عدد طبیعی است؟\t['۶', '۷', '۸', '۹']\t0\t۶\t0\t۶\n","شعاع دایره ای یک دهم افزایش یافته است. مساحت مربع محاطی آن چند درصد افزایش می‌یابد؟\t['۷۹', '۲۱', '۱۹', '۸۱']\t1\t۲۱\t0\t۷۹\n","پدری نصف دارائی خود را بین ۳ فرزندش تقسیم کرده چه کسری از کل دارائی پدر به هر پسر می رسد؟\t['یک ششم', 'یک پنجم', 'یک چهارم', 'یک سوم']\t0\tیک ششم\t0\tیک ششم\n","شخصی جنسی را به ۲۰۰۰ ریال خریده بود به ۲۴۰۰ ریال فروخت. حال اگر جنسی را به ۶۰۰۰ ریال بفروشد به چند ریال خریده بود؟\t['۵۴۰۰', '۵۲۰۰', '۵۰۰۰', '۲۸۰۰']\t2\t۵۰۰۰\t0\t۵۴۰۰\n","یک مخزن بنزین، دو مجرا دارد، اولی مخزن را در ۶ ساعت و هر دو مجرا با هم آن را در ۴ ساعت خالی\n","می‌کنند، در صورتی که مخزن خالی و فقط مجرای دوم باز باشد مخزن در چند ساعت خالی می‌شود؟\n","\t['۱۲ ساعت', '۸ ساعت', '۴ ساعت', '۳ ساعت']\t1\t۸ ساعت\t0\t۱۲ ساعت\n"," برای انجام عمل تقسیم به ﺪوﻋﺪﺪ نیاﺯﻤﻧﺪﻴﻡ که  عبارﺗﻧﺪﺍﺯ:۟۟۟۟۟۰۰۰۰۰۰۰۰ ۟۟۟۟۟۰۰۰۰۰۰۰۰\t['مقسوم علیه وخارج قسمت', 'مقسوم ومقسوم علیه', 'مقسوم وباقی ماﻧﺪﻩ', 'خارج قسمت و باقی ماﻧﺪﻩ']\t1\tمقسوم ومقسوم علیه\t0\tمقسوم علیه وخارج قسمت\n","موتورسواری با سرعت متوسط ۶۰ کیلومتر در ساعت فاصله بین دو شهر را طی می‌کند و همین فاصله را با سرعت متوسط ۴۰ کیلومتر در ساعت برمی گردد.\r\n","سرعت متوسط او برای تمام مسیر رفت و برگشت عبارت است از\r\t['۵۳ کیلومتر در ساعت', '۵ کیلومتر در ساعت', '۴۸ کیلومتر در ساعت', '۵۲ کیلومتر در ساعت']\t2\t۴۸ کیلومتر در ساعت\t0\t۵۳ کیلومتر در ساعت\n","به یک نوع کالا نسبت به هشتاد درصد قیمت آن صد و بیست درصد سود بازرگانی تعلـق مـیگیـرد. افـزایش\n","قیمت با محاسبۀ سود بازرگانی چند درصد است؟ \t['۹۶', '۷۶', '۱۹۶', '۱۷۶']\t0\t۹۶\t3\t۱۷۶\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T_YDCiUN9gYV","executionInfo":{"status":"ok","timestamp":1628959612325,"user_tz":-270,"elapsed":1069,"user":{"displayName":"Zohreh Fallahnejad","photoUrl":"","userId":"17176314055126146710"}}},"source":["output_file_name = \"multiple_choice_qa_all_testset_{}_outputs.txt\".format(model_name.replace('/','-'))\n","with open(output_file_name, \"w\", encoding='utf8') as output_file:\n","  for question, candidates, true_choice, true_answer, predicted_choice, predicted_answer in evaluation_output:\n","    output_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(question, candidates, true_choice, true_answer, predicted_choice, predicted_answer))\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","upload = drive.CreateFile({'title': output_file_name})\n","upload.SetContentFile(output_file_name)\n","upload.Upload()"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpBvPple9gbd"},"source":[""],"execution_count":null,"outputs":[]}]}