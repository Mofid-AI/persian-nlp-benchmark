{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TextualThematicSimilarity/m3hrdadfi/bert-fa-base-uncased-wikinli.ipynb","provenance":[{"file_id":"1qTxJYhOvaSSJYszCEnu9cmFc0Ipzs7sb","timestamp":1626164129785}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9448f37750d24bf9a7d2dc7a10bea116":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ebfdb2a12bcd409fbe358961f99bcc6f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f35de9d9f7db4b01b14f42029d6a542e","IPY_MODEL_d190d246f1b54fadabd41711a7a043d0"]}},"ebfdb2a12bcd409fbe358961f99bcc6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f35de9d9f7db4b01b14f42029d6a542e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_13cfc29a4bfd45d2b83c9c896628aff4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":699,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":699,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bc2f2e3235744617917b4aa702fbde8b"}},"d190d246f1b54fadabd41711a7a043d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fffaecb8d89b405580670af852ddd4db","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 699/699 [00:00&lt;00:00, 872B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_776d90821b2043eb9f78e3facb981414"}},"13cfc29a4bfd45d2b83c9c896628aff4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bc2f2e3235744617917b4aa702fbde8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fffaecb8d89b405580670af852ddd4db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"776d90821b2043eb9f78e3facb981414":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"59c8bcdd979c48deb579c5d4affdc8f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c4b986a83ade4a7b9d795df1990433b3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_91285bb5f94e4fc7957e2b0cb222a8b8","IPY_MODEL_6ab4919fa4a040e7bdadf1d0b3438bbb"]}},"c4b986a83ade4a7b9d795df1990433b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91285bb5f94e4fc7957e2b0cb222a8b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_006254b7bd7f4f8f835a7d43fd1627c1","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1198122,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1198122,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4bd56a38a1134811aaa74f24dbc74400"}},"6ab4919fa4a040e7bdadf1d0b3438bbb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ca2c24a8106249f28453f7ec6ac2a5cb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.20M/1.20M [00:02&lt;00:00, 449kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_25ff89b0397e4fe58b15b105be34fbc4"}},"006254b7bd7f4f8f835a7d43fd1627c1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4bd56a38a1134811aaa74f24dbc74400":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ca2c24a8106249f28453f7ec6ac2a5cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"25ff89b0397e4fe58b15b105be34fbc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"559fbf3e33044b95a09c99d17ceb73c6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bb719ac599a54f32abde2daf1df8e53c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dc526fd862e94134bbc892d3b50c243f","IPY_MODEL_fb65e24c4e8e4775a86cb0d029937960"]}},"bb719ac599a54f32abde2daf1df8e53c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dc526fd862e94134bbc892d3b50c243f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_874f6f2e141441fe9787864bd94138f4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4a58775c30d2440c8b4b6498a57e71e3"}},"fb65e24c4e8e4775a86cb0d029937960":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b9e7920ee714412bb11d3d8906d2ad51","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 122B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ed94173c39854cf58cad66eac2c811b5"}},"874f6f2e141441fe9787864bd94138f4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4a58775c30d2440c8b4b6498a57e71e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9e7920ee714412bb11d3d8906d2ad51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ed94173c39854cf58cad66eac2c811b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"910a6729131f4381bb27987e834d5eba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4b970388eb3a4e3cb46cb018a61400e0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_45ead3faa50f4784aa1911ab75bd846e","IPY_MODEL_6973faddd928409bb785ef413b02567f"]}},"4b970388eb3a4e3cb46cb018a61400e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"45ead3faa50f4784aa1911ab75bd846e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_77b2e31ab0bf477b9c5e7673eee16602","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":377,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":377,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b125270f8cca43f58bdf980a2b6449e9"}},"6973faddd928409bb785ef413b02567f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_88c75d1e6062475b9927ab625fe0799a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 377/377 [00:00&lt;00:00, 2.53kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2b9ccc752721446a9f3ec67b7372239b"}},"77b2e31ab0bf477b9c5e7673eee16602":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b125270f8cca43f58bdf980a2b6449e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"88c75d1e6062475b9927ab625fe0799a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2b9ccc752721446a9f3ec67b7372239b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4d24e4eb509f40409147a67ec9ad7350":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9c637ffd943e431dac15277b399cec8f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c5d21bdaa863440f867ccb319ec041da","IPY_MODEL_ec20451b9fbc4034b70364eddf0d4275"]}},"9c637ffd943e431dac15277b399cec8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c5d21bdaa863440f867ccb319ec041da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ce35c1491b474a04bdc82e2d8c1ac03b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":651458839,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":651458839,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8ec0017e407b45c2ba8cd9f8d4f61f8e"}},"ec20451b9fbc4034b70364eddf0d4275":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a641a48fa5f544f3b67bb73359b35d02","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 651M/651M [00:21&lt;00:00, 30.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3abdeb85060248f6bdf0d9cce227628b"}},"ce35c1491b474a04bdc82e2d8c1ac03b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8ec0017e407b45c2ba8cd9f8d4f61f8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a641a48fa5f544f3b67bb73359b35d02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3abdeb85060248f6bdf0d9cce227628b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2XtVRjBj_avi"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ir0KniWxd1u","executionInfo":{"status":"ok","timestamp":1627316780831,"user_tz":-270,"elapsed":36969,"user":{"displayName":"maryam fallahnejad","photoUrl":"","userId":"10352009640377516011"}},"outputId":"35234c4a-c7ad-44f5-e35f-c92de0f20c8a"},"source":["!pip install hazm==0.7.0\n","!pip install seqeval==1.2.2\n","!pip install sentencepiece==0.1.96\n","!pip install sentence-transformers==2.0.0\n","!pip install transformers==4.7.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting hazm==0.7.0\n","  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n","\u001b[K     |████████████████████████████████| 316 kB 11.6 MB/s \n","\u001b[?25hCollecting libwapiti>=0.2.1\n","  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n","\u001b[K     |████████████████████████████████| 233 kB 21.0 MB/s \n","\u001b[?25hCollecting nltk==3.3\n","  Downloading nltk-3.3.0.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 27.7 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm==0.7.0) (1.15.0)\n","Building wheels for collected packages: nltk, libwapiti\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394485 sha256=d6c87b3b91e9f19fd6ca94ee61f60729493f9422a9c3f01e913b1d29280cd3bd\n","  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n","  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154047 sha256=80d5753137e9e2ca782ca34febeebe38bccce1c950db7b2b31592f1455d38a60\n","  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n","Successfully built nltk libwapiti\n","Installing collected packages: nltk, libwapiti, hazm\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n","Collecting seqeval==1.2.2\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2) (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.0.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=15054670db445ad2ac720efa5e9285c1a6d8313501949e6c1e8c5d65c06021af\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Collecting sentencepiece==0.1.96\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 13.1 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting sentence-transformers==2.0.0\n","  Downloading sentence-transformers-2.0.0.tar.gz (85 kB)\n","\u001b[K     |████████████████████████████████| 85 kB 3.3 MB/s \n","\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n","  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 19.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==2.0.0) (4.41.1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==2.0.0) (1.9.0+cu102)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==2.0.0) (0.10.0+cu102)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==2.0.0) (1.19.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==2.0.0) (0.22.2.post1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==2.0.0) (1.4.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==2.0.0) (3.3)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==2.0.0) (0.1.96)\n","Collecting huggingface-hub\n","  Downloading huggingface_hub-0.0.14-py3-none-any.whl (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers==2.0.0) (3.7.4.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.0.0) (4.6.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.0.0) (21.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 43.3 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.0.0) (3.0.12)\n","Collecting huggingface-hub\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 40.8 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 38.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.0.0) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.0.0) (2019.12.20)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers==2.0.0) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers==2.0.0) (3.5.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers==2.0.0) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers==2.0.0) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers==2.0.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers==2.0.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers==2.0.0) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers==2.0.0) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers==2.0.0) (7.1.2)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers==2.0.0) (7.1.2)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.0.0-py3-none-any.whl size=126709 sha256=caa4bfa8734f84afbd6126b9d453a49df247fc3204be5d8830ab5058cbadcdef\n","  Stored in directory: /root/.cache/pip/wheels/d1/c1/0f/faafd427f705c4b012274ba60d9a91d75830306811e1355293\n","Successfully built sentence-transformers\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers, sentence-transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 sentence-transformers-2.0.0 tokenizers-0.10.3 transformers-4.9.1\n","Collecting transformers==4.7.0\n","  Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 12.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (1.19.5)\n","Collecting huggingface-hub==0.0.8\n","  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (21.0)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (0.10.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (4.41.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (5.4.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (4.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (3.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0) (0.0.45)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0) (3.5.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.7.0) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0) (1.15.0)\n","Installing collected packages: huggingface-hub, transformers\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.0.12\n","    Uninstalling huggingface-hub-0.0.12:\n","      Successfully uninstalled huggingface-hub-0.0.12\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.9.1\n","    Uninstalling transformers-4.9.1:\n","      Successfully uninstalled transformers-4.9.1\n","Successfully installed huggingface-hub-0.0.8 transformers-4.7.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W2FV-u04Vccd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627316810446,"user_tz":-270,"elapsed":29627,"user":{"displayName":"maryam fallahnejad","photoUrl":"","userId":"10352009640377516011"}},"outputId":"3dad2937-dddc-46f8-c555-c64ab3720620"},"source":["!pip install PyDrive\n","import os\n","import IPython.display as ipd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: PyDrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (1.12.8)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (5.4.1)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.32.1)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.26.3)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n","Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.23.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.17.3)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2018.9)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (57.2.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.53.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (21.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.2.2)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2021.5.30)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"swiMZ0m8Vn1l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627316820294,"user_tz":-270,"elapsed":7639,"user":{"displayName":"maryam fallahnejad","photoUrl":"","userId":"10352009640377516011"}},"outputId":"b59322ee-c4be-4264-8018-275c50e30376"},"source":["import re\n","import gc\n","import os\n","import hazm\n","import time\n","import json\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","import transformers\n","from transformers import AutoTokenizer, AutoConfig\n","from transformers import AutoModelForSequenceClassification\n","\n","from sentence_transformers import models, SentenceTransformer, util\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","\n","print()\n","print('numpy', np.__version__)\n","print('pandas', pd.__version__)\n","print('transformers', transformers.__version__)\n","print('torch', torch.__version__)\n","print()\n","\n","# load rouge for validation\n","# rouge = datasets.load_metric(\"rouge\")\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","numpy 1.19.5\n","pandas 1.1.5\n","transformers 4.7.0\n","torch 1.9.0+cu102\n","\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rzY3wThDVxeI"},"source":["class TextualThematicSimilarityDataset(torch.utils.data.Dataset):\n","    \"\"\" Create a PyTorch dataset for Textual Thematic Similarity. \"\"\"\n","\n","    def __init__(self, sentences_1, sentences_2, targets, tokenizer, model_architecture, max_length):\n","        self.sentences_1 = sentences_1\n","        self.sentences_2 = sentences_2\n","        self.targets = targets\n","        self.tokenizer = tokenizer\n","        self.model_architecture = model_architecture\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.sentences_1)\n","\n","    def __getitem__(self, item):\n","        if self.model_architecture == \"BertForSequenceClassification\":\n","            encoding = self.tokenizer(\n","                [(self.sentences_1[item], self.sentences_2[item])],\n","                add_special_tokens=True,\n","                max_length=self.max_length,\n","                truncation=True,\n","                padding='max_length',\n","                return_tensors=\"pt\"\n","            )\n","            inputs = {\n","                'sentence_1': self.sentences_1[item],\n","                'sentence_2': self.sentences_2[item],\n","                'targets': self.targets[item],\n","                'input_ids': encoding.input_ids.flatten(),\n","                'attention_mask': encoding.attention_mask.flatten(),\n","                'token_type_ids': encoding['token_type_ids'].flatten()\n","            }\n","            return inputs\n","        elif self.model_architecture == \"sentence-transformer\":\n","            inputs = {\n","                'item': item,\n","                'sentence_1': self.sentences_1[item],\n","                'sentence_2': self.sentences_2[item],\n","                'targets': self.targets[item]\n","            }\n","            return inputs\n","        return {}\n","\n","\n","class TextualThematicSimilarity:\n","    def __init__(self, model_name, model_architecture, label2id=None):\n","        self.normalizer = hazm.Normalizer()\n","        self.model_name = model_name\n","        self.model_architecture = model_architecture\n","        if self.model_architecture == \"BertForSequenceClassification\":\n","            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n","            self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)\n","            self.config = AutoConfig.from_pretrained(self.model_name)\n","            self.label2id = label2id\n","            self.id2label = {i: l for l, i in label2id.items()}\n","        elif self.model_architecture == \"sentence-transformer\":\n","            word_embedding_model = models.Transformer(self.model_name)\n","            pooling_model = models.Pooling(\n","                word_embedding_model.get_word_embedding_dimension(),\n","                pooling_mode_mean_tokens=True,\n","                pooling_mode_cls_token=False,\n","                pooling_mode_max_tokens=False)\n","            self.model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n","            self.config = AutoConfig.from_pretrained(self.model_name)\n","\n","    def load_dataset_test_file(self, dataset_name, dataset_file, **kwargs):\n","        if dataset_name.lower() == \"wiki-d-similar\":\n","            if not os.path.exists(dataset_file):\n","                print(f'{dataset_file} not exists!')\n","                return\n","            data = pd.read_csv(dataset_file, delimiter=\"\\t\")\n","\n","            # cleaning labels\n","            valid_labels = ['dissimilar', 'similar']\n","            data['Label'] = data['Label'].apply(lambda r: r if r in valid_labels else None)\n","            data = data.dropna(subset=['Label'])\n","            data = data.reset_index(drop=True)\n","\n","            sentence1_list, sentence2_list = data['Sentence1'].values.tolist(), data['Sentence2'].values.tolist()\n","            labels = data['Label'].values.tolist()\n","            print(f'test part:\\n #sentence1: {len(sentence1_list)}, #sentence2: {len(sentence2_list)}, '\n","                  f'#labels: {len(labels)}')\n","            return sentence1_list, sentence2_list, labels\n","\n","    def thematic_similarity_inference_seq_classification(self, sentences_1, sentences_2, device, max_length):\n","        if not self.model or not self.tokenizer or not self.id2label:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        new_input = []\n","        for s1, s2 in zip(sentences_1, sentences_2):\n","            new_input.append((s1, s2))\n","\n","        tokenized_batch = self.tokenizer(\n","            new_input,\n","            padding=True,\n","            truncation=True,\n","            max_length=max_length,\n","            return_tensors=\"pt\"\n","        )\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","\n","        tokenized_batch = tokenized_batch.to(device)\n","        outputs = self.model(**tokenized_batch)\n","        pt_predictions = torch.argmax(F.softmax(outputs.logits, dim=1), dim=1)\n","        pt_predictions = pt_predictions.cpu().detach().numpy().tolist()\n","\n","        output_predictions = []\n","        for i, sent1 in enumerate(sentences_1):\n","            output_predictions.append(\n","                (sent1, sentences_2[i], pt_predictions[i], self.id2label[pt_predictions[i]])\n","            )\n","        return output_predictions\n","\n","    def thematic_similarity_inference_pair_similarity(self, sentences_1, sentences_2, device, label_list,\n","                                                      similarity_threshold=0.5):\n","        if not self.model:\n","            print('Something wrong has been happened!')\n","            return\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","\n","        # Compute the sentence embeddings\n","        sent1_embeddings = self.model.encode(sentences_1, convert_to_tensor=True, show_progress_bar=True)\n","        sent2_embeddings = self.model.encode(sentences_2, convert_to_tensor=True, show_progress_bar=True)\n","\n","        # Compute the pair-wise cosine similarities\n","        similarity_scores, predicted_labels = [], []\n","        for i in range(len(sentences_1)):\n","            cos_scores = util.pytorch_cos_sim(sent1_embeddings[i], sent2_embeddings[i]).cpu().detach().numpy()\n","            similarity_scores.append(cos_scores[0][0])\n","            if cos_scores[0][0] >= similarity_threshold:\n","                predicted_labels.append(label_list[1])\n","            else:\n","                predicted_labels.append(label_list[0])\n","\n","        output_predictions = []\n","        for i, sent1 in enumerate(sentences_1):\n","            output_predictions.append(\n","                (sent1, sentences_2[i], similarity_scores[i], predicted_labels[i])\n","            )\n","        return output_predictions\n","\n","    def evaluation_seq_classification(self, sentence1_list, sentence2_list, labels, device, max_length, batch_size=4):\n","        if not self.model or not self.tokenizer or not self.id2label:\n","            print('Something wrong has been happened!')\n","            return\n","        label_count = {label: labels.count(label) for label in labels}\n","        print(\"label_count:\", label_count)\n","\n","        # convert labels\n","        new_labels = [self.label2id[_] for _ in labels]\n","        dataset = TextualThematicSimilarityDataset(sentences_1=sentence1_list, sentences_2=sentence2_list,\n","                                                   targets=new_labels, tokenizer=self.tokenizer,\n","                                                   model_architecture=self.model_architecture, max_length=max_length)\n","        data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n","        print(f'#sentence1:{len(sentence1_list)}, #sentence2:{len(sentence2_list)}, #labels:{len(labels)}')\n","        print(\"#batch:\", len(data_loader))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","\n","        total_loss, total_time = 0, 0\n","        output_predictions = []\n","        golden_labels, predicted_labels = [], []\n","        print(\"Start to evaluate test data ...\")\n","        for step, batch in enumerate(data_loader):\n","            b_sentence_1 = batch['sentence_1']\n","            b_input_ids = batch['input_ids']\n","            b_attention_mask = batch['attention_mask']\n","            b_token_type_ids = batch['token_type_ids']\n","            b_targets = batch['targets']\n","\n","            # move tensors to GPU if CUDA is available\n","            b_input_ids = b_input_ids.to(device)\n","            b_attention_mask = b_attention_mask.to(device)\n","            b_token_type_ids = b_token_type_ids.to(device)\n","            b_targets = b_targets.to(device)\n","\n","            # This will return the loss (rather than the model output) because we have provided the `labels`.\n","            with torch.no_grad():\n","                start = time.monotonic()\n","                b_outputs = self.model(input_ids=b_input_ids, attention_mask=b_attention_mask,\n","                                       token_type_ids=b_token_type_ids, labels=b_targets)\n","                end = time.monotonic()\n","                total_time += end - start\n","                print(f'inference time for step {step}: {end - start}')\n","            # get the loss\n","            total_loss += b_outputs.loss.item()\n","\n","            golden_labels.extend([self.id2label[_.item()] for _ in b_targets])\n","\n","            b_predictions = torch.argmax(F.softmax(b_outputs.logits, dim=1), dim=1)\n","            b_predictions = b_predictions.cpu().detach().numpy().tolist()\n","            b_predictions = [self.id2label[_] for _ in b_predictions]\n","            predicted_labels.extend(b_predictions)\n","\n","            for i, sent1 in enumerate(b_sentence_1):\n","                output_predictions.append((\n","                    sent1,\n","                    batch['sentence_2'][i],\n","                    self.id2label[b_targets[i].item()],\n","                    b_predictions[i]\n","                ))\n","\n","        # Calculate the average loss over the training data.\n","        avg_train_loss = total_loss / len(data_loader)\n","        print(\"average loss:\", avg_train_loss)\n","        print(\"total inference time:\", total_time)\n","        print(\"total inference time / #samples:\", total_time / len(sentence1_list))\n","\n","        # evaluate\n","        print(\"Test Accuracy: {}\".format(accuracy_score(golden_labels, predicted_labels)))\n","        print(\"Test Precision: {}\".format(precision_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test Recall: {}\".format(recall_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test F1-Score(weighted average): {}\".format(\n","            f1_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test classification Report:\\n{}\".format(classification_report(\n","            golden_labels, predicted_labels, digits=10)))\n","        return output_predictions\n","\n","    def evaluation_pair_similarity(self, sentence1_list, sentence2_list, labels, device, max_length, label_list,\n","                                   batch_size=4, similarity_threshold=0.5):\n","        if not self.model:\n","            print('Something wrong has been happened!')\n","            return\n","        label_count = {label: labels.count(label) for label in labels}\n","        print(\"label_count:\", label_count)\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        # Tell pytorch to run this model on the GPU.\n","        if device.type != 'cpu':\n","            self.model.cuda()\n","\n","        total_time = 0\n","        print(\"Start to evaluate test data ...\")\n","\n","        # Compute the sentence embeddings\n","        start = time.monotonic()\n","        sent1_embeddings = self.model.encode(sentence1_list, convert_to_tensor=True, show_progress_bar=True,\n","                                             batch_size=batch_size)\n","        sent2_embeddings = self.model.encode(sentence2_list, convert_to_tensor=True, show_progress_bar=True,\n","                                             batch_size=batch_size)\n","\n","        end = time.monotonic()\n","        total_time += end - start\n","        print(f'time for computing sentence embeddings: {end - start}')\n","\n","        # # convert labels\n","        # new_labels = [self.label2id[_] for _ in labels]\n","        dataset = TextualThematicSimilarityDataset(sentences_1=sent1_embeddings, sentences_2=sent2_embeddings,\n","                                                   targets=labels, tokenizer=None,\n","                                                   model_architecture=self.model_architecture, max_length=max_length)\n","        data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n","        print(f'#sentence1:{len(sentence1_list)}, #sentence2:{len(sentence2_list)}, #labels:{len(labels)}')\n","        print(\"#batch:\", len(data_loader))\n","\n","        output_predictions = []\n","        golden_labels, predicted_labels = [], []\n","        for step, batch in enumerate(data_loader):\n","            b_sentence_1 = batch['sentence_1']\n","            b_sentence_2 = batch['sentence_2']\n","\n","            # move tensors to GPU if CUDA is available\n","            b_sentence_1 = b_sentence_1.to(device)\n","            b_sentence_2 = b_sentence_2.to(device)\n","\n","            # Compute the pair-wise cosine similarities\n","            # similarity_scores, predicted_labels = [], []\n","            start = time.monotonic()\n","            cos_similarity_scores, b_predictions = [], []\n","            for i in range(len(b_sentence_1)):\n","                cos_scores = util.pytorch_cos_sim(b_sentence_1[i], b_sentence_2[i]).cpu().detach().numpy()\n","                cos_similarity_scores.append(cos_scores[0][0])\n","                if cos_scores[0][0] >= similarity_threshold:\n","                    b_predictions.append(label_list[1])\n","                else:\n","                    b_predictions.append(label_list[0])\n","            end = time.monotonic()\n","            total_time += end - start\n","            print(f'time for calculating cosine similarity in step {step}: {end - start}')\n","\n","            golden_labels.extend(batch['targets'])\n","            predicted_labels.extend(b_predictions)\n","\n","            for i, item in enumerate(batch['item']):\n","                output_predictions.append((\n","                    sentence1_list[item],\n","                    sentence2_list[item],\n","                    cos_similarity_scores[i],\n","                    batch['targets'][i],\n","                    b_predictions[i]\n","                ))\n","\n","        print(\"total inference time:\", total_time)\n","        print(\"total inference time / #samples:\", total_time / len(sentence1_list))\n","\n","        # evaluate\n","        print(\"Test Accuracy: {}\".format(accuracy_score(golden_labels, predicted_labels)))\n","        print(\"Test Precision: {}\".format(precision_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test Recall: {}\".format(recall_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test F1-Score(weighted average): {}\".format(\n","            f1_score(golden_labels, predicted_labels, average=\"weighted\")))\n","        print(\"Test classification Report:\\n{}\".format(classification_report(\n","            golden_labels, predicted_labels, digits=10)))\n","        return output_predictions\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"auUSkQziWIm-","colab":{"base_uri":"https://localhost:8080/","height":832,"referenced_widgets":["9448f37750d24bf9a7d2dc7a10bea116","ebfdb2a12bcd409fbe358961f99bcc6f","f35de9d9f7db4b01b14f42029d6a542e","d190d246f1b54fadabd41711a7a043d0","13cfc29a4bfd45d2b83c9c896628aff4","bc2f2e3235744617917b4aa702fbde8b","fffaecb8d89b405580670af852ddd4db","776d90821b2043eb9f78e3facb981414","59c8bcdd979c48deb579c5d4affdc8f0","c4b986a83ade4a7b9d795df1990433b3","91285bb5f94e4fc7957e2b0cb222a8b8","6ab4919fa4a040e7bdadf1d0b3438bbb","006254b7bd7f4f8f835a7d43fd1627c1","4bd56a38a1134811aaa74f24dbc74400","ca2c24a8106249f28453f7ec6ac2a5cb","25ff89b0397e4fe58b15b105be34fbc4","559fbf3e33044b95a09c99d17ceb73c6","bb719ac599a54f32abde2daf1df8e53c","dc526fd862e94134bbc892d3b50c243f","fb65e24c4e8e4775a86cb0d029937960","874f6f2e141441fe9787864bd94138f4","4a58775c30d2440c8b4b6498a57e71e3","b9e7920ee714412bb11d3d8906d2ad51","ed94173c39854cf58cad66eac2c811b5","910a6729131f4381bb27987e834d5eba","4b970388eb3a4e3cb46cb018a61400e0","45ead3faa50f4784aa1911ab75bd846e","6973faddd928409bb785ef413b02567f","77b2e31ab0bf477b9c5e7673eee16602","b125270f8cca43f58bdf980a2b6449e9","88c75d1e6062475b9927ab625fe0799a","2b9ccc752721446a9f3ec67b7372239b","4d24e4eb509f40409147a67ec9ad7350","9c637ffd943e431dac15277b399cec8f","c5d21bdaa863440f867ccb319ec041da","ec20451b9fbc4034b70364eddf0d4275","ce35c1491b474a04bdc82e2d8c1ac03b","8ec0017e407b45c2ba8cd9f8d4f61f8e","a641a48fa5f544f3b67bb73359b35d02","3abdeb85060248f6bdf0d9cce227628b"]},"executionInfo":{"status":"ok","timestamp":1627316848876,"user_tz":-270,"elapsed":27162,"user":{"displayName":"maryam fallahnejad","photoUrl":"","userId":"10352009640377516011"}},"outputId":"3548a2b2-7198-4a6e-ade8-2f146147db94"},"source":["model_name = 'm3hrdadfi/bert-fa-base-uncased-wikinli'\n","tts_model = TextualThematicSimilarity(model_name=model_name, model_architecture=\"BertForSequenceClassification\", label2id= {\"dissimilar\": 0, \"similar\": 1})\n","print(tts_model.config)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9448f37750d24bf9a7d2dc7a10bea116","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=699.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59c8bcdd979c48deb579c5d4affdc8f0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1198122.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"559fbf3e33044b95a09c99d17ceb73c6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"910a6729131f4381bb27987e834d5eba","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=377.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d24e4eb509f40409147a67ec9ad7350","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=651458839.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","BertConfig {\n","  \"_name_or_path\": \"HooshvareLab/bert-fa-base-uncased\",\n","  \"architectures\": [\n","    \"BertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"wikinli\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"dissimilar\",\n","    \"1\": \"similar\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 0,\n","    \"entailment\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.7.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 100000\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EJ6JJPMcWRUD"},"source":["## Sample Inference"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ns8uNIXFx570","executionInfo":{"status":"ok","timestamp":1627316858719,"user_tz":-270,"elapsed":9853,"user":{"displayName":"maryam fallahnejad","photoUrl":"","userId":"10352009640377516011"}},"outputId":"6c485097-074b-445b-a5d3-03de03b0ccee"},"source":["sentences_1 = [\n","    'در جریان انقلاب آلمان در سال های ۱۹۱۸ و ۱۹۱۹ او به برپایی تشکیلات فرایکورپس که سازمانی شبه نظامی برای سرکوب تحرکات انقلابی کمونیستی در اروپای مرکزی بود ، کمک کرد .\t',\n","    'در جریان انقلاب آلمان در سال های ۱۹۱۸ و ۱۹۱۹ او به برپایی تشکیلات فرایکورپس که سازمانی شبه نظامی برای سرکوب تحرکات انقلابی کمونیستی در اروپای مرکزی بود ، کمک کرد .\t',\n","    'شهر شیراز در بین سال های ۱۳۴۷ تا ۱۳۵۷ محل برگزاری جشن هنر شیراز بود .\t', \n","    'شهر شیراز در بین سال های ۱۳۴۷ تا ۱۳۵۷ محل برگزاری جشن هنر شیراز بود .\t'\n","]\n","sentences_2 = [\n","    'کاناریس بعد از جنگ در ارتش باقی ماند ، اول به عنوان عضو فرایکورپس و سپس در نیروی دریایی رایش.در ۱۹۳۱ به درجه سروانی رسیده بود .\t',\n","    'پسر سرهنگ وسل فرییتاگ لورینگوون به نام نیکی در مورد ارتباط کاناریس با بهم خوردن توطئه هیتلر برای اجرای آدمربایی و ترور پاپ پیوس دوازدهم در ایتالیا در ۱۹۷۲ در مونیخ شهادت داده است .\t',\n","    'جشنواره ای از هنر نمایشی و موسیقی بود که از سال ۱۳۴۶ تا ۱۳۵۶ در پایان تابستان هر سال در شهر شیراز و تخت جمشید برگزار می شد .\t',\n","    'ورزشگاه پارس با ظرفیت ۵۰ هزار تن که در جنوب شیراز واقع شده است .\t'\n","]\n","tts_model.thematic_similarity_inference_seq_classification(sentences_1, sentences_2, device, max_length=tts_model.config.max_position_embeddings)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('در جریان انقلاب آلمان در سال های ۱۹۱۸ و ۱۹۱۹ او به برپایی تشکیلات فرایکورپس که سازمانی شبه نظامی برای سرکوب تحرکات انقلابی کمونیستی در اروپای مرکزی بود ، کمک کرد .\\t',\n","  'کاناریس بعد از جنگ در ارتش باقی ماند ، اول به عنوان عضو فرایکورپس و سپس در نیروی دریایی رایش.در ۱۹۳۱ به درجه سروانی رسیده بود .\\t',\n","  1,\n","  'similar'),\n"," ('در جریان انقلاب آلمان در سال های ۱۹۱۸ و ۱۹۱۹ او به برپایی تشکیلات فرایکورپس که سازمانی شبه نظامی برای سرکوب تحرکات انقلابی کمونیستی در اروپای مرکزی بود ، کمک کرد .\\t',\n","  'پسر سرهنگ وسل فرییتاگ لورینگوون به نام نیکی در مورد ارتباط کاناریس با بهم خوردن توطئه هیتلر برای اجرای آدمربایی و ترور پاپ پیوس دوازدهم در ایتالیا در ۱۹۷۲ در مونیخ شهادت داده است .\\t',\n","  0,\n","  'dissimilar'),\n"," ('شهر شیراز در بین سال های ۱۳۴۷ تا ۱۳۵۷ محل برگزاری جشن هنر شیراز بود .\\t',\n","  'جشنواره ای از هنر نمایشی و موسیقی بود که از سال ۱۳۴۶ تا ۱۳۵۶ در پایان تابستان هر سال در شهر شیراز و تخت جمشید برگزار می شد .\\t',\n","  1,\n","  'similar'),\n"," ('شهر شیراز در بین سال های ۱۳۴۷ تا ۱۳۵۷ محل برگزاری جشن هنر شیراز بود .\\t',\n","  'ورزشگاه پارس با ظرفیت ۵۰ هزار تن که در جنوب شیراز واقع شده است .\\t',\n","  0,\n","  'dissimilar')]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"35ncJgC2Wsui"},"source":["## Wiki D/Similar dataset v1.0.0"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7NA63HHjyvRr","executionInfo":{"status":"ok","timestamp":1627316892892,"user_tz":-270,"elapsed":6629,"user":{"displayName":"maryam fallahnejad","photoUrl":"","userId":"10352009640377516011"}},"outputId":"ed079943-fe62-4d2b-a7e3-a9015b8a6e98"},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","download = drive.CreateFile({'id': '1P-KfNVIAx4HkaWFxc9aFoO3sHzHJFaVn'})\n","download.GetContentFile('wiki-d-similar.zip')\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["adc.json  sample_data  wiki-d-similar.zip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nZ5zyC2uy8wi","executionInfo":{"status":"ok","timestamp":1627316894230,"user_tz":-270,"elapsed":1344,"user":{"displayName":"maryam fallahnejad","photoUrl":"","userId":"10352009640377516011"}},"outputId":"88397571-fcda-4655-aee8-e2a042d825be"},"source":["!unzip wiki-d-similar.zip\n","!ls\n","!ls wiki-d-similar"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  wiki-d-similar.zip\n","   creating: wiki-d-similar/\n","  inflating: wiki-d-similar/wiki-d-similar.csv  \n","  inflating: wiki-d-similar/test.csv  \n","  inflating: wiki-d-similar/dev.csv  \n","  inflating: wiki-d-similar/train.csv  \n","adc.json  sample_data  wiki-d-similar  wiki-d-similar.zip\n","dev.csv  test.csv  train.csv  wiki-d-similar.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZwEE_JQmy83r","executionInfo":{"status":"ok","timestamp":1627316894684,"user_tz":-270,"elapsed":457,"user":{"displayName":"maryam fallahnejad","photoUrl":"","userId":"10352009640377516011"}},"outputId":"9787efac-a7ac-4dec-ab7a-25d1117d887d"},"source":["sentences_1, sentences_2, labels = tts_model.load_dataset_test_file(dataset_name=\"wiki-d-similar\", dataset_file=\"./wiki-d-similar/test.csv\")\n","print(len(sentences_1), len(sentences_2), len(labels))\n","print(sentences_1[0])\n","print(sentences_2[0])\n","print(labels[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test part:\n"," #sentence1: 5497, #sentence2: 5497, #labels: 5497\n","5497 5497 5497\n","سوادآموزی بزرگسالان از سال ۱۲۸۶ با تشکیل کلاس های اکابر در شیراز آغاز شد .\n","از فعالیت های سوادآموزی پیش از سال ۱۳۳۴ به دلیل کمبود اطلاعات نمی توان برداشت درستی ارائه داد .\n","similar\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Deyo2qxm0EDF","executionInfo":{"status":"ok","timestamp":1627316895143,"user_tz":-270,"elapsed":467,"user":{"displayName":"maryam fallahnejad","photoUrl":"","userId":"10352009640377516011"}},"outputId":"d2b85cad-debe-4a00-b7fb-b57d9be50d3e"},"source":["!nvidia-smi\n","!lscpu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon Jul 26 16:28:14 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   74C    P0    73W / 149W |   1309MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               63\n","Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n","Stepping:            0\n","CPU MHz:             2299.998\n","BogoMIPS:            4599.99\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            256K\n","L3 cache:            46080K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W0AEniWKyvZM","executionInfo":{"status":"ok","timestamp":1627317265307,"user_tz":-270,"elapsed":370167,"user":{"displayName":"maryam fallahnejad","photoUrl":"","userId":"10352009640377516011"}},"outputId":"94ed5a63-665d-46ca-934f-f155c1060229"},"source":["evaluation_results_wikidsim = tts_model.evaluation_seq_classification(sentences_1, sentences_2, labels, device, max_length=tts_model.config.max_position_embeddings, batch_size=256)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["label_count: {'similar': 2749, 'dissimilar': 2748}\n","#sentence1:5497, #sentence2:5497, #labels:5497\n","#batch: 22\n","Start to evaluate test data ...\n","inference time for step 0: 0.04202250000003005\n","inference time for step 1: 0.013429370000039853\n","inference time for step 2: 0.01310894499999904\n","inference time for step 3: 0.013263803999961965\n","inference time for step 4: 0.01400522100004764\n","inference time for step 5: 0.013270427999941603\n","inference time for step 6: 0.013091837000047235\n","inference time for step 7: 0.013211930000011307\n","inference time for step 8: 0.012973102999922048\n","inference time for step 9: 0.013209708999966097\n","inference time for step 10: 0.013283149000017147\n","inference time for step 11: 0.013391782999974566\n","inference time for step 12: 0.012856177999992724\n","inference time for step 13: 0.01240633399993385\n","inference time for step 14: 0.013773341000046457\n","inference time for step 15: 0.01334908199999063\n","inference time for step 16: 0.013466816000004656\n","inference time for step 17: 0.01321727100003045\n","inference time for step 18: 0.012273035000021082\n","inference time for step 19: 0.013195533000043724\n","inference time for step 20: 0.013381323999965389\n","inference time for step 21: 0.013214947000051325\n","average loss: 1.235341402617368\n","total inference time: 0.31939564000003884\n","total inference time / #samples: 5.810362743315242e-05\n","Test Accuracy: 0.766418046207022\n","Test Precision: 0.767216240963963\n","Test Recall: 0.766418046207022\n","Test F1-Score(weighted average): 0.7662451503678674\n","Test classification Report:\n","              precision    recall  f1-score   support\n","\n","  dissimilar  0.7525879917 0.7936681223 0.7725823592      2748\n","     similar  0.7818391689 0.7391778829 0.7599102468      2749\n","\n","    accuracy                      0.7664180462      5497\n","   macro avg  0.7672135803 0.7664230026 0.7662463030      5497\n","weighted avg  0.7672162410 0.7664180462 0.7662451504      5497\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-lA87A_iCQ05","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627317265309,"user_tz":-270,"elapsed":24,"user":{"displayName":"maryam fallahnejad","photoUrl":"","userId":"10352009640377516011"}},"outputId":"ab869a63-6946-4fad-c693-19348d7f8c26"},"source":["for sent1, sent2, true_label, predicted_label in evaluation_results_wikidsim[:10]:\n","  print('{}\\t{}\\t{}\\t{}'.format(sent1, sent2, true_label, predicted_label))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["سوادآموزی بزرگسالان از سال ۱۲۸۶ با تشکیل کلاس های اکابر در شیراز آغاز شد .\tاز فعالیت های سوادآموزی پیش از سال ۱۳۳۴ به دلیل کمبود اطلاعات نمی توان برداشت درستی ارائه داد .\tsimilar\tdissimilar\n","در کانادا ، دولت به عنوان یک نهاد کلی به تعدادی تقسیمات سنای کانادایی تقسیم شده است که هر یک از آن ها بر اساس فاکتورهای خاصی ، همراه تعداد متفاوتی از سناتورها می باشد .\tسناتورها در کانادا توسط مردم انتخاب نمی شوند اما توسط فرماندار کل کانادا به توصیه نخست وزیر منصوب می شوند .\tsimilar\tsimilar\n","هر گاه نتوان چیزی را به طور جهانی اثبات کرد ، اعتبار آن را می سنجند (یعنی اعتقاد یا باور به آن) .وجود جادو نیز به طور جهانی اثبات نشده .\tبرخی مردم در غرب یا به گونه های مختلف جادوگری عقیده دارند یا آن ها را انجام می دهند .\tdissimilar\tsimilar\n","نخستین تغییر بزرگ در سیبری ساخت راه آهن سراسری سیبری بود که در خلال سال های ۱۸۹۱ تا ۱۹۱۶ انجام شد .\tمهم ترین جانوران در سیبری از راسته جفت سم سانان دو حیوان ، یعنی آهوی ختن سیبری و واپیتی منچوری و از راسته گوشت خوارسانان خرس قطبی ، خرس قهوه ای ، خرس سیاه آسیایی ، ببر سیبری و پلنگ آمور هستند .\tdissimilar\tdissimilar\n","ماهی پوزه پارویی ، پلانکتون ها را با کمک دریافت کننده های الکتریکی کنش پذیر (passive) که بر روی پوزه برجسته اش وجود دارد شکار می کند .\tمنظور از صید بی رویه ، ماهی گیری در مقدارهای بسیار زیادی است که جمعیت ماهی های بالغ را آنقدر کاهش دهد که قادر به بازیابی جمعیت خود نشوند .\tdissimilar\tdissimilar\n","در این روز مردم از لاکشمی ، الهه ثروت ، برای نعمات متعدد او سپاسگزاری می کنند و مراسم دعای شکرگزاری که پوجا (puja) نام دارد ، هم در سپیده دم و هم هنگام غروب آفتاب انجام می گیرد .\tهنگام غروب ، خانه ها و خیابان ها با چراغها ، فانوسها و شمعهای بی شمار تزیین می شود .\tsimilar\tsimilar\n","تنهایی اجتماعی ، تنهایی است که مردم به دلیل نداشتن شبکه گسترده تر اجتماعی تجربه می کنند .\tیک موسسه خیریه غیر انتفاعی در انگلستان ، که با افرادی که درگیر بحران هستند ، همکاری می کند و می گوید : بین احساس تنهایی و خودکشی برای نوجوانان و افراد در سن جوانی خود ، رابطه ی مستقیمی وجود دارد .\tdissimilar\tdissimilar\n","سکونت گاه قره کمر ، در شمال شهر ایبک در ولایت سمنگان افغانستان ، کشف شده که آثار بدست آمده از آن از سنخ فرهنگ اوریگنیشن است ، اما به فرهنگ برادوستی شباهت ندارد .\tافول امپراتوری ساسانی درست پس از فوت خسروپرویز آغاز شد .\tdissimilar\tdissimilar\n","فیلم برداری فصل چهارم در دوبروونیک ادامه پیدا کرد و چندین لوکیشن دیگر مانند قصر دیوکلشن و قلعه کلیس در اسپلیت نیز به مکان های فیلم برداری افزوده شدند .\tکار فیلم برداری فصل پنجم مجموعه از ماه ژوئیه سال ۲۰۱۴ آغاز و در ماه دسامبر همان سال به پایان رسید .\tsimilar\tsimilar\n","در آگوست ۲۰۱۴ ، tvxq دومین کنسرت در دوم های ۵ گانه ژاپن را اعلام کرد که همراه با دهمین سالگرد فعالیت گروه در ژاپن نیز بود .\ttvxq اولین گروه آیدل کره ای بودند که به کوهاکو اوتا گاسن دعوت شدند .\tdissimilar\tdissimilar\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CKLZ2PWJ1Gz_"},"source":["output_file_name = \"textual_thematic_similarity_wikidsimilar_testset_{}_outputs.txt\".format(model_name.replace('/','-'))\n","with open(output_file_name, \"w\", encoding='utf8') as output_file:\n","  for sent1, sent2, true_label, predicted_label in evaluation_results_wikidsim:\n","    output_file.write('{}\\t{}\\t{}\\t{}\\n'.format(sent1, sent2, true_label, predicted_label))\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","upload = drive.CreateFile({'title': output_file_name})\n","upload.SetContentFile(output_file_name)\n","upload.Upload()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CdSh414FXWwn"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hRh5kVEsGYhT"},"source":[""],"execution_count":null,"outputs":[]}]}